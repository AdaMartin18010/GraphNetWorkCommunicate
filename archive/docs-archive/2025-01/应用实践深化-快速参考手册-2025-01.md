# åº”ç”¨å®è·µæ·±åŒ– - å¿«é€Ÿå‚è€ƒæ‰‹å†Œ / Application Practice Deepening - Quick Reference Manual

## ğŸ“š **æ¦‚è¿° / Overview**

æœ¬æ–‡æ¡£æä¾›æœ€æ–°ç ”ç©¶ä¸“é¢˜ï¼ˆPGTã€NSDI 2025åˆ†å¸ƒå¼ç³»ç»Ÿã€LLM-å›¾èåˆæ¨¡å‹ã€GPSæ¶æ„æœ€æ–°è¿›å±•ã€Mamba2ï¼‰çš„å¿«é€Ÿå‚è€ƒæ‰‹å†Œï¼ŒåŒ…æ‹¬å¿«é€Ÿå¼€å§‹ã€å¸¸ç”¨å‘½ä»¤ã€APIå‚è€ƒå’Œæ•…éšœæ’æŸ¥ã€‚

**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**çŠ¶æ€**: âœ… æŒç»­æ›´æ–°ä¸­
**ä¼˜å…ˆçº§**: ğŸ”´ P0 - æé«˜ä¼˜å…ˆçº§
**æœ€æ–°æ›´æ–°**: 2025å¹´1æœˆ - æ•´åˆNSDI 2025æœ€æ–°ç³»ç»Ÿå¿«é€Ÿå‚è€ƒ

---

## ğŸš€ **ä¸€ã€å¿«é€Ÿå¼€å§‹ / Quick Start**

### 1.1 PGTå¿«é€Ÿå¼€å§‹

```python
# 1. å®‰è£…ä¾èµ–
pip install torch torch-geometric transformers

# 2. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
from pgt import PGTModel
model = PGTModel.from_pretrained('pgt-base')

# 3. é¢„è®­ç»ƒ
from pgt import PGTTrainer
trainer = PGTTrainer(model=model)
trainer.train(train_data, num_epochs=100)

# 4. ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ
trainer.finetune(downstream_data, task='node_classification')

# 5. æ¨ç†
predictions = model.predict(test_data)
```

### 1.2 Emmaå¿«é€Ÿå¼€å§‹

```python
# 1. åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
import torch.distributed as dist
dist.init_process_group(backend='nccl')

# 2. åˆ›å»ºEmmaè®­ç»ƒå™¨
from emma import EmmaTrainer
trainer = EmmaTrainer(
    model=gnn_model,
    num_workers=64,
    block_size=10000
)

# 3. è®­ç»ƒ
trainer.train(graph_data, num_epochs=100)
```

### 1.3 GraphGPTå¿«é€Ÿå¼€å§‹

```python
# 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
from graphgpt import GraphGPTModel
model = GraphGPTModel.from_pretrained('graphgpt-base')

# 2. ç”Ÿæˆå›¾
generated_graphs = model.generate(
    num_graphs=1000,
    target_properties={'logP': 2.5, 'MW': 350.0}
)

# 3. è¯„ä¼°ç”Ÿæˆè´¨é‡
quality_scores = model.evaluate_generation(generated_graphs)
```

### 1.4 GPSå¿«é€Ÿå¼€å§‹

```python
# 1. åˆ›å»ºGPSæ¨¡å‹
from gps import GPSModel
model = GPSModel(
    input_dim=128,
    hidden_dim=512,
    num_layers=6,
    num_heads=8
)

# 2. è®­ç»ƒ
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
for epoch in range(100):
    for batch in dataloader:
        output = model(batch)
        loss = criterion(output, batch.y)
        loss.backward()
        optimizer.step()

# 3. æ¨ç†
predictions = model.predict(test_data)
```

### 1.5 Mamba2å¿«é€Ÿå¼€å§‹

```python
# 1. åˆ›å»ºMamba2æ¨¡å‹
from mamba2 import Mamba2Model
model = Mamba2Model(
    input_dim=128,
    hidden_dim=512,
    num_layers=12,
    num_heads=16
)

# 2. æ—¶åºé¢„æµ‹
predictions = model.predict_sequence(
    historical_sequence,
    prediction_horizon=100
)
```

---

## ğŸ“‹ **äºŒã€å¸¸ç”¨å‘½ä»¤ / Common Commands**

### 2.1 è®­ç»ƒå‘½ä»¤

```bash
# PGTé¢„è®­ç»ƒ
python train_pgt.py \
    --data_path /data/graph_data.pt \
    --model_config pgt_config.yaml \
    --output_dir /output/pgt_model \
    --num_epochs 100 \
    --batch_size 32 \
    --learning_rate 1e-4

# Emmaåˆ†å¸ƒå¼è®­ç»ƒ
python train_emma.py \
    --graph_path /data/large_graph.pt \
    --num_workers 64 \
    --block_size 10000 \
    --num_epochs 100

# GraphGPTç”Ÿæˆ
python generate_graphgpt.py \
    --model_path /models/graphgpt.pt \
    --target_properties properties.json \
    --num_molecules 10000 \
    --output_path /output/generated_molecules.pt

# GPSè®­ç»ƒ
python train_gps.py \
    --data_path /data/graph_data.pt \
    --hidden_dim 512 \
    --num_layers 6 \
    --num_epochs 100

# Mamba2æ—¶åºé¢„æµ‹
python train_mamba2.py \
    --sequence_data /data/temporal_data.pt \
    --prediction_horizon 100 \
    --num_epochs 100
```

### 2.2 è¯„ä¼°å‘½ä»¤

```bash
# æ€§èƒ½è¯„ä¼°
python evaluate.py \
    --model_path /models/model.pt \
    --test_data /data/test_data.pt \
    --metrics accuracy f1_score auc_roc \
    --output_path /output/evaluation_report.json

# æ‰¹é‡å¯¹æ¯”
python compare_models.py \
    --models pgt emma graphgpt gps mamba2 \
    --datasets cora citeseer pubmed \
    --output_path /output/comparison_report.json
```

### 2.3 éƒ¨ç½²å‘½ä»¤

```bash
# Dockeræ„å»º
docker build -t graph-model-service:latest .

# Dockerè¿è¡Œ
docker run -d \
    --name model-service \
    --gpus all \
    -p 8000:8000 \
    -v /models:/models \
    graph-model-service:latest

# Kuberneteséƒ¨ç½²
kubectl apply -f k8s-deployment.yaml

# æœåŠ¡æµ‹è¯•
curl -X POST http://localhost:8000/predict \
    -H "Content-Type: application/json" \
    -d '{"data": [...]}'
```

---

## ğŸ“– **ä¸‰ã€APIå‚è€ƒ / API Reference**

### 3.1 PGT API

```python
# æ¨¡å‹åˆå§‹åŒ–
model = PGTModel(
    input_dim=768,
    hidden_dim=768,
    num_layers=12,
    num_heads=12
)

# é¢„è®­ç»ƒ
trainer = PGTTrainer(model=model)
trainer.pretrain(
    data=train_data,
    num_epochs=100,
    batch_size=32,
    learning_rate=1e-4
)

# å¾®è°ƒ
trainer.finetune(
    data=downstream_data,
    task='node_classification',
    num_epochs=50
)

# æ¨ç†
predictions = model.predict(data)
embeddings = model.encode(data)
```

### 3.2 Emma API

```python
# è®­ç»ƒå™¨åˆå§‹åŒ–
trainer = EmmaTrainer(
    model=gnn_model,
    num_workers=64,
    block_size=10000,
    use_mobile_aggregation=True,
    use_load_balancing=True
)

# è®­ç»ƒ
trainer.train(
    graph_data=large_graph,
    num_epochs=100,
    batch_size=32
)

# è¯„ä¼°
metrics = trainer.evaluate(test_data)
```

### 3.3 GraphGPT API

```python
# æ¨¡å‹åˆå§‹åŒ–
model = GraphGPTModel.from_pretrained('graphgpt-base')

# ç”Ÿæˆ
generated = model.generate(
    num_graphs=1000,
    target_properties={'logP': 2.5},
    temperature=0.8,
    top_k=50
)

# è¡¥å…¨
completed = model.complete(partial_graph)

# è¯„ä¼°
quality = model.evaluate_generation(generated_graphs)
```

### 3.4 GPS API

```python
# æ¨¡å‹åˆå§‹åŒ–
model = GPSModel(
    input_dim=128,
    hidden_dim=512,
    num_layers=6,
    num_heads=8,
    dropout=0.1
)

# è®­ç»ƒ
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
trainer = GPSTrainer(model=model, optimizer=optimizer)
trainer.train(train_loader, num_epochs=100)

# æ¨ç†
predictions = model.predict(test_data)
```

### 3.5 Mamba2 API

```python
# æ¨¡å‹åˆå§‹åŒ–
model = Mamba2Model(
    input_dim=128,
    hidden_dim=512,
    num_layers=12,
    num_heads=16,
    s4_state_dim=128
)

# æ—¶åºé¢„æµ‹
predictions = model.predict_sequence(
    historical_sequence,
    prediction_horizon=100
)

# æ¼”åŒ–åˆ†æ
evolution = model.analyze_evolution(
    historical_data,
    entity_pair=(head, tail)
)
```

---

## ğŸ”§ **å››ã€æ•…éšœæ’æŸ¥å¿«é€Ÿå‚è€ƒ / Troubleshooting Quick Reference**

### 4.1 å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

| é”™è¯¯ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| **CUDA out of memory** | å†…å­˜ä¸è¶³ | å‡å°‘batch_sizeï¼Œä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼Œæ··åˆç²¾åº¦è®­ç»ƒ |
| **Lossä¸æ”¶æ•›** | å­¦ä¹ ç‡è¿‡é«˜ | é™ä½å­¦ä¹ ç‡ï¼Œä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦ |
| **è®­ç»ƒé€Ÿåº¦æ…¢** | æ•°æ®åŠ è½½æ…¢ | å¢åŠ num_workersï¼Œä½¿ç”¨pin_memory |
| **é€šä¿¡å¼€é”€å¤§** | ç½‘ç»œå¸¦å®½ä¸è¶³ | ä½¿ç”¨Emmaä¼˜åŒ–ï¼Œæ¢¯åº¦å‹ç¼© |
| **ç”Ÿæˆè´¨é‡å·®** | æ¸©åº¦å‚æ•°ä¸å½“ | è°ƒæ•´temperatureå’Œtop_kå‚æ•° |

### 4.2 æ€§èƒ½ä¼˜åŒ–å¿«é€Ÿæ£€æŸ¥

```python
# æ£€æŸ¥GPUåˆ©ç”¨ç‡
nvidia-smi

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
python -c "import torch; print(torch.cuda.memory_allocated() / 1024**3)"

# æ£€æŸ¥è®­ç»ƒé€Ÿåº¦
python profile_training.py --model model.pt --data data.pt

# æ£€æŸ¥é€šä¿¡å¼€é”€
python profile_communication.py --num_workers 64
```

---

## ğŸ“Š **äº”ã€æ€§èƒ½åŸºå‡†å‚è€ƒ / Performance Benchmarks**

### 5.1 PGTæ€§èƒ½åŸºå‡†

| æ•°æ®é›† | èŠ‚ç‚¹æ•° | å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´ | å†…å­˜å ç”¨ |
|--------|--------|--------|---------|---------|
| **Cora** | 2,708 | 91% | 10åˆ†é’Ÿ | 2GB |
| **Citeseer** | 3,327 | 89% | 15åˆ†é’Ÿ | 2.5GB |
| **PubMed** | 19,717 | 93% | 1å°æ—¶ | 5GB |
| **OGBN-Arxiv** | 169,343 | 82% | 8å°æ—¶ | 20GB |

### 5.2 Emmaæ€§èƒ½åŸºå‡†

| å›¾è§„æ¨¡ | èŠ‚ç‚¹æ•° | è®­ç»ƒæ—¶é—´ | é€šä¿¡å¼€é”€ | GPUåˆ©ç”¨ç‡ |
|--------|--------|---------|---------|----------|
| **ä¸­ç­‰** | 1000ä¸‡ | 1å¤© | 60% | 75% |
| **å¤§è§„æ¨¡** | 1äº¿ | 1å‘¨ | 50% | 80% |
| **è¶…å¤§è§„æ¨¡** | 10äº¿ | 1.5å‘¨ | 45% | 85% |

### 5.3 GraphGPTæ€§èƒ½åŸºå‡†

| ä»»åŠ¡ | ç”Ÿæˆé€Ÿåº¦ | æœ‰æ•ˆæ€§ | è´¨é‡åˆ†æ•° |
|------|---------|--------|---------|
| **åˆ†å­ç”Ÿæˆ** | 10,000/å°æ—¶ | 92% | 0.85 |
| **çŸ¥è¯†å›¾è°±è¡¥å…¨** | 10,000/å°æ—¶ | 89% | 0.92 |

### 5.4 GPSæ€§èƒ½åŸºå‡†

| å›¾è§„æ¨¡ | èŠ‚ç‚¹æ•° | åˆ†ç±»å‡†ç¡®ç‡ | å¤„ç†é€Ÿåº¦ | å†…å­˜å ç”¨ |
|--------|--------|-----------|---------|---------|
| **å¤§è§„æ¨¡** | 1000ä¸‡ | 91.5% | 500ä¸‡èŠ‚ç‚¹/å°æ—¶ | 45GB |
| **è¶…å¤§è§„æ¨¡** | 5000ä¸‡ | 90% | 300ä¸‡èŠ‚ç‚¹/å°æ—¶ | 80GB |

### 5.5 Mamba2æ€§èƒ½åŸºå‡†

| åºåˆ—é•¿åº¦ | é¢„æµ‹å‡†ç¡®ç‡ | å¤„ç†é€Ÿåº¦ | é•¿æœŸä¾èµ– |
|---------|-----------|---------|---------|
| **1000** | 85% | 500æ—¶é—´æ­¥/ç§’ | 80% |
| **10,000** | 87% | 1000æ—¶é—´æ­¥/ç§’ | 90% |
| **36,500** | 87% | 800æ—¶é—´æ­¥/ç§’ | 92% |

---

## ğŸ“ **å…­ã€æœ€ä½³å®è·µå¿«é€Ÿå‚è€ƒ / Best Practices Quick Reference**

### 6.1 è®­ç»ƒæœ€ä½³å®è·µ

```python
# âœ… ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()

# âœ… ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 4

# âœ… ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer, T_max=100
)

# âœ… ä½¿ç”¨æ¢¯åº¦è£å‰ª
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

### 6.2 éƒ¨ç½²æœ€ä½³å®è·µ

```python
# âœ… æ¨¡å‹å‹ç¼©
model_quantized = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

# âœ… æ‰¹å¤„ç†æ¨ç†
predictions = model.predict_batch(data, batch_size=64)

# âœ… ç¼“å­˜ç»“æœ
from functools import lru_cache
@lru_cache(maxsize=1000)
def cached_predict(data_hash):
    return model.predict(data)
```

### 6.3 ç›‘æ§æœ€ä½³å®è·µ

```python
# âœ… æ€§èƒ½ç›‘æ§
monitor = PerformanceMonitor()
monitor.start_monitoring()

# âœ… æ—¥å¿—è®°å½•
import logging
logging.basicConfig(level=logging.INFO)

# âœ… æŒ‡æ ‡è®°å½•
import wandb
wandb.log({'loss': loss.item(), 'accuracy': accuracy})
```

---

## ğŸ“š **ä¸ƒã€èµ„æºé“¾æ¥ / Resource Links**

### 7.1 æ–‡æ¡£é“¾æ¥

- [PGTä¸“é¢˜æ–‡æ¡£](docs/01-å›¾è®ºåŸºç¡€/05-é«˜çº§ç†è®º/å›¾é¢„è®­ç»ƒæ¨¡å‹ä¸“é¢˜-2024-2025.md)
- [Emmaä¸“é¢˜æ–‡æ¡£](docs/04-åˆ†å¸ƒå¼ç³»ç»Ÿ/05-é«˜çº§ç†è®º/åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ç³»ç»Ÿä¸“é¢˜-2024-2025.md)
- [GraphGPTä¸“é¢˜æ–‡æ¡£](docs/01-å›¾è®ºåŸºç¡€/05-é«˜çº§ç†è®º/LLMä¸å›¾å­¦ä¹ èåˆä¸“é¢˜-2024-2025.md)
- [GPSä¸“é¢˜æ–‡æ¡£](docs/01-å›¾è®ºåŸºç¡€/05-é«˜çº§ç†è®º/Graph-Transformerä¸“é¢˜-2024-2025.md)
- [Mamba2ä¸“é¢˜æ–‡æ¡£](docs/01-å›¾è®ºåŸºç¡€/05-é«˜çº§ç†è®º/LLMä¸å›¾å­¦ä¹ èåˆä¸“é¢˜-2024-2025.md)

### 7.2 å·¥å…·æ–‡æ¡£

- [æ€§èƒ½è¯„ä¼°æ–‡æ¡£](docs/åº”ç”¨å®è·µæ·±åŒ–-æ€§èƒ½è¯„ä¼°ä¸å¯¹æ¯”åˆ†æ-2025-01.md)
- [éƒ¨ç½²æŒ‡å—](docs/åº”ç”¨å®è·µæ·±åŒ–-å®é™…éƒ¨ç½²æ¡ˆä¾‹ä¸æœ€ä½³å®è·µæŒ‡å—-2025-01.md)
- [æŠ€æœ¯é€‰å‹æŒ‡å—](docs/åº”ç”¨å®è·µæ·±åŒ–-æŠ€æœ¯é€‰å‹æŒ‡å—-2025-01.md)
- [å®æ–½è·¯çº¿å›¾](docs/åº”ç”¨å®è·µæ·±åŒ–-å®æ–½è·¯çº¿å›¾-2025-01.md)
- [æ•…éšœæ’æŸ¥æ‰‹å†Œ](docs/åº”ç”¨å®è·µæ·±åŒ–-æ•…éšœæ’æŸ¥æ‰‹å†Œ-2025-01.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**ç»´æŠ¤è€…**: GraphNetWorkCommunicateé¡¹ç›®ç»„
**çŠ¶æ€**: âœ… å®Œæˆ
