# åº”ç”¨å®è·µæ·±åŒ– - æ•°æ®å‡†å¤‡ä¸å¤„ç†æŒ‡å— / Application Practice Deepening - Data Preparation and Processing Guide

## ğŸ“š **æ¦‚è¿° / Overview**

æœ¬æ–‡æ¡£æä¾›PGTã€Emmaã€GraphGPTã€GPSã€Mamba2äº”ä¸ªä¸“é¢˜çš„æ•°æ®å‡†å¤‡å’Œå¤„ç†æŒ‡å—ï¼ŒåŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¸…æ´—ã€é¢„å¤„ç†å’Œå¢å¼ºæ–¹æ³•ã€‚

**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**çŠ¶æ€**: âœ… æŒç»­æ›´æ–°ä¸­
**ä¼˜å…ˆçº§**: ğŸ”´ P0 - æé«˜ä¼˜å…ˆçº§

---

## ğŸ“Š **ä¸€ã€æ•°æ®æ”¶é›† / Data Collection**

### 1.1 æ•°æ®æ¥æº

**å…¬å¼€æ•°æ®é›†**:

- Cora, Citeseer, PubMed
- OGBæ•°æ®é›†
- çŸ¥è¯†å›¾è°±æ•°æ®é›†
- åˆ†å­æ•°æ®é›†

**è‡ªå»ºæ•°æ®é›†**:

- ä¸šåŠ¡æ•°æ®æ”¶é›†
- æ•°æ®æ ‡æ³¨
- æ•°æ®éªŒè¯

### 1.2 æ•°æ®è´¨é‡è¦æ±‚

**æ•°æ®è´¨é‡æ ‡å‡†**:

- å®Œæ•´æ€§: >95%
- å‡†ç¡®æ€§: >90%
- ä¸€è‡´æ€§: >90%
- æ—¶æ•ˆæ€§: æœ€æ–°æ•°æ®

---

## ğŸ§¹ **äºŒã€æ•°æ®æ¸…æ´— / Data Cleaning**

### 2.1 å¸¸è§é—®é¢˜

**èŠ‚ç‚¹æ•°æ®é—®é¢˜**:

- ç¼ºå¤±å€¼
- å¼‚å¸¸å€¼
- é‡å¤å€¼
- æ ¼å¼ä¸ä¸€è‡´

**è¾¹æ•°æ®é—®é¢˜**:

- è‡ªç¯
- é‡å¤è¾¹
- å­¤ç«‹èŠ‚ç‚¹
- è¾¹æƒé‡å¼‚å¸¸

### 2.2 æ¸…æ´—æ–¹æ³•

```python
# èŠ‚ç‚¹æ•°æ®æ¸…æ´—
def clean_node_data(nodes):
    # ç§»é™¤ç¼ºå¤±å€¼
    nodes = nodes[~torch.isnan(nodes).any(dim=1)]

    # ç§»é™¤å¼‚å¸¸å€¼
    nodes = nodes[nodes.abs().max(dim=1)[0] < 100]

    # å½’ä¸€åŒ–
    nodes = F.normalize(nodes, p=2, dim=1)

    return nodes

# è¾¹æ•°æ®æ¸…æ´—
def clean_edge_data(edges):
    # ç§»é™¤è‡ªç¯
    edges = remove_self_loops(edges)[0]

    # ç§»é™¤é‡å¤è¾¹
    edges = to_undirected(edges)

    return edges
```

---

## ğŸ”„ **ä¸‰ã€æ•°æ®é¢„å¤„ç† / Data Preprocessing**

### 3.1 ç‰¹å¾å·¥ç¨‹

**èŠ‚ç‚¹ç‰¹å¾**:

- åŸå§‹ç‰¹å¾æå–
- ç‰¹å¾å½’ä¸€åŒ–
- ç‰¹å¾é™ç»´
- ç‰¹å¾å¢å¼º

**å›¾ç»“æ„**:

- é‚»æ¥çŸ©é˜µæ„å»º
- åº¦ä¸­å¿ƒæ€§è®¡ç®—
- ç¤¾åŒºæ£€æµ‹
- å­å›¾æå–

### 3.2 æ•°æ®è½¬æ¢

```python
# å›¾æ•°æ®è½¬æ¢
from torch_geometric.data import Data

def create_graph_data(node_features, edge_index, labels):
    graph = Data(
        x=node_features,
        edge_index=edge_index,
        y=labels
    )
    return graph

# åºåˆ—æ•°æ®è½¬æ¢ï¼ˆGraphGPTï¼‰
def graph_to_sequence(graph, method='bfs'):
    sequencer = GraphSequencer(method=method)
    sequence = sequencer.sequence_graph(graph)
    return sequence
```

---

## ğŸ“ˆ **å››ã€æ•°æ®å¢å¼º / Data Augmentation**

### 4.1 å›¾æ•°æ®å¢å¼º

**èŠ‚ç‚¹å¢å¼º**:

```python
# èŠ‚ç‚¹ç‰¹å¾å¢å¼º
def augment_node_features(graph, noise_std=0.1):
    graph.x += torch.randn_like(graph.x) * noise_std
    return graph

# èŠ‚ç‚¹åˆ é™¤
def node_dropout(graph, dropout_rate=0.1):
    num_nodes = graph.num_nodes
    keep_nodes = torch.randperm(num_nodes)[:int(num_nodes * (1 - dropout_rate))]
    return subgraph(keep_nodes, graph)
```

**è¾¹å¢å¼º**:

```python
# è¾¹æ·»åŠ 
def add_random_edges(graph, ratio=0.1):
    num_edges = graph.edge_index.size(1)
    num_new_edges = int(num_edges * ratio)
    new_edges = torch.randint(0, graph.num_nodes, (2, num_new_edges))
    graph.edge_index = torch.cat([graph.edge_index, new_edges], dim=1)
    return graph

# è¾¹åˆ é™¤
def edge_dropout(graph, dropout_rate=0.1):
    num_edges = graph.edge_index.size(1)
    keep_edges = torch.randperm(num_edges)[:int(num_edges * (1 - dropout_rate))]
    graph.edge_index = graph.edge_index[:, keep_edges]
    return graph
```

### 4.2 æ—¶åºæ•°æ®å¢å¼º

**åºåˆ—å¢å¼º**:

```python
# æ—¶é—´æ‰­æ›²
def time_warp(sequence, sigma=0.2):
    # æ·»åŠ æ—¶é—´æ‰­æ›²
    warp = torch.randn(len(sequence)) * sigma
    warped_sequence = sequence + warp
    return warped_sequence

# çª—å£åˆ‡ç‰‡
def window_slice(sequence, window_size=100):
    start = torch.randint(0, len(sequence) - window_size, (1,))
    return sequence[start:start+window_size]
```

---

## ğŸ—‚ï¸ **äº”ã€æ•°æ®å­˜å‚¨ / Data Storage**

### 5.1 å­˜å‚¨æ ¼å¼

**å›¾æ•°æ®å­˜å‚¨**:

- PyTorch Geometricæ ¼å¼
- NetworkXæ ¼å¼
- é‚»æ¥çŸ©é˜µæ ¼å¼
- è¾¹åˆ—è¡¨æ ¼å¼

**åºåˆ—æ•°æ®å­˜å‚¨**:

- NumPyæ•°ç»„
- PyTorchå¼ é‡
- HDF5æ ¼å¼
- Parquetæ ¼å¼

### 5.2 æ•°æ®ç®¡ç†

```python
# æ•°æ®ç‰ˆæœ¬ç®¡ç†
import pickle
from pathlib import Path

def save_data(data, version='v1.0'):
    path = Path(f'data/{version}/graph_data.pt')
    path.parent.mkdir(parents=True, exist_ok=True)
    torch.save(data, path)

def load_data(version='v1.0'):
    path = Path(f'data/{version}/graph_data.pt')
    return torch.load(path)
```

---

## ğŸ” **å…­ã€æ•°æ®éªŒè¯ / Data Validation**

### 6.1 æ•°æ®æ£€æŸ¥

```python
def validate_graph_data(graph):
    """éªŒè¯å›¾æ•°æ®"""
    issues = []

    # æ£€æŸ¥èŠ‚ç‚¹ç‰¹å¾
    if torch.isnan(graph.x).any():
        issues.append("èŠ‚ç‚¹ç‰¹å¾åŒ…å«NaNå€¼")

    # æ£€æŸ¥è¾¹ç´¢å¼•
    if graph.edge_index.max() >= graph.num_nodes:
        issues.append("è¾¹ç´¢å¼•è¶…å‡ºèŠ‚ç‚¹èŒƒå›´")

    # æ£€æŸ¥æ ‡ç­¾
    if graph.y is not None and len(graph.y) != graph.num_nodes:
        issues.append("æ ‡ç­¾æ•°é‡ä¸åŒ¹é…")

    return issues
```

### 6.2 æ•°æ®ç»Ÿè®¡

```python
def compute_data_statistics(dataset):
    """è®¡ç®—æ•°æ®ç»Ÿè®¡"""
    stats = {
        'num_graphs': len(dataset),
        'avg_num_nodes': np.mean([g.num_nodes for g in dataset]),
        'avg_num_edges': np.mean([g.num_edges for g in dataset]),
        'num_features': dataset[0].x.size(1),
        'num_classes': len(torch.unique(dataset[0].y))
    }
    return stats
```

---

## ğŸ“ **ä¸ƒã€ä¸“é¢˜ç‰¹å®šæ•°æ®å¤„ç† / Topic-Specific Data Processing**

### 7.1 PGTæ•°æ®å‡†å¤‡

**é¢„è®­ç»ƒæ•°æ®**:

- å¤§è§„æ¨¡æ— æ ‡æ³¨å›¾æ•°æ®
- å¤šé¢†åŸŸæ•°æ®æ··åˆ
- æ•°æ®å¹³è¡¡

**ä¸‹æ¸¸ä»»åŠ¡æ•°æ®**:

- ä»»åŠ¡ç‰¹å®šæ ‡æ³¨
- æ•°æ®åˆ’åˆ†ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰

### 7.2 Emmaæ•°æ®å‡†å¤‡

**åˆ†å¸ƒå¼æ•°æ®**:

- å›¾åˆ†å—
- æ•°æ®åˆ†ç‰‡
- è´Ÿè½½å¹³è¡¡

### 7.3 GraphGPTæ•°æ®å‡†å¤‡

**ç”Ÿæˆæ•°æ®**:

- å›¾åºåˆ—åŒ–
- åºåˆ—æ ‡æ³¨
- æ¡ä»¶ä¿¡æ¯

### 7.4 GPSæ•°æ®å‡†å¤‡

**å¤§è§„æ¨¡å›¾æ•°æ®**:

- å›¾åˆ†å—
- ç‰¹å¾å½’ä¸€åŒ–
- å†…å­˜ä¼˜åŒ–

### 7.5 Mamba2æ•°æ®å‡†å¤‡

**æ—¶åºæ•°æ®**:

- åºåˆ—å¯¹é½
- æ—¶é—´æˆ³å¤„ç†
- é•¿æœŸä¾èµ–æ„å»º

---

## ğŸ“Š **å…«ã€æ•°æ®ç®¡é“ / Data Pipeline**

### 8.1 å®Œæ•´æ•°æ®ç®¡é“

```python
class DataPipeline:
    """æ•°æ®ç®¡é“"""

    def __init__(self):
        self.steps = []

    def add_step(self, step):
        self.steps.append(step)

    def process(self, data):
        for step in self.steps:
            data = step(data)
        return data

# ä½¿ç”¨ç¤ºä¾‹
pipeline = DataPipeline()
pipeline.add_step(clean_node_data)
pipeline.add_step(normalize_features)
pipeline.add_step(augment_graph)
processed_data = pipeline.process(raw_data)
```

---

## ğŸ“ **ä¹ã€æœ€ä½³å®è·µ / Best Practices**

### 9.1 æ•°æ®å‡†å¤‡æ£€æŸ¥æ¸…å•

- [ ] æ•°æ®æ”¶é›†å®Œæˆ
- [ ] æ•°æ®æ¸…æ´—å®Œæˆ
- [ ] æ•°æ®é¢„å¤„ç†å®Œæˆ
- [ ] æ•°æ®å¢å¼ºå®Œæˆ
- [ ] æ•°æ®éªŒè¯é€šè¿‡
- [ ] æ•°æ®å­˜å‚¨å®Œæˆ
- [ ] æ•°æ®ç»Ÿè®¡è®¡ç®—

### 9.2 æ•°æ®è´¨é‡ä¿è¯

1. **å®Œæ•´æ€§**: æ£€æŸ¥ç¼ºå¤±å€¼
2. **å‡†ç¡®æ€§**: éªŒè¯æ•°æ®æ­£ç¡®æ€§
3. **ä¸€è‡´æ€§**: ç»Ÿä¸€æ•°æ®æ ¼å¼
4. **æ—¶æ•ˆæ€§**: ä½¿ç”¨æœ€æ–°æ•°æ®

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**çŠ¶æ€**: âœ… å®Œæˆ
