# åº”ç”¨å®è·µæ·±åŒ– - æ¨¡å‹è¯„ä¼°ä¸éªŒè¯æŒ‡å— / Application Practice Deepening - Model Evaluation and Validation Guide

## ğŸ“š **æ¦‚è¿° / Overview**

æœ¬æ–‡æ¡£æä¾›PGTã€NSDI 2025åˆ†å¸ƒå¼ç³»ç»Ÿï¼ˆArmadaã€RapidGNNã€D3-GNNã€E2E-GRecã€TD-Orchã€GeoLayerï¼‰ã€LLM-å›¾èåˆï¼ˆGRAPHGPT-Oã€GL-Fusionã€Hybrid-LLM-GNNã€GLANCEï¼‰ã€GPSæ¶æ„ï¼ˆAnchorGTã€DHIL-GTï¼‰ã€Mamba2ç­‰ä¸“é¢˜çš„æ¨¡å‹è¯„ä¼°å’ŒéªŒè¯æŒ‡å—ï¼ŒåŒ…æ‹¬è¯„ä¼°æŒ‡æ ‡ã€éªŒè¯æ–¹æ³•å’Œæœ€ä½³å®è·µã€‚

**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**çŠ¶æ€**: âœ… æŒç»­æ›´æ–°ä¸­
**ä¼˜å…ˆçº§**: ğŸ”´ P0 - æé«˜ä¼˜å…ˆçº§
**æœ€æ–°æ›´æ–°**: 2025å¹´1æœˆ - æ•´åˆNSDI 2025æœ€æ–°ç³»ç»Ÿè¯„ä¼°æŒ‡æ ‡

---

## ğŸ“Š **ä¸€ã€è¯„ä¼°æŒ‡æ ‡ / Evaluation Metrics**

### 1.1 åˆ†ç±»ä»»åŠ¡æŒ‡æ ‡

**å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**:

```python
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_true, y_pred)
```

**F1åˆ†æ•°ï¼ˆF1-Scoreï¼‰**:

```python
from sklearn.metrics import f1_score
f1 = f1_score(y_true, y_pred, average='macro')
```

**AUC-ROC**:

```python
from sklearn.metrics import roc_auc_score
auc = roc_auc_score(y_true, y_scores)
```

### 1.2 å›å½’ä»»åŠ¡æŒ‡æ ‡

**å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**:

```python
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_true, y_pred)
```

**å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰**:

```python
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_true, y_pred)
```

**RÂ²åˆ†æ•°**:

```python
from sklearn.metrics import r2_score
r2 = r2_score(y_true, y_pred)
```

### 1.3 é“¾æ¥é¢„æµ‹æŒ‡æ ‡

**Hits@K**:

```python
def hits_at_k(y_true, y_scores, k=10):
    sorted_indices = torch.argsort(y_scores, descending=True)
    top_k = sorted_indices[:k]
    hits = (y_true[top_k] == 1).sum().item()
    return hits / k
```

**MRRï¼ˆMean Reciprocal Rankï¼‰**:

```python
def mrr(y_true, y_scores):
    sorted_indices = torch.argsort(y_scores, descending=True)
    rank = (sorted_indices == y_true.argmax()).nonzero()[0].item() + 1
    return 1.0 / rank
```

### 1.4 å›¾ç”ŸæˆæŒ‡æ ‡

**æœ‰æ•ˆæ€§ï¼ˆValidityï¼‰**:

```python
def validity(generated_graphs):
    valid_count = sum(1 for g in generated_graphs if is_valid_graph(g))
    return valid_count / len(generated_graphs)
```

**å”¯ä¸€æ€§ï¼ˆUniquenessï¼‰**:

```python
def uniqueness(generated_graphs):
    unique_graphs = set([graph_to_hash(g) for g in generated_graphs])
    return len(unique_graphs) / len(generated_graphs)
```

**æ–°é¢–æ€§ï¼ˆNoveltyï¼‰**:

```python
def novelty(generated_graphs, training_graphs):
    training_hashes = set([graph_to_hash(g) for g in training_graphs])
    generated_hashes = set([graph_to_hash(g) for g in generated_graphs])
    novel_count = len(generated_hashes - training_hashes)
    return novel_count / len(generated_graphs)
```

---

## ğŸ”¬ **äºŒã€éªŒè¯æ–¹æ³• / Validation Methods**

### 2.1 äº¤å‰éªŒè¯

**KæŠ˜äº¤å‰éªŒè¯**:

```python
from sklearn.model_selection import KFold

kfold = KFold(n_splits=5, shuffle=True)
for train_idx, val_idx in kfold.split(dataset):
    train_data = dataset[train_idx]
    val_data = dataset[val_idx]
    # è®­ç»ƒå’Œè¯„ä¼°
```

**æ—¶é—´åºåˆ—äº¤å‰éªŒè¯**:

```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
for train_idx, val_idx in tscv.split(dataset):
    train_data = dataset[train_idx]
    val_data = dataset[val_idx]
    # è®­ç»ƒå’Œè¯„ä¼°
```

### 2.2 ç•™å‡ºæ³•

```python
# æ•°æ®åˆ’åˆ†
train_size = int(0.8 * len(dataset))
val_size = int(0.1 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_data, val_data, test_data = torch.utils.data.random_split(
    dataset, [train_size, val_size, test_size]
)
```

### 2.3 è‡ªåŠ©æ³•

```python
from sklearn.utils import resample

def bootstrap_validation(dataset, n_iterations=100):
    scores = []
    for _ in range(n_iterations):
        bootstrap_sample = resample(dataset)
        score = evaluate_model(model, bootstrap_sample)
        scores.append(score)
    return np.mean(scores), np.std(scores)
```

---

## ğŸ“ˆ **ä¸‰ã€æ€§èƒ½è¯„ä¼° / Performance Evaluation**

### 3.1 è®­ç»ƒæ€§èƒ½

**è®­ç»ƒæ—¶é—´**:

```python
import time

start_time = time.time()
train_model(model, train_data)
training_time = time.time() - start_time
```

**å†…å­˜å ç”¨**:

```python
import torch

def get_memory_usage():
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        return allocated, reserved
```

**GPUåˆ©ç”¨ç‡**:

```python
import GPUtil

gpus = GPUtil.getGPUs()
for gpu in gpus:
    print(f"GPU {gpu.id}: {gpu.load * 100}%")
```

### 3.2 æ¨ç†æ€§èƒ½

**æ¨ç†å»¶è¿Ÿ**:

```python
import time

model.eval()
times = []
with torch.no_grad():
    for batch in test_loader:
        start = time.time()
        _ = model(batch)
        torch.cuda.synchronize()
        elapsed = time.time() - start
        times.append(elapsed)

avg_latency = np.mean(times)
```

**ååé‡**:

```python
throughput = len(test_dataset) / sum(times)
```

---

## ğŸ¯ **å››ã€ä¸“é¢˜ç‰¹å®šè¯„ä¼° / Topic-Specific Evaluation**

### 4.1 PGTè¯„ä¼°

**é¢„è®­ç»ƒè¯„ä¼°**:

- é¢„è®­ç»ƒæŸå¤±
- ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½
- è¿ç§»å­¦ä¹ æ•ˆæœ

**ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°**:

- èŠ‚ç‚¹åˆ†ç±»å‡†ç¡®ç‡
- å›¾åˆ†ç±»å‡†ç¡®ç‡
- é“¾æ¥é¢„æµ‹Hits@K

### 4.2 Emmaè¯„ä¼°

**åˆ†å¸ƒå¼è®­ç»ƒè¯„ä¼°**:

- è®­ç»ƒé€Ÿåº¦
- é€šä¿¡å¼€é”€
- èµ„æºåˆ©ç”¨ç‡
- å¯æ‰©å±•æ€§

### 4.3 GraphGPTè¯„ä¼°

**ç”Ÿæˆè´¨é‡è¯„ä¼°**:

- æœ‰æ•ˆæ€§
- å”¯ä¸€æ€§
- æ–°é¢–æ€§
- æ€§è´¨åŒ¹é…ç‡

### 4.4 GPSè¯„ä¼°

**å¤§è§„æ¨¡å¤„ç†è¯„ä¼°**:

- å¤„ç†é€Ÿåº¦
- å†…å­˜å ç”¨
- åˆ†ç±»å‡†ç¡®ç‡
- å¯æ‰©å±•æ€§

### 4.5 Mamba2è¯„ä¼°

**æ—¶åºé¢„æµ‹è¯„ä¼°**:

- é¢„æµ‹å‡†ç¡®ç‡
- é•¿æœŸä¾èµ–æ•æ‰
- å¤„ç†é€Ÿåº¦
- åºåˆ—é•¿åº¦æ”¯æŒ

---

## ğŸ“Š **äº”ã€è¯„ä¼°æŠ¥å‘Š / Evaluation Report**

### 5.1 æŠ¥å‘Šæ¨¡æ¿

```python
class EvaluationReport:
    """è¯„ä¼°æŠ¥å‘Š"""

    def __init__(self):
        self.metrics = {}
        self.performance = {}
        self.comparison = {}

    def add_metric(self, name, value):
        self.metrics[name] = value

    def add_performance(self, name, value):
        self.performance[name] = value

    def generate_report(self):
        report = {
            'metrics': self.metrics,
            'performance': self.performance,
            'comparison': self.comparison
        }
        return report
```

### 5.2 å¯è§†åŒ–

```python
import matplotlib.pyplot as plt

def plot_training_curve(train_losses, val_losses):
    plt.plot(train_losses, label='Train')
    plt.plot(val_losses, label='Validation')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

def plot_confusion_matrix(y_true, y_pred):
    from sklearn.metrics import confusion_matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.colorbar()
    plt.show()
```

---

## ğŸ“ **å…­ã€æœ€ä½³å®è·µ / Best Practices**

### 6.1 è¯„ä¼°æ£€æŸ¥æ¸…å•

- [ ] é€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡
- [ ] ä½¿ç”¨äº¤å‰éªŒè¯
- [ ] è¯„ä¼°è®­ç»ƒå’Œæ¨ç†æ€§èƒ½
- [ ] ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
- [ ] å¯è§†åŒ–ç»“æœ
- [ ] å¯¹æ¯”åŸºçº¿æ–¹æ³•

### 6.2 è¯„ä¼°å»ºè®®

1. **å¤šæŒ‡æ ‡è¯„ä¼°**: ä½¿ç”¨å¤šä¸ªæŒ‡æ ‡å…¨é¢è¯„ä¼°
2. **äº¤å‰éªŒè¯**: ä½¿ç”¨äº¤å‰éªŒè¯ä¿è¯ç¨³å®šæ€§
3. **æ€§èƒ½è¯„ä¼°**: è¯„ä¼°è®­ç»ƒå’Œæ¨ç†æ€§èƒ½
4. **å¯¹æ¯”åˆ†æ**: ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”

---

## ğŸ“Š **äº”ã€NSDI 2025åˆ†å¸ƒå¼ç³»ç»Ÿè¯„ä¼°æŒ‡æ ‡ / NSDI 2025 Distributed Systems Evaluation Metrics**

### 5.1 Armadaè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **åŠ é€Ÿæ¯”**: 4.5xï¼ˆç›¸æ¯”ä¼ ç»Ÿåˆ†å¸ƒå¼è®­ç»ƒï¼‰
- **å†…å­˜èŠ‚çœ**: 60%
- **é€šä¿¡å¼€é”€å‡å°‘**: 45%
- **æˆæœ¬èŠ‚çœ**: 40-50%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_armada_performance(baseline_time, armada_time, baseline_memory, armada_memory):
    speedup = baseline_time / armada_time
    memory_saving = (baseline_memory - armada_memory) / baseline_memory
    return {
        'speedup': speedup,
        'memory_saving': memory_saving,
        'cost_saving': 0.4 + 0.1 * speedup  # ä¼°ç®—
    }
```

### 5.2 RapidGNNè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **è®­ç»ƒååé‡æå‡**: 2-3x
- **èƒ½æºæ¶ˆè€—å‡å°‘**: 40%
- **é€šä¿¡å¼€é”€å‡å°‘**: 50%
- **æˆæœ¬èŠ‚çœ**: 35-45%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_rapidgnn_performance(baseline_throughput, rapidgnn_throughput, baseline_energy, rapidgnn_energy):
    throughput_improvement = rapidgnn_throughput / baseline_throughput
    energy_saving = (baseline_energy - rapidgnn_energy) / baseline_energy
    return {
        'throughput_improvement': throughput_improvement,
        'energy_saving': energy_saving
    }
```

### 5.3 D3-GNNè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **å¤„ç†ååé‡æå‡**: 76xï¼ˆç›¸æ¯”æ‰¹å¤„ç†ï¼‰
- **å»¶è¿Ÿ**: ç§’çº§ï¼ˆä»å°æ—¶çº§é™ä½ï¼‰
- **å†…å­˜å ç”¨å‡å°‘**: 80%
- **æˆæœ¬èŠ‚çœ**: 45-55%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_d3gnn_performance(batch_latency, streaming_latency, batch_memory, streaming_memory):
    latency_reduction = batch_latency / streaming_latency
    memory_saving = (batch_memory - streaming_memory) / batch_memory
    return {
        'latency_reduction': latency_reduction,
        'memory_saving': memory_saving,
        'real_time_capability': streaming_latency < 10  # ç§’çº§
    }
```

### 5.4 E2E-GRecè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **è®­ç»ƒæ•ˆç‡æå‡**: 3.5x
- **æ¨èå‡†ç¡®ç‡æå‡**: +12%ï¼ˆNDCG@10ï¼‰
- **å­˜å‚¨æˆæœ¬å‡å°‘**: 40%
- **æˆæœ¬èŠ‚çœ**: 30-40%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_e2egrec_performance(baseline_ndcg, e2egrec_ndcg, baseline_storage, e2egrec_storage):
    accuracy_improvement = e2egrec_ndcg - baseline_ndcg
    storage_saving = (baseline_storage - e2egrec_storage) / baseline_storage
    return {
        'accuracy_improvement': accuracy_improvement,
        'storage_saving': storage_saving
    }
```

### 5.5 TD-Orchè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **å¹³å‡åŠ é€Ÿ**: 4.1x
- **èµ„æºåˆ©ç”¨ç‡æå‡**: 60%
- **å†…å­˜èŠ‚çœ**: 50%
- **æˆæœ¬èŠ‚çœ**: 40-50%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_tdorch_performance(baseline_time, tdorch_time, baseline_utilization, tdorch_utilization):
    speedup = baseline_time / tdorch_time
    utilization_improvement = tdorch_utilization - baseline_utilization
    return {
        'speedup': speedup,
        'utilization_improvement': utilization_improvement
    }
```

### 5.6 GeoLayerè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **åœ¨çº¿å“åº”æ—¶é—´æå‡**: 3.67x
- **è·¨åŒºåŸŸå»¶è¿Ÿå‡å°‘**: 70%
- **å†…å­˜èŠ‚çœ**: 55%
- **æˆæœ¬èŠ‚çœ**: 30-40%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_geolayer_performance(baseline_latency, geolayer_latency, baseline_cross_region, geolayer_cross_region):
    latency_improvement = baseline_latency / geolayer_latency
    cross_region_reduction = (baseline_cross_region - geolayer_cross_region) / baseline_cross_region
    return {
        'latency_improvement': latency_improvement,
        'cross_region_reduction': cross_region_reduction
    }
```

---

## ğŸ“Š **å…­ã€LLM-å›¾èåˆæ¨¡å‹è¯„ä¼°æŒ‡æ ‡ / LLM-Graph Fusion Models Evaluation Metrics**

### 6.1 GRAPHGPT-Oè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **é—®ç­”å‡†ç¡®ç‡æå‡**: +18%
- **å¤šæ¨¡æ€ç†è§£èƒ½åŠ›**: æ˜¾è‘—æå‡
- **ç”Ÿæˆè´¨é‡**: æ–‡æœ¬å’Œå›¾åƒè´¨é‡æå‡20%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_graphgpto_performance(baseline_accuracy, graphgpto_accuracy, baseline_multimodal, graphgpto_multimodal):
    accuracy_improvement = graphgpto_accuracy - baseline_accuracy
    multimodal_improvement = graphgpto_multimodal - baseline_multimodal
    return {
        'accuracy_improvement': accuracy_improvement,
        'multimodal_improvement': multimodal_improvement
    }
```

### 6.2 GL-Fusionè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **è¡¥å…¨å‡†ç¡®ç‡æå‡**: +20%ï¼ˆHit@10ï¼‰
- **æ–‡æœ¬ç†è§£æå‡**: +18%
- **æ¨ç†èƒ½åŠ›æå‡**: +15%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_glfusion_performance(baseline_hit10, glfusion_hit10, baseline_text, glfusion_text):
    hit10_improvement = glfusion_hit10 - baseline_hit10
    text_improvement = glfusion_text - baseline_text
    return {
        'hit10_improvement': hit10_improvement,
        'text_improvement': text_improvement
    }
```

### 6.3 Hybrid-LLM-GNNè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **é¢„æµ‹å‡†ç¡®ç‡æå‡**: +22%
- **å¯è§£é‡Šæ€§**: æ˜¾è‘—æå‡ï¼ˆç‰¹å¾é‡è¦æ€§åˆ†æï¼‰
- **è·¨åŸŸè¿ç§»**: +18%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_hybridllmgnn_performance(baseline_accuracy, hybrid_accuracy, explainability_score):
    accuracy_improvement = hybrid_accuracy - baseline_accuracy
    return {
        'accuracy_improvement': accuracy_improvement,
        'explainability_score': explainability_score
    }
```

### 6.4 GLANCEè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **æ¨èå‡†ç¡®ç‡æå‡**: +16%ï¼ˆNDCG@10ï¼‰
- **å¼‚é…èŠ‚ç‚¹å¤„ç†æå‡**: +25%
- **è®¡ç®—æ•ˆç‡æå‡**: +30%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_glance_performance(baseline_ndcg, glance_ndcg, baseline_hetero, glance_hetero):
    ndcg_improvement = glance_ndcg - baseline_ndcg
    hetero_improvement = glance_hetero - baseline_hetero
    return {
        'ndcg_improvement': ndcg_improvement,
        'hetero_improvement': hetero_improvement
    }
```

---

## ğŸ“Š **ä¸ƒã€GPSæ¶æ„æœ€æ–°è¿›å±•è¯„ä¼°æŒ‡æ ‡ / GPS Architecture Latest Advances Evaluation Metrics**

### 7.1 AnchorGTè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **è®­ç»ƒé€Ÿåº¦æå‡**: 2-3x
- **å†…å­˜å ç”¨å‡å°‘**: 50%
- **åˆ†ç±»å‡†ç¡®ç‡æå‡**: +5%
- **æˆæœ¬èŠ‚çœ**: 35-45%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_anchorgt_performance(baseline_time, anchorgt_time, baseline_memory, anchorgt_memory, baseline_acc, anchorgt_acc):
    speedup = baseline_time / anchorgt_time
    memory_saving = (baseline_memory - anchorgt_memory) / baseline_memory
    accuracy_improvement = anchorgt_acc - baseline_acc
    return {
        'speedup': speedup,
        'memory_saving': memory_saving,
        'accuracy_improvement': accuracy_improvement
    }
```

### 7.2 DHIL-GTè¯„ä¼°æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:

- **æ£€ç´¢é€Ÿåº¦æå‡**: 3-4x
- **æ£€ç´¢å‡†ç¡®ç‡æå‡**: +12%
- **å†…å­˜å ç”¨å‡å°‘**: 60%
- **æˆæœ¬èŠ‚çœ**: 40-50%

**è¯„ä¼°æ–¹æ³•**:

```python
def evaluate_dhilgt_performance(baseline_retrieval_time, dhilgt_retrieval_time, baseline_retrieval_acc, dhilgt_retrieval_acc):
    retrieval_speedup = baseline_retrieval_time / dhilgt_retrieval_time
    retrieval_improvement = dhilgt_retrieval_acc - baseline_retrieval_acc
    return {
        'retrieval_speedup': retrieval_speedup,
        'retrieval_improvement': retrieval_improvement
    }
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0
**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ - æ•´åˆNSDI 2025æœ€æ–°ç³»ç»Ÿè¯„ä¼°æŒ‡æ ‡
**çŠ¶æ€**: âœ… å®Œæˆ
