# æ“ä½œç³»ç»Ÿåº”ç”¨æ¨¡å¼å·¥å…·é›†æˆæŒ‡å— / OS Application Patterns Tools Integration Guide

## ğŸ“š **æ¦‚è¿° / Overview**

**æ–‡æ¡£ç›®çš„**: æä¾›æ“ä½œç³»ç»Ÿé¢†åŸŸåº”ç”¨æ¨¡å¼çš„å®Œæ•´å·¥å…·é›†æˆæŒ‡å—ï¼ŒåŒ…æ‹¬Petriç½‘ã€åŠ¨æ€å›¾è®ºã€æ‹“æ‰‘æ¨¡å‹ç›¸å…³å·¥å…·çš„å®‰è£…ã€é…ç½®ã€é›†æˆå’Œä½¿ç”¨æ–¹æ³•ã€‚

**é€‚ç”¨å¯¹è±¡**: æ“ä½œç³»ç»Ÿå¼€å‘è€…ã€ç³»ç»Ÿæ¶æ„å¸ˆã€å¹¶å‘ç³»ç»Ÿç ”ç©¶äººå‘˜

**ç›¸å…³æ–‡æ¡£**:

- [æ“ä½œç³»ç»Ÿåº”ç”¨æ¨¡å¼æ¸…å•](æ“ä½œç³»ç»Ÿåº”ç”¨æ¨¡å¼æ¸…å•.md)
- [å®ç°æŒ‡å—](02-å®ç°æŒ‡å—.md)
- [å·¥å…·é›†æˆä¸é…ç½®æŒ‡å—](../å·¥å…·é›†æˆä¸é…ç½®æŒ‡å—.md)

---

## ğŸ¯ **ä¸€ã€Petriç½‘å·¥å…·é›†æˆ / Part 1: Petri Net Tools Integration**

### 1.1 CPN Toolsé›†æˆ

**å®‰è£…**:

```bash
# ä¸‹è½½CPN Tools
wget https://cpntools.org/download/cpntools-installer.jar

# å®‰è£…Javaï¼ˆå¦‚æœæœªå®‰è£…ï¼‰
sudo apt-get install openjdk-11-jdk  # Ubuntu/Debian
brew install openjdk@11              # macOS

# è¿è¡Œå®‰è£…ç¨‹åº
java -jar cpntools-installer.jar
```

**é…ç½®**:

```bash
# ç¯å¢ƒå˜é‡é…ç½®
export CPNTOOLS_HOME=/opt/cpntools
export PATH=$PATH:$CPNTOOLS_HOME/bin
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64

# éªŒè¯å®‰è£…
cpntools --version
```

**Pythoné›†æˆ**:

```python
import subprocess
import os
from pathlib import Path

class CPNToolsIntegration:
    def __init__(self, cpn_tools_path=None):
        self.cpn_tools_path = cpn_tools_path or os.environ.get('CPNTOOLS_HOME')
        if not self.cpn_tools_path:
            raise ValueError("CPN Toolsè·¯å¾„æœªè®¾ç½®")

    def simulate_model(self, model_file: str, output_file: str = None):
        """
        ä»¿çœŸCPNæ¨¡å‹
        """
        cmd = [
            os.path.join(self.cpn_tools_path, 'bin', 'cpntools'),
            '-simulate',
            model_file
        ]

        if output_file:
            cmd.extend(['-output', output_file])

        result = subprocess.run(cmd, capture_output=True, text=True)
        return {
            'success': result.returncode == 0,
            'stdout': result.stdout,
            'stderr': result.stderr
        }

    def verify_deadlock(self, model_file: str) -> bool:
        """
        éªŒè¯æ¨¡å‹æ˜¯å¦å­˜åœ¨æ­»é”
        """
        cmd = [
            os.path.join(self.cpn_tools_path, 'bin', 'cpntools'),
            '-verify',
            '-deadlock',
            model_file
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        return 'No deadlock' in result.stdout
```

### 1.2 TLA+é›†æˆ

**å®‰è£…**:

```bash
# ä¸‹è½½TLA+ Toolbox
wget https://github.com/tlaplus/tlaplus/releases/latest/download/TLAToolbox-linux.gtk.x86_64.zip

# è§£å‹
unzip TLAToolbox-linux.gtk.x86_64.zip -d /opt/tlaplus

# é…ç½®ç¯å¢ƒå˜é‡
export TLA_PATH=/opt/tlaplus
export PATH=$PATH:$TLA_PATH
```

**Pythoné›†æˆ**:

```python
import subprocess
import json

class TLAIntegration:
    def __init__(self, tla_path=None):
        self.tla_path = tla_path or os.environ.get('TLA_PATH')
        if not self.tla_path:
            raise ValueError("TLA+è·¯å¾„æœªè®¾ç½®")

    def verify_spec(self, spec_file: str, config_file: str = None):
        """
        éªŒè¯TLA+è§„èŒƒ
        """
        cmd = [
            os.path.join(self.tla_path, 'tlc'),
            spec_file
        ]

        if config_file:
            cmd.extend(['-config', config_file])

        result = subprocess.run(cmd, capture_output=True, text=True)

        return {
            'success': result.returncode == 0,
            'output': result.stdout,
            'errors': result.stderr
        }

    def check_invariants(self, spec_file: str, invariants: list):
        """
        æ£€æŸ¥ä¸å˜é‡
        """
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        config_content = f"INIT Init\nNEXT Next\n"
        for inv in invariants:
            config_content += f"INVARIANT {inv}\n"

        with open('temp.cfg', 'w') as f:
            f.write(config_content)

        result = self.verify_spec(spec_file, 'temp.cfg')
        os.remove('temp.cfg')

        return result
```

### 1.3 GreatSPNé›†æˆ

**å®‰è£…**:

```bash
# ä¸‹è½½GreatSPN
wget http://www.di.unito.it/~greatspn/SOURCES/GreatSPN.tar.gz

# è§£å‹å¹¶ç¼–è¯‘
tar -xzf GreatSPN.tar.gz
cd GreatSPN
make
sudo make install
```

---

## ğŸ”§ **äºŒã€åŠ¨æ€å›¾è®ºå·¥å…·é›†æˆ / Part 2: Dynamic Graph Tools Integration**

### 2.1 NetworkXé›†æˆ

**å®‰è£…**:

```bash
pip install networkx matplotlib numpy scipy
```

**é…ç½®**:

```python
import networkx as nx
import numpy as np

# é…ç½®NetworkX
nx.config.use_cache = True
nx.config.cache_size = 1000

class OSGraphAnalyzer:
    def __init__(self):
        self.graph = nx.DiGraph()
        self.lock_dependencies = {}

    def add_lock_sequence(self, thread_id: int, locks: list):
        """
        æ·»åŠ é”è·å–åºåˆ—
        """
        for i in range(len(locks) - 1):
            self.graph.add_edge(locks[i], locks[i+1],
                              thread=thread_id, timestamp=i)

    def detect_deadlock_cycle(self) -> list:
        """
        æ£€æµ‹æ­»é”å¾ªç¯
        """
        try:
            cycles = list(nx.simple_cycles(self.graph))
            return cycles
        except nx.NetworkXError:
            return []

    def validate_lock_order(self) -> dict:
        """
        éªŒè¯é”é¡ºåºä¸€è‡´æ€§
        """
        violations = []

        # æ£€æµ‹å¾ªç¯
        cycles = self.detect_deadlock_cycle()
        if cycles:
            violations.append({
                'type': 'cycle',
                'cycles': cycles
            })

        # æ£€æŸ¥å…¨å±€é¡ºåºä¸€è‡´æ€§
        for edge in self.graph.edges(data=True):
            lock1, lock2 = edge[0], edge[1]
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åå‘è¾¹
            if self.graph.has_edge(lock2, lock1):
                violations.append({
                    'type': 'order_violation',
                    'locks': [lock1, lock2]
                })

        return {
            'is_valid': len(violations) == 0,
            'violations': violations
        }
```

### 2.2 Neo4jé›†æˆ

**å®‰è£…**:

```bash
# ä¸‹è½½Neo4j Community Edition
wget https://neo4j.com/artifact.php?name=neo4j-community-5.15.0-unix.tar.gz

# è§£å‹
tar -xzf neo4j-community-5.15.0-unix.tar.gz
cd neo4j-community-5.15.0

# é…ç½®
vim conf/neo4j.conf
# è®¾ç½®: dbms.default_listen_address=0.0.0.0

# å¯åŠ¨
./bin/neo4j start
```

**Pythoné›†æˆ**:

```python
from neo4j import GraphDatabase

class OSNeo4jIntegration:
    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def store_lock_graph(self, graph: nx.DiGraph):
        """
        å­˜å‚¨é”ä¾èµ–å›¾åˆ°Neo4j
        """
        with self.driver.session() as session:
            # åˆ›å»ºèŠ‚ç‚¹
            for node in graph.nodes():
                session.run(
                    "MERGE (l:Lock {id: $id})",
                    id=node
                )

            # åˆ›å»ºè¾¹
            for source, target, data in graph.edges(data=True):
                session.run(
                    "MATCH (a:Lock {id: $source}), (b:Lock {id: $target}) "
                    "MERGE (a)-[r:DEPENDS_ON {thread: $thread, timestamp: $ts}]->(b)",
                    source=source, target=target,
                    thread=data.get('thread'),
                    ts=data.get('timestamp')
                )

    def query_deadlock_paths(self) -> list:
        """
        æŸ¥è¯¢æ­»é”è·¯å¾„
        """
        with self.driver.session() as session:
            result = session.run("""
                MATCH path = (a:Lock)-[:DEPENDS_ON*]->(a:Lock)
                RETURN path
                LIMIT 10
            """)

            return [record['path'] for record in result]

    def close(self):
        self.driver.close()
```

### 2.3 Flinké›†æˆï¼ˆå®æ—¶ç›‘æ§ï¼‰

**å®‰è£…**:

```bash
# ä¸‹è½½Apache Flink
wget https://dlcdn.apache.org/flink/flink-1.18.0/flink-1.18.0-bin-scala_2.12.tgz

# è§£å‹
tar -xzf flink-1.18.0-bin-scala_2.12.tgz
cd flink-1.18.0

# å¯åŠ¨
./bin/start-cluster.sh
```

**Pythoné›†æˆï¼ˆPyFlinkï¼‰**:

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.table import StreamTableEnvironment

class OSFlinkIntegration:
    def __init__(self):
        self.env = StreamExecutionEnvironment.get_execution_environment()
        self.table_env = StreamTableEnvironment.create(self.env)

    def monitor_lock_events(self, lock_event_stream):
        """
        å®æ—¶ç›‘æ§é”äº‹ä»¶
        """
        # åˆ›å»ºè¡¨
        self.table_env.execute_sql("""
            CREATE TABLE lock_events (
                thread_id BIGINT,
                lock_id STRING,
                action STRING,
                timestamp BIGINT,
                proctime AS PROCTIME()
            ) WITH (
                'connector' = 'kafka',
                'topic' = 'lock-events',
                'properties.bootstrap.servers' = 'localhost:9092',
                'format' = 'json'
            )
        """)

        # æ£€æµ‹æ­»é”æ¨¡å¼
        result = self.table_env.execute_sql("""
            SELECT
                thread_id,
                lock_id,
                action,
                COUNT(*) as event_count
            FROM lock_events
            WHERE action = 'acquire'
            GROUP BY thread_id, lock_id, action
            HAVING COUNT(*) > 10
        """)

        return result
```

---

## ğŸ”¬ **ä¸‰ã€æ‹“æ‰‘åˆ†æå·¥å…·é›†æˆ / Part 3: Topological Analysis Tools Integration**

### 3.1 GUDHIé›†æˆ

**å®‰è£…**:

```bash
pip install gudhi
```

**Pythoné›†æˆ**:

```python
from gudhi import RipsComplex, SimplexTree
import numpy as np

class OSTopologyAnalyzer:
    def __init__(self):
        self.rips_complex = None
        self.simplex_tree = None

    def analyze_scheduling_patterns(self, schedule_sequence: list):
        """
        åˆ†æè°ƒåº¦æ¨¡å¼çš„æ‹“æ‰‘ç‰¹å¾
        schedule_sequence: [(process_id, queue_level, wait_time), ...]
        """
        # æå–ç‰¹å¾å‘é‡
        features = []
        for proc_id, level, wait_time in schedule_sequence:
            features.append([level, wait_time, proc_id % 10])

        features = np.array(features)

        # æ„å»ºRipså¤å½¢
        rips_complex = RipsComplex(points=features, max_edge_length=5.0)
        simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)

        # è®¡ç®—æŒä¹…åŒè°ƒ
        persistence = simplex_tree.persistence()

        # æ£€æµ‹è°ƒåº¦æ¨¡å¼
        patterns = {
            'connected_components': [],
            'cycles': []
        }

        for dim, (birth, death) in persistence:
            if dim == 0:
                patterns['connected_components'].append((birth, death))
            elif dim == 1:
                patterns['cycles'].append((birth, death))

        return patterns
```

### 3.2 Ripseré›†æˆ

**å®‰è£…**:

```bash
pip install ripser
```

**Pythoné›†æˆ**:

```python
from ripser import ripser

class OSRipserIntegration:
    def analyze_process_patterns(self, process_features: np.ndarray):
        """
        åˆ†æè¿›ç¨‹æ¨¡å¼çš„æ‹“æ‰‘ç‰¹å¾
        """
        result = ripser(process_features, maxdim=2, sparse=True)

        return {
            'dgms': result['dgms'],
            'num_features': [len(dgm) for dgm in result['dgms']]
        }
```

---

## ğŸ”„ **å››ã€å·¥å…·ç»„åˆä½¿ç”¨ç¤ºä¾‹ / Part 4: Tool Combination Examples**

### 4.1 æ­»é”æ£€æµ‹å®Œæ•´æµç¨‹

```python
class OSDeadlockDetector:
    def __init__(self):
        self.cpn_tools = CPNToolsIntegration()
        self.graph_analyzer = OSGraphAnalyzer()
        self.neo4j = OSNeo4jIntegration('bolt://localhost:7687', 'neo4j', 'password')

    def detect_deadlock(self, system_spec: dict):
        """
        ç»¼åˆæ­»é”æ£€æµ‹æµç¨‹
        """
        # 1. Petriç½‘å½¢å¼åŒ–éªŒè¯
        petri_result = self.cpn_tools.verify_deadlock(system_spec['petri_model'])

        # 2. åŠ¨æ€å›¾åˆ†æ
        for lock_seq in system_spec['lock_sequences']:
            self.graph_analyzer.add_lock_sequence(
                lock_seq['thread_id'],
                lock_seq['locks']
            )

        graph_result = self.graph_analyzer.validate_lock_order()

        # 3. å­˜å‚¨åˆ°Neo4j
        self.neo4j.store_lock_graph(self.graph_analyzer.graph)

        # 4. æŸ¥è¯¢æ­»é”è·¯å¾„
        deadlock_paths = self.neo4j.query_deadlock_paths()

        return {
            'petri_verification': petri_result,
            'graph_analysis': graph_result,
            'deadlock_paths': deadlock_paths
        }
```

### 4.2 è¿›ç¨‹è°ƒåº¦ä¼˜åŒ–æµç¨‹

```python
class OSSchedulerOptimizer:
    def __init__(self):
        self.topology_analyzer = OSTopologyAnalyzer()
        self.graph_analyzer = OSGraphAnalyzer()

    def optimize_scheduling(self, schedule_history: list):
        """
        è°ƒåº¦ä¼˜åŒ–æµç¨‹
        """
        # 1. æ‹“æ‰‘åˆ†æè¯†åˆ«æ¨¡å¼
        patterns = self.topology_analyzer.analyze_scheduling_patterns(schedule_history)

        # 2. å›¾åˆ†æè¯†åˆ«ç“¶é¢ˆ
        # æ„å»ºè¿›ç¨‹ä¾èµ–å›¾
        for proc in schedule_history:
            self.graph_analyzer.graph.add_node(proc['id'],
                                              wait_time=proc['wait_time'])

        # åˆ†æå…³é”®è¿›ç¨‹
        betweenness = nx.betweenness_centrality(self.graph_analyzer.graph)
        critical_processes = sorted(betweenness.items(),
                                   key=lambda x: x[1], reverse=True)[:10]

        return {
            'topology_patterns': patterns,
            'critical_processes': critical_processes,
            'optimization_suggestions': self._generate_suggestions(patterns, critical_processes)
        }

    def _generate_suggestions(self, patterns, critical_processes):
        """
        ç”Ÿæˆä¼˜åŒ–å»ºè®®
        """
        suggestions = []

        # åŸºäºæ‹“æ‰‘æ¨¡å¼
        if len(patterns['cycles']) > 0:
            suggestions.append("æ£€æµ‹åˆ°å¾ªç¯è°ƒåº¦æ¨¡å¼ï¼Œå»ºè®®ä¼˜åŒ–è°ƒåº¦ç®—æ³•")

        # åŸºäºå…³é”®è¿›ç¨‹
        if len(critical_processes) > 0:
            suggestions.append(f"è¿›ç¨‹ {critical_processes[0][0]} æ˜¯å…³é”®ç“¶é¢ˆï¼Œå»ºè®®ä¼˜å…ˆè°ƒåº¦")

        return suggestions
```

---

## ğŸš€ **äº”ã€Graph Transformerå’ŒPGNNå·¥å…·é›†æˆï¼ˆ2025æœ€æ–°ï¼‰/ Part 5: Graph Transformer and PGNN Tools Integration (2025 Latest)**

### 5.1 PyTorch Geometricé›†æˆï¼ˆGraph Transformerï¼‰

**å®‰è£…**:

```bash
pip install torch torch-geometric
```

**Pythoné›†æˆ**:

```python
import torch
import torch.nn as nn
from torch_geometric.data import Data
from torch_geometric.nn import TransformerConv

class OSDeadlockDetectorGTIntegration:
    """æ“ä½œç³»ç»Ÿæ­»é”æ£€æµ‹Graph Transformeré›†æˆ"""

    def __init__(self, input_dim, hidden_dim=128, num_layers=3, num_heads=8):
        self.model = self._build_model(input_dim, hidden_dim, num_layers, num_heads)
        self.deadlock_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )

    def _build_model(self, input_dim, hidden_dim, num_layers, num_heads):
        """æ„å»ºGraph Transformeræ¨¡å‹"""
        layers = []
        layers.append(TransformerConv(input_dim, hidden_dim, heads=num_heads))

        for _ in range(num_layers - 1):
            layers.append(TransformerConv(hidden_dim, hidden_dim, heads=num_heads))

        return nn.Sequential(*layers)

    def detect_deadlock(self, node_features, edge_index):
        """æ£€æµ‹æ­»é”"""
        data = Data(x=node_features, edge_index=edge_index)
        node_embeddings = self.model(data.x, data.edge_index)
        deadlock_scores = self.deadlock_head(node_embeddings)
        return deadlock_scores
```

### 5.2 PyTorché›†æˆï¼ˆPGNNï¼‰

**Pythoné›†æˆ**:

```python
import torch
import torch.nn as nn
import networkx as nx

class OSDeadlockDetectorPGNNIntegration:
    """æ“ä½œç³»ç»Ÿæ­»é”æ£€æµ‹PGNNé›†æˆ"""

    def __init__(self, num_processes, num_resources, hidden_dim=128):
        self.process_embedding = nn.Embedding(num_processes, hidden_dim)
        self.resource_embedding = nn.Embedding(num_resources, hidden_dim)

        self.propagation_layers = nn.ModuleList([
            nn.Linear(hidden_dim, hidden_dim) for _ in range(3)
        ])

        self.deadlock_head = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()
        )

    def detect_deadlock(self, os_petri_net, process_features, resource_features):
        """æ£€æµ‹æ­»é”"""
        embeddings = {}
        for node in os_petri_net.nodes():
            if os_petri_net.nodes[node]['type'] == 'process':
                proc_idx = os_petri_net.nodes[node]['index']
                embeddings[node] = self.process_embedding(proc_idx) + process_features[proc_idx]
            else:
                res_idx = os_petri_net.nodes[node]['index']
                embeddings[node] = self.resource_embedding(res_idx) + resource_features[res_idx]

        # PGNNä¼ æ’­ï¼ˆåŸºäºPetriç½‘æµçº¦æŸï¼‰
        for layer in self.propagation_layers:
            new_embeddings = {}
            for node in os_petri_net.nodes():
                neighbor_embeddings = [embeddings[n] for n in os_petri_net.neighbors(node)]
                if neighbor_embeddings:
                    aggregated = torch.stack(neighbor_embeddings).mean(dim=0)
                    new_embeddings[node] = layer(aggregated)
                else:
                    new_embeddings[node] = embeddings[node]
            embeddings = new_embeddings

        # æ£€æµ‹æ­»é”ï¼ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨å¾ªç¯ç­‰å¾…ï¼‰
        deadlock_scores = {}
        for process_node in os_petri_net.nodes():
            if os_petri_net.nodes[process_node]['type'] == 'process':
                # æ£€æŸ¥è¯¥è¿›ç¨‹æ˜¯å¦åœ¨æ­»é”ä¸­
                cycle_score = self._check_cycle(os_petri_net, process_node, embeddings)
                deadlock_scores[process_node] = cycle_score

        return deadlock_scores

    def _check_cycle(self, petri_net, start_node, embeddings):
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¾ªç¯ç­‰å¾…"""
        # ä½¿ç”¨DFSæ£€æµ‹å¾ªç¯
        visited = set()
        rec_stack = set()

        def dfs(node):
            visited.add(node)
            rec_stack.add(node)

            for neighbor in petri_net.neighbors(node):
                if neighbor not in visited:
                    if dfs(neighbor):
                        return True
                elif neighbor in rec_stack:
                    return True

            rec_stack.remove(node)
            return False

        has_cycle = dfs(start_node)

        # å¦‚æœæœ‰å¾ªç¯ï¼Œè®¡ç®—æ­»é”æ¦‚ç‡
        if has_cycle:
            node_emb = embeddings[start_node]
            # ä½¿ç”¨å¹³å‡é‚»å±…åµŒå…¥
            neighbor_embs = [embeddings[n] for n in petri_net.neighbors(start_node)]
            if neighbor_embs:
                avg_neighbor = torch.stack(neighbor_embs).mean(dim=0)
                pair_feat = torch.cat([node_emb, avg_neighbor], dim=-1)
                return self.deadlock_head(pair_feat)

        return torch.tensor(0.0)
```

---

## ğŸ“‹ **å…­ã€æœ€ä½³å®è·µ / Part 6: Best Practices**

### 5.1 å·¥å…·é€‰æ‹©å»ºè®®

| åœºæ™¯ | æ¨èå·¥å…· | ç†ç”± |
|------|----------|------|
| å½¢å¼åŒ–éªŒè¯ | CPN Tools / TLA+ | ä¸¥æ ¼çš„æ•°å­¦è¯æ˜ |
| å®æ—¶ç›‘æ§ | NetworkX + Flink | é«˜æ€§èƒ½å®æ—¶åˆ†æ |
| å†å²åˆ†æ | Neo4j | å¤æ‚æŸ¥è¯¢å’Œå¯è§†åŒ– |
| æ¨¡å¼è¯†åˆ« | GUDHI / Ripser | æ‹“æ‰‘ç‰¹å¾æå– |
| æ­»é”æ£€æµ‹ï¼ˆ2025ï¼‰ | Graph Transformer / PGNN | æ·±åº¦å­¦ä¹ æ­»é”æ£€æµ‹ |
| æ€§èƒ½ä¼˜åŒ–ï¼ˆ2025ï¼‰ | Graph Transformer | å…¨å±€æ³¨æ„åŠ›æœºåˆ¶ |

### 5.2 æ€§èƒ½ä¼˜åŒ–

1. **å¹¶è¡Œè®¡ç®—**: ä½¿ç”¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹å¤„ç†å¤§è§„æ¨¡å›¾
2. **ç¼“å­˜æœºåˆ¶**: ç¼“å­˜é¢‘ç¹è®¡ç®—çš„å›¾åˆ†æç»“æœ
3. **å¢é‡æ›´æ–°**: ä½¿ç”¨å¢é‡ç®—æ³•æ›´æ–°å›¾ç»“æ„

### 5.3 é”™è¯¯å¤„ç†

```python
class OSErrorHandler:
    @staticmethod
    def handle_tool_error(error, tool_name):
        """
        ç»Ÿä¸€é”™è¯¯å¤„ç†
        """
        error_map = {
            'CPN Tools': 'æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ ¼å¼å’ŒJavaç¯å¢ƒ',
            'TLA+': 'æ£€æŸ¥è§„èŒƒè¯­æ³•å’Œé…ç½®',
            'Neo4j': 'æ£€æŸ¥æ•°æ®åº“è¿æ¥å’Œæƒé™',
            'NetworkX': 'æ£€æŸ¥å›¾æ•°æ®æ ¼å¼',
            'Graph Transformer': 'æ£€æŸ¥PyTorchå’ŒPyTorch Geometricç‰ˆæœ¬',
            'PGNN': 'æ£€æŸ¥Petriç½‘æ¨¡å‹æ ¼å¼å’ŒèŠ‚ç‚¹ç‰¹å¾ç»´åº¦'
        }

        suggestion = error_map.get(tool_name, 'æŸ¥çœ‹å·¥å…·æ–‡æ¡£')
        return {
            'error': str(error),
            'tool': tool_name,
            'suggestion': suggestion
        }
```

---

## ğŸ“š **å…­ã€å‚è€ƒèµ„æº / Part 6: Reference Resources**

### 6.1 å®˜æ–¹æ–‡æ¡£

- [CPN Toolsæ–‡æ¡£](https://cpntools.org/documentation/)
- [TLA+å­¦ä¹ èµ„æº](https://learntla.com/)
- [NetworkXæ–‡æ¡£](https://networkx.org/documentation/)
- [Neo4jæ–‡æ¡£](https://neo4j.com/docs/)
- [GUDHIæ–‡æ¡£](https://gudhi.inria.fr/documentation/)
- [PyTorch Geometricæ–‡æ¡£](https://pytorch-geometric.readthedocs.io/)
- [Graph Transformerè®ºæ–‡](https://arxiv.org/abs/2012.09699)
- [PGNN ç›¸å…³ç ”ç©¶ï¼ˆPetri ç½‘ + å›¾ç¥ç»ç½‘ç»œï¼‰](https://arxiv.org/search/?query=graph+neural+network+petri+net&searchtype=all)ï¼ˆæ­£å¼æœŸåˆŠ DOI å¾…æ›´æ–°ï¼‰

### 6.2 ç›¸å…³æ–‡æ¡£

- [æ“ä½œç³»ç»Ÿåº”ç”¨æ¨¡å¼æ¸…å•](æ“ä½œç³»ç»Ÿåº”ç”¨æ¨¡å¼æ¸…å•.md)
- [å®ç°æŒ‡å—](02-å®ç°æŒ‡å—.md)
- [å·¥å…·é›†æˆä¸é…ç½®æŒ‡å—](../å·¥å…·é›†æˆä¸é…ç½®æŒ‡å—.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**çŠ¶æ€**: âœ… å®Œæˆ
**ç»´æŠ¤è€…**: GraphNetWorkCommunicateé¡¹ç›®ç»„
