# å·¥å…·é›†æˆä¸é…ç½®æŒ‡å— / Tools Integration and Configuration Guide

## ğŸ“š **æ¦‚è¿° / Overview**

**æ–‡æ¡£ç›®çš„**: æä¾›ä¸‰å¤§ç†è®ºï¼ˆPetriç½‘ã€åŠ¨æ€å›¾è®ºã€æ‹“æ‰‘æ¨¡å‹ï¼‰ç›¸å…³å·¥å…·çš„å®Œæ•´é›†æˆå’Œé…ç½®æŒ‡å—ã€‚

**é€‚ç”¨å¯¹è±¡**: ç³»ç»Ÿæ¶æ„å¸ˆã€å¼€å‘å·¥ç¨‹å¸ˆã€è¿ç»´å·¥ç¨‹å¸ˆ

---

## ğŸ¯ **ä¸€ã€Petriç½‘å·¥å…·é›†æˆ / Part 1: Petri Net Tools Integration**

### 1.1 å·¥å…·æ ˆæ¦‚è§ˆ

**æ ¸å¿ƒå·¥å…·**:

| å·¥å…· | ç”¨é€” | å®‰è£…æ–¹å¼ | å®˜æ–¹æ–‡æ¡£ |
|------|------|----------|----------|
| **CPN Tools** | å¯è§†åŒ–å»ºæ¨¡ã€ä»¿çœŸ | <https://cpntools.org/download> | <https://cpntools.org/documentation/> |
| **TLA+** | å½¢å¼åŒ–éªŒè¯ | <https://github.com/tlaplus/tlaplus/releases> | <https://learntla.com/> |
| **GreatSPN** | æ€§èƒ½åˆ†æ | <http://www.di.unito.it/~greatspn/> | <http://www.di.unito.it/~greatspn/manual.html> |

### 1.2 CPN Toolsé…ç½®

**ç¯å¢ƒå˜é‡é…ç½®**:

```bash
export CPNTOOLS_HOME=/path/to/cpntools
export PATH=$PATH:$CPNTOOLS_HOME/bin
export JAVA_HOME=/path/to/java
```

**Javaé…ç½®**:

```bash
# ç¡®ä¿Javaç‰ˆæœ¬ >= 8
java -version

# è®¾ç½®Javaå†…å­˜
export JAVA_OPTS="-Xmx4g -Xms2g"
```

### 1.3 TLA+é…ç½®

**ç¯å¢ƒå˜é‡é…ç½®**:

```bash
export TLA_PATH=/path/to/tlaplus
export JAVA_HOME=/path/to/java
```

**TLCæ¨¡å‹æ£€éªŒå™¨é…ç½®**:

```bash
# TLCé…ç½®
export TLC_JVM_ARGS="-Xmx8g -Xms4g"
```

### 1.4 å·¥å…·é›†æˆç¤ºä¾‹

**Pythoné›†æˆ**:

```python
import subprocess
import os

class CPNToolsWrapper:
    def __init__(self, cpn_tools_path):
        self.cpn_tools_path = cpn_tools_path
        os.environ['CPNTOOLS_HOME'] = cpn_tools_path

    def simulate_model(self, model_file):
        """
        ä»¿çœŸCPNæ¨¡å‹
        """
        cmd = [
            os.path.join(self.cpn_tools_path, 'bin', 'cpntools'),
            model_file
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        return result

class TLAWrapper:
    def __init__(self, tla_path):
        self.tla_path = tla_path
        os.environ['TLA_PATH'] = tla_path

    def verify_spec(self, spec_file):
        """
        éªŒè¯TLA+è§„èŒƒ
        """
        cmd = [
            os.path.join(self.tla_path, 'tlc'),
            spec_file
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        return result
```

---

## ğŸ”§ **äºŒã€åŠ¨æ€å›¾è®ºå·¥å…·é›†æˆ / Part 2: Dynamic Graph Tools Integration**

### 2.1 å·¥å…·æ ˆæ¦‚è§ˆ

**æ ¸å¿ƒå·¥å…·**:

| å·¥å…· | ç”¨é€” | å®‰è£…æ–¹å¼ | å®˜æ–¹æ–‡æ¡£ |
|------|------|----------|----------|
| **NetworkX** | å›¾åˆ†æå’Œç®—æ³• | `pip install networkx` | <https://networkx.org/documentation/> |
| **Neo4j** | å›¾æ•°æ®åº“ | <https://neo4j.com/download/> | <https://neo4j.com/docs/> |
| **Apache Flink** | æµå¼å›¾å¤„ç† | <https://flink.apache.org/downloads.html> | <https://flink.apache.org/docs/> |
| **GraphX** | åˆ†å¸ƒå¼å›¾è®¡ç®— | Sparkç”Ÿæ€ | <https://spark.apache.org/graphx/> |

### 2.2 NetworkXé…ç½®

**å®‰è£…**:

```bash
pip install networkx
pip install matplotlib  # å¯è§†åŒ–
pip install numpy       # æ•°å€¼è®¡ç®—
pip install scipy       # ç§‘å­¦è®¡ç®—
```

**é…ç½®**:

```python
import networkx as nx

# è®¾ç½®é»˜è®¤å‚æ•°
nx.config.use_cache = True
nx.config.cache_size = 1000
```

### 2.3 Neo4jé…ç½®

**ç¯å¢ƒå˜é‡é…ç½®**:

```bash
export NEO4J_HOME=/path/to/neo4j
export PATH=$PATH:$NEO4J_HOME/bin
```

**é…ç½®æ–‡ä»¶** (`neo4j.conf`):

```properties
# å†…å­˜é…ç½®
dbms.memory.heap.initial_size=512m
dbms.memory.heap.max_size=2g
dbms.memory.pagecache.size=1g

# è¿æ¥é…ç½®
dbms.connector.bolt.listen_address=localhost:7687
dbms.connector.http.listen_address=localhost:7474
```

### 2.4 Apache Flinké…ç½®

**ç¯å¢ƒå˜é‡é…ç½®**:

```bash
export FLINK_HOME=/path/to/flink
export PATH=$PATH:$FLINK_HOME/bin
```

**é…ç½®æ–‡ä»¶** (`flink-conf.yaml`):

```yaml
# ä»»åŠ¡ç®¡ç†å™¨é…ç½®
taskmanager.memory.process.size: 4096m
taskmanager.numberOfTaskSlots: 4

# å¹¶è¡Œåº¦é…ç½®
parallelism.default: 2

# æ£€æŸ¥ç‚¹é…ç½®
execution.checkpointing.interval: 60000
```

### 2.5 å·¥å…·é›†æˆç¤ºä¾‹

**Pythoné›†æˆ**:

```python
import networkx as nx
from neo4j import GraphDatabase
from pyflink.datastream import StreamExecutionEnvironment

class GraphToolsIntegration:
    def __init__(self, neo4j_uri, neo4j_user, neo4j_password):
        self.nx_graph = nx.DiGraph()
        self.neo4j_driver = GraphDatabase.driver(
            neo4j_uri,
            auth=(neo4j_user, neo4j_password)
        )
        self.flink_env = StreamExecutionEnvironment.get_execution_environment()

    def sync_to_neo4j(self):
        """
        åŒæ­¥NetworkXå›¾åˆ°Neo4j
        """
        with self.neo4j_driver.session() as session:
            # åˆ›å»ºèŠ‚ç‚¹
            for node, data in self.nx_graph.nodes(data=True):
                session.run(
                    "MERGE (n:Node {id: $id}) SET n += $props",
                    id=node,
                    props=data
                )

            # åˆ›å»ºè¾¹
            for source, target, data in self.nx_graph.edges(data=True):
                session.run(
                    "MATCH (a:Node {id: $source}), (b:Node {id: $target}) "
                    "MERGE (a)-[r:RELATES]->(b) SET r += $props",
                    source=source,
                    target=target,
                    props=data
                )

    def load_from_neo4j(self):
        """
        ä»Neo4jåŠ è½½å›¾åˆ°NetworkX
        """
        with self.neo4j_driver.session() as session:
            # åŠ è½½èŠ‚ç‚¹
            nodes_result = session.run("MATCH (n:Node) RETURN n.id as id, n")
            for record in nodes_result:
                node_id = record["id"]
                props = dict(record["n"])
                self.nx_graph.add_node(node_id, **props)

            # åŠ è½½è¾¹
            edges_result = session.run(
                "MATCH (a:Node)-[r:RELATES]->(b:Node) "
                "RETURN a.id as source, b.id as target, r"
            )
            for record in edges_result:
                source = record["source"]
                target = record["target"]
                props = dict(record["r"])
                self.nx_graph.add_edge(source, target, **props)

    def process_with_flink(self, graph_stream):
        """
        ä½¿ç”¨Flinkå¤„ç†å›¾æµ
        """
        # è½¬æ¢ä¸ºFlinkæµ
        flink_stream = self.flink_env.from_collection(graph_stream)

        # æ‰§è¡Œå›¾ç®—æ³•
        # ...

        return flink_stream
```

---

## ğŸ”¬ **ä¸‰ã€æ‹“æ‰‘æ¨¡å‹å·¥å…·é›†æˆ / Part 3: Topological Model Tools Integration**

### 3.1 å·¥å…·æ ˆæ¦‚è§ˆ

**æ ¸å¿ƒå·¥å…·**:

| å·¥å…· | ç”¨é€” | å®‰è£…æ–¹å¼ | å®˜æ–¹æ–‡æ¡£ |
|------|------|----------|----------|
| **GUDHI** | æ‹“æ‰‘æ•°æ®åˆ†æ | `pip install gudhi` | <https://gudhi.inria.fr/documentation/> |
| **Ripser** | æŒä¹…åŒè°ƒè®¡ç®— | `pip install ripser` | <https://ripser.scikit-tda.org/> |
| **KeplerMapper** | Mapperç®—æ³• | `pip install kmapper` | <https://github.com/MLWave/kepler-mapper> |
| **giotto-tda** | TDAå·¥å…·é›† | `pip install giotto-tda` | <https://giotto.ai/giotto-tda/> |

### 3.2 GUDHIé…ç½®

**å®‰è£…**:

```bash
pip install gudhi
pip install gudhi[all]  # åŒ…å«æ‰€æœ‰å¯é€‰ä¾èµ–
```

**é…ç½®**:

```python
import gudhi

# è®¾ç½®å¹¶è¡Œåº¦
gudhi.parallelism.set_parallelism(4)
```

### 3.3 Ripseré…ç½®

**å®‰è£…**:

```bash
pip install ripser
pip install ripser-tda
```

**é…ç½®**:

```python
from ripser import ripser

# ä½¿ç”¨ç¨€ç–çŸ©é˜µä¼˜åŒ–
result = ripser(data, maxdim=2, sparse=True, n_threads=4)
```

### 3.4 å·¥å…·é›†æˆç¤ºä¾‹

**Pythoné›†æˆ**:

```python
from gudhi import RipsComplex, SimplexTree
from ripser import ripser
import kmapper as km
import numpy as np

class TopologyToolsIntegration:
    def __init__(self):
        self.gudhi_complex = None
        self.ripser_result = None
        self.mapper_graph = None

    def compute_with_gudhi(self, points, max_edge_length=1.0):
        """
        ä½¿ç”¨GUDHIè®¡ç®—æŒä¹…åŒè°ƒ
        """
        rips_complex = RipsComplex(points=points, max_edge_length=max_edge_length)
        simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)
        persistence = simplex_tree.persistence()

        return persistence

    def compute_with_ripser(self, points, maxdim=2):
        """
        ä½¿ç”¨Ripserè®¡ç®—æŒä¹…åŒè°ƒ
        """
        result = ripser(points, maxdim=maxdim, sparse=True)
        return result

    def compute_with_mapper(self, data, n_cubes=10):
        """
        ä½¿ç”¨KeplerMapperè®¡ç®—Mapperå›¾
        """
        mapper = km.KeplerMapper(verbose=1)

        # æŠ•å½±
        projected = mapper.fit_transform(data, projection=None)

        # æ„å»ºMapperå›¾
        cover = km.Cover(n_cubes=n_cubes, perc_overlap=0.2)
        graph = mapper.map(projected, data, cover=cover)

        return graph, mapper

    def compare_results(self, points):
        """
        æ¯”è¾ƒä¸åŒå·¥å…·çš„ç»“æœ
        """
        gudhi_result = self.compute_with_gudhi(points)
        ripser_result = self.compute_with_ripser(points)

        return {
            'gudhi': gudhi_result,
            'ripser': ripser_result['dgms']
        }
```

---

## ğŸ”„ **å››ã€è·¨å·¥å…·é›†æˆ / Part 4: Cross-Tool Integration**

### 4.1 ç»Ÿä¸€æ¥å£è®¾è®¡

**æŠ½è±¡æ¥å£**:

```python
from abc import ABC, abstractmethod

class GraphAnalyzer(ABC):
    @abstractmethod
    def build_graph(self, data):
        pass

    @abstractmethod
    def analyze(self, graph):
        pass

class PetriNetAnalyzer(ABC):
    @abstractmethod
    def build_model(self, spec):
        pass

    @abstractmethod
    def verify(self, model):
        pass

class TopologyAnalyzer(ABC):
    @abstractmethod
    def compute_persistence(self, data):
        pass

    @abstractmethod
    def extract_features(self, persistence):
        pass

class IntegratedAnalyzer:
    def __init__(self, graph_analyzer, petri_analyzer, topology_analyzer):
        self.graph_analyzer = graph_analyzer
        self.petri_analyzer = petri_analyzer
        self.topology_analyzer = topology_analyzer

    def comprehensive_analysis(self, system_spec):
        """
        ç»¼åˆåˆ†æ
        """
        # 1. å›¾åˆ†æ
        graph = self.graph_analyzer.build_graph(system_spec)
        graph_result = self.graph_analyzer.analyze(graph)

        # 2. Petriç½‘éªŒè¯
        petri_model = self.petri_analyzer.build_model(system_spec)
        petri_result = self.petri_analyzer.verify(petri_model)

        # 3. æ‹“æ‰‘åˆ†æ
        topology_data = self._extract_topology_data(graph)
        persistence = self.topology_analyzer.compute_persistence(topology_data)
        topology_features = self.topology_analyzer.extract_features(persistence)

        return {
            'graph': graph_result,
            'petri': petri_result,
            'topology': topology_features
        }
```

### 4.2 æ•°æ®æ ¼å¼è½¬æ¢

**æ ¼å¼è½¬æ¢å·¥å…·**:

```python
class DataConverter:
    @staticmethod
    def graph_to_topology_data(graph):
        """
        å°†å›¾è½¬æ¢ä¸ºæ‹“æ‰‘åˆ†ææ•°æ®
        """
        # è®¡ç®—èŠ‚ç‚¹åµŒå…¥
        embeddings = []
        for node in graph.nodes():
            features = [
                graph.degree(node),
                nx.clustering(graph.to_undirected(), node),
                nx.betweenness_centrality(graph)[node]
            ]
            embeddings.append(features)

        return np.array(embeddings)

    @staticmethod
    def petri_to_graph(petri_net):
        """
        å°†Petriç½‘è½¬æ¢ä¸ºå›¾
        """
        graph = nx.DiGraph()

        # æ·»åŠ èŠ‚ç‚¹ï¼ˆåº“æ‰€å’Œå˜è¿ï¼‰
        for place in petri_net.places:
            graph.add_node(place, type='place')

        for transition in petri_net.transitions:
            graph.add_node(transition, type='transition')

        # æ·»åŠ è¾¹ï¼ˆæµå…³ç³»ï¼‰
        for arc in petri_net.arcs:
            graph.add_edge(arc.source, arc.target, weight=arc.weight)

        return graph
```

---

## ğŸ“‹ **äº”ã€æœ€ä½³å®è·µ / Part 5: Best Practices**

### 5.1 å·¥å…·é€‰æ‹©åŸåˆ™

1. **éœ€æ±‚åŒ¹é…**: æ ¹æ®å…·ä½“éœ€æ±‚é€‰æ‹©å·¥å…·
2. **æ€§èƒ½è€ƒè™‘**: è€ƒè™‘å·¥å…·çš„æ€§èƒ½å’Œå¯æ‰©å±•æ€§
3. **ç”Ÿæ€å…¼å®¹**: é€‰æ‹©ä¸ç°æœ‰ç”Ÿæ€å…¼å®¹çš„å·¥å…·

### 5.2 é›†æˆå®è·µ

1. **ç»Ÿä¸€æ¥å£**: è®¾è®¡ç»Ÿä¸€çš„æ¥å£æŠ½è±¡
2. **æ•°æ®è½¬æ¢**: å®ç°é«˜æ•ˆçš„æ•°æ®æ ¼å¼è½¬æ¢
3. **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶

### 5.3 æ€§èƒ½ä¼˜åŒ–

1. **å¹¶è¡Œè®¡ç®—**: åˆ©ç”¨å¤šæ ¸å’Œåˆ†å¸ƒå¼è®¡ç®—
2. **ç¼“å­˜æœºåˆ¶**: å®ç°ç»“æœç¼“å­˜
3. **èµ„æºç®¡ç†**: åˆç†ç®¡ç†è®¡ç®—èµ„æº

---

## ğŸ“š **å…­ã€å‚è€ƒæ–‡æ¡£ / Part 6: Reference Documents**

### 6.1 ç›¸å…³æ–‡æ¡£

- [åº”ç”¨æ¨¡å¼å½’çº³æ¦‚è¿°](00-åº”ç”¨æ¨¡å¼å½’çº³æ¦‚è¿°.md)
- [è·¨é¢†åŸŸåº”ç”¨æ¨¡å¼ç»¼åˆ](08-è·¨é¢†åŸŸåº”ç”¨æ¨¡å¼ç»¼åˆ.md)

### 6.2 å·¥å…·æ–‡æ¡£

- [CPN Toolsæ–‡æ¡£](https://cpntools.org/documentation/)
- [TLA+å­¦ä¹ èµ„æº](https://learntla.com/)
- [NetworkXæ–‡æ¡£](https://networkx.org/documentation/)
- [GUDHIæ–‡æ¡£](https://gudhi.inria.fr/documentation/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**çŠ¶æ€**: âœ… å®Œæˆ
**ç»´æŠ¤è€…**: GraphNetWorkCommunicateé¡¹ç›®ç»„
