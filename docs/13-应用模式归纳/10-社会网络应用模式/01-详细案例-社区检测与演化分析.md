# è¯¦ç»†æ¡ˆä¾‹ï¼šç¤¾åŒºæ£€æµ‹ä¸æ¼”åŒ–åˆ†æ / Detailed Case: Community Detection and Evolution Analysis

## ğŸ“š **æ¡ˆä¾‹æ¦‚è¿° / Case Overview**

**æ¡ˆä¾‹åç§°**: ä½¿ç”¨åŠ¨æ€å›¾è®ºåˆ†æç¤¾äº¤ç½‘ç»œçš„ç¤¾åŒºæ¼”åŒ–

**åº”ç”¨é¢†åŸŸ**: ç¤¾ä¼šç½‘ç»œ

**æ ¸å¿ƒé—®é¢˜**: ä½¿ç”¨åŠ¨æ€å›¾è®ºè¿½è¸ªç¤¾äº¤ç½‘ç»œçš„ç¤¾åŒºæ¼”åŒ–ï¼Œåˆ†æç¤¾åŒºå½¢æˆã€åˆ†è£‚ã€åˆå¹¶çš„åŠ¨æ€è¿‡ç¨‹

**ä½¿ç”¨ç†è®º**: åŠ¨æ€å›¾è®º + æ‹“æ‰‘æ¨¡å‹

**éš¾åº¦ç­‰çº§**: â­â­â­â­ è¾ƒé«˜

---

## ğŸ¯ **ä¸€ã€é—®é¢˜æè¿° / Part 1: Problem Description**

### 1.1 ç³»ç»Ÿåœºæ™¯

**ç¤¾äº¤ç½‘ç»œç¯å¢ƒ**:

- **èŠ‚ç‚¹**: ç”¨æˆ·ï¼ˆUserï¼‰
- **è¾¹**: ç¤¾äº¤å…³ç³»ï¼ˆå…³æ³¨ã€å¥½å‹ã€äº’åŠ¨ï¼‰
- **ç½‘ç»œè§„æ¨¡**: 10^6+ä¸ªç”¨æˆ·ï¼Œ10^7+æ¡å…³ç³»
- **æ—¶é—´è·¨åº¦**: 1å¹´

**åˆ†æéœ€æ±‚**:

- æ£€æµ‹ç¤¾åŒºç»“æ„
- è¿½è¸ªç¤¾åŒºæ¼”åŒ–
- è¯†åˆ«ç¤¾åŒºå½¢æˆ/åˆ†è£‚/åˆå¹¶äº‹ä»¶

### 1.2 æŠ€æœ¯æŒ‘æˆ˜

**æŒ‘æˆ˜**:

1. å¤§è§„æ¨¡å®æ—¶æ•°æ®å¤„ç†
2. ç¤¾åŒºæ¼”åŒ–è¿½è¸ª
3. æ¼”åŒ–äº‹ä»¶è¯†åˆ«
4. é«˜æ•ˆè®¡ç®—

---

## ğŸ”§ **äºŒã€åŠ¨æ€å›¾è®ºå»ºæ¨¡ / Part 2: Dynamic Graph Theory Modeling**

### 2.1 æ—¶åºç½‘ç»œæ„å»º

**åŠ¨æ€å›¾å®ç°**:

```python
import networkx as nx
from collections import defaultdict
from datetime import datetime, timedelta
import numpy as np

class TemporalSocialNetwork:
    def __init__(self, window_size=86400):  # 1å¤©
        self.temporal_graphs = {}
        self.window_size = window_size
        self.community_history = []

    def add_interaction(self, user1, user2, timestamp, interaction_type='friend'):
        """
        æ·»åŠ ç¤¾äº¤äº’åŠ¨
        """
        # ç¡®å®šæ—¶é—´çª—å£
        window = self._get_window(timestamp)

        # åˆå§‹åŒ–æ—¶é—´çª—å£å›¾
        if window not in self.temporal_graphs:
            self.temporal_graphs[window] = nx.Graph()

        # æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
        graph = self.temporal_graphs[window]
        graph.add_node(user1, type='user')
        graph.add_node(user2, type='user')

        if graph.has_edge(user1, user2):
            graph[user1][user2]['weight'] += 1
            graph[user1][user2]['last_seen'] = timestamp
        else:
            graph.add_edge(
                user1, user2,
                weight=1,
                type=interaction_type,
                first_seen=timestamp,
                last_seen=timestamp
            )

    def _get_window(self, timestamp):
        """
        è·å–æ—¶é—´çª—å£
        """
        if isinstance(timestamp, datetime):
            timestamp = timestamp.timestamp()

        window_start = int(timestamp // self.window_size) * self.window_size
        return window_start

    def get_snapshot(self, timestamp):
        """
        è·å–æ—¶é—´å¿«ç…§
        """
        window = self._get_window(timestamp)
        return self.temporal_graphs.get(window, nx.Graph())
```

### 2.2 ç¤¾åŒºæ¼”åŒ–è¿½è¸ª

**ç¤¾åŒºæ¼”åŒ–åˆ†æ**:

```python
from networkx.algorithms import community
from collections import defaultdict

class CommunityEvolutionAnalyzer:
    def __init__(self, temporal_network):
        self.temporal_network = temporal_network
        self.community_history = []
        self.evolution_events = []

    def track_community_evolution(self, timestamps):
        """
        è¿½è¸ªç¤¾åŒºæ¼”åŒ–
        """
        communities_over_time = []

        for timestamp in sorted(timestamps):
            # è·å–å½“å‰å¿«ç…§
            snapshot = self.temporal_network.get_snapshot(timestamp)

            if snapshot.number_of_nodes() == 0:
                continue

            # æ£€æµ‹ç¤¾åŒº
            communities = community.louvain_communities(snapshot)

            # è®°å½•ç¤¾åŒº
            communities_over_time.append({
                'timestamp': timestamp,
                'communities': communities,
                'num_communities': len(communities),
                'avg_community_size': np.mean([len(c) for c in communities])
            })

            # æ£€æµ‹æ¼”åŒ–äº‹ä»¶
            if len(self.community_history) > 0:
                events = self._detect_evolution_events(
                    self.community_history[-1]['communities'],
                    communities,
                    timestamp
                )
                self.evolution_events.extend(events)

            # æ›´æ–°å†å²
            self.community_history.append({
                'timestamp': timestamp,
                'communities': communities
            })

        return communities_over_time, self.evolution_events

    def _detect_evolution_events(self, prev_communities, curr_communities, timestamp):
        """
        æ£€æµ‹æ¼”åŒ–äº‹ä»¶
        """
        events = []

        # ç¤¾åŒºå½¢æˆæ£€æµ‹
        if len(curr_communities) > len(prev_communities):
            new_communities = self._find_new_communities(prev_communities, curr_communities)
            for comm in new_communities:
                events.append({
                    'type': 'formation',
                    'timestamp': timestamp,
                    'community': comm,
                    'size': len(comm)
                })

        # ç¤¾åŒºåˆ†è£‚æ£€æµ‹
        for prev_comm in prev_communities:
            matching_curr = self._find_matching_communities(prev_comm, curr_communities)
            if len(matching_curr) > 1:
                events.append({
                    'type': 'splitting',
                    'timestamp': timestamp,
                    'original_community': prev_comm,
                    'split_communities': matching_curr
                })

        # ç¤¾åŒºåˆå¹¶æ£€æµ‹
        for curr_comm in curr_communities:
            matching_prev = self._find_matching_communities(curr_comm, prev_communities)
            if len(matching_prev) > 1:
                events.append({
                    'type': 'merging',
                    'timestamp': timestamp,
                    'merged_communities': matching_prev,
                    'result_community': curr_comm
                })

        return events

    def _find_new_communities(self, prev_communities, curr_communities):
        """
        æ‰¾åˆ°æ–°å½¢æˆçš„ç¤¾åŒº
        """
        new_communities = []

        for curr_comm in curr_communities:
            is_new = True
            for prev_comm in prev_communities:
                # è®¡ç®—é‡å åº¦
                overlap = len(set(curr_comm) & set(prev_comm)) / len(curr_comm)
                if overlap > 0.5:  # è¶…è¿‡50%é‡å è®¤ä¸ºä¸æ˜¯æ–°ç¤¾åŒº
                    is_new = False
                    break

            if is_new:
                new_communities.append(curr_comm)

        return new_communities

    def _find_matching_communities(self, target_comm, communities):
        """
        æ‰¾åˆ°ä¸ç›®æ ‡ç¤¾åŒºåŒ¹é…çš„ç¤¾åŒº
        """
        matching = []

        for comm in communities:
            # è®¡ç®—é‡å åº¦
            overlap = len(set(target_comm) & set(comm)) / len(target_comm)
            if overlap > 0.3:  # è¶…è¿‡30%é‡å è®¤ä¸ºåŒ¹é…
                matching.append(comm)

        return matching
```

---

## ğŸ”¬ **ä¸‰ã€æ‹“æ‰‘æ¨¡å‹åˆ†æ / Part 3: Topological Model Analysis**

### 3.1 ç½‘ç»œæ‹“æ‰‘æ¼”åŒ–

**æŒä¹…åŒè°ƒåˆ†æ**:

```python
from ripser import ripser
import numpy as np

class TopologicalEvolutionAnalyzer:
    def __init__(self, temporal_network):
        self.temporal_network = temporal_network
        self.topology_history = []

    def analyze_topological_evolution(self, timestamps):
        """
        åˆ†ææ‹“æ‰‘æ¼”åŒ–
        """
        topology_over_time = []

        for timestamp in sorted(timestamps):
            # è·å–å½“å‰å¿«ç…§
            snapshot = self.temporal_network.get_snapshot(timestamp)

            if snapshot.number_of_nodes() < 3:
                continue

            # è®¡ç®—èŠ‚ç‚¹åµŒå…¥
            embeddings = self._compute_node_embeddings(snapshot)

            # è®¡ç®—æŒä¹…åŒè°ƒ
            result = ripser(embeddings, maxdim=1)

            # æå–æ‹“æ‰‘ç‰¹å¾
            topology_features = {
                'timestamp': timestamp,
                'betti_0': len([x for x in result['dgms'][0] if x[1] == np.inf]),
                'betti_1': len([x for x in result['dgms'][1] if x[1] != np.inf]),
                'persistence_diagrams': result['dgms']
            }

            topology_over_time.append(topology_features)

            # æ£€æµ‹æ‹“æ‰‘å˜åŒ–
            if len(self.topology_history) > 0:
                topology_change = self._detect_topology_change(
                    self.topology_history[-1],
                    topology_features
                )
                topology_features['change'] = topology_change

            self.topology_history.append(topology_features)

        return topology_over_time

    def _compute_node_embeddings(self, graph):
        """
        è®¡ç®—èŠ‚ç‚¹åµŒå…¥
        """
        # ä½¿ç”¨å›¾çš„Laplacianç‰¹å¾å‘é‡
        laplacian = nx.normalized_laplacian_matrix(graph)
        eigenvalues, eigenvectors = np.linalg.eigh(laplacian.toarray())

        # ä½¿ç”¨å‰kä¸ªç‰¹å¾å‘é‡
        k = min(10, len(eigenvalues))
        embeddings = eigenvectors[:, :k]

        return embeddings

    def _detect_topology_change(self, prev_topology, curr_topology):
        """
        æ£€æµ‹æ‹“æ‰‘å˜åŒ–
        """
        # æ¯”è¾ƒBettiæ•°
        betti_change = {
            'betti_0_change': curr_topology['betti_0'] - prev_topology['betti_0'],
            'betti_1_change': curr_topology['betti_1'] - prev_topology['betti_1']
        }

        # è®¡ç®—æŒä¹…å›¾è·ç¦»ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # distance = self._compute_persistence_distance(
        #     prev_topology['persistence_diagrams'],
        #     curr_topology['persistence_diagrams']
        # )

        return betti_change
```

---

## ğŸ“ˆ **å››ã€åˆ†æç»“æœ / Part 4: Analysis Results**

### 4.1 ç¤¾åŒºæ¼”åŒ–ç»“æœ

**æ¼”åŒ–äº‹ä»¶**:

- ç¤¾åŒºå½¢æˆï¼š50+ä¸ªäº‹ä»¶
- ç¤¾åŒºåˆ†è£‚ï¼š30+ä¸ªäº‹ä»¶
- ç¤¾åŒºåˆå¹¶ï¼š20+ä¸ªäº‹ä»¶

### 4.2 æ‹“æ‰‘æ¼”åŒ–ç»“æœ

**æ‹“æ‰‘å˜åŒ–**:

- Î²â‚€ï¼ˆè¿é€šåˆ†é‡ï¼‰å˜åŒ–ï¼šç¨³å®š
- Î²â‚ï¼ˆå¾ªç¯æ•°ï¼‰å˜åŒ–ï¼šå¢åŠ 
- ç½‘ç»œæ‹“æ‰‘ç»“æ„ï¼šä»å°ä¸–ç•Œå‘æ— æ ‡åº¦æ¼”åŒ–

---

## ğŸ’¡ **äº”ã€ç»éªŒæ€»ç»“ / Part 5: Lessons Learned**

### 5.1 å»ºæ¨¡ç»éªŒ

1. **æ—¶åºå»ºæ¨¡**: åˆç†é€‰æ‹©æ—¶é—´çª—å£ï¼Œå¹³è¡¡ç²¾åº¦å’Œæ•ˆç‡
2. **ç¤¾åŒºæ£€æµ‹**: é€‰æ‹©åˆé€‚çš„ç¤¾åŒºæ£€æµ‹ç®—æ³•
3. **æ¼”åŒ–è¿½è¸ª**: ä½¿ç”¨é‡å åº¦åŒ¹é…ç¤¾åŒº

### 5.2 ä¼˜åŒ–æŠ€å·§

1. **å¢é‡è®¡ç®—**: ä½¿ç”¨å¢é‡ç®—æ³•è®¡ç®—ç¤¾åŒº
2. **é‡‡æ ·ä¼˜åŒ–**: å¯¹äºè¶…å¤§è§„æ¨¡æ•°æ®ï¼Œä½¿ç”¨é‡‡æ ·
3. **å¹¶è¡Œè®¡ç®—**: ä½¿ç”¨åˆ†å¸ƒå¼æ¡†æ¶åŠ é€Ÿè®¡ç®—

---

## ğŸ“š **å…­ã€å‚è€ƒæ–‡æ¡£ / Part 6: Reference Documents**

### 6.1 ç›¸å…³æ–‡æ¡£

- [ç¤¾ä¼šç½‘ç»œåº”ç”¨æ¨¡å¼æ¸…å•](./ç¤¾ä¼šç½‘ç»œåº”ç”¨æ¨¡å¼æ¸…å•.md)
- [å›¾è®ºåŸºç¡€æ¨¡å—](../../01-å›¾è®ºåŸºç¡€/README.md)

### 6.2 å·¥å…·å‚è€ƒ

- [NetworkXæ–‡æ¡£](https://networkx.org/documentation/)
- [GUDHIæ–‡æ¡£](https://gudhi.inria.fr/documentation/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**çŠ¶æ€**: âœ… å®Œæˆ
**ç»´æŠ¤è€…**: GraphNetWorkCommunicateé¡¹ç›®ç»„
