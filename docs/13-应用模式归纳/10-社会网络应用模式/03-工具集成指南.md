# ç¤¾ä¼šç½‘ç»œåº”ç”¨æ¨¡å¼å·¥å…·é›†æˆæŒ‡å— / Tool Integration Guide

## ğŸ“š **æ¦‚è¿° / Overview**

æœ¬æ–‡æ¡£æä¾›ç¤¾ä¼šç½‘ç»œåˆ†æåº”ç”¨æ¨¡å¼æ‰€éœ€å·¥å…·çš„é›†æˆé…ç½®æŒ‡å—ï¼Œæ¶µç›–å›¾åˆ†æåº“ã€ç¤¾åŒºæ£€æµ‹ã€å½±å“åŠ›åˆ†æã€å¯è§†åŒ–ç­‰æ ¸å¿ƒå·¥å…·ã€‚

**åˆ›å»ºæ—¶é—´**: 2025å¹´2æœˆ
**çŠ¶æ€**: âœ… å®Œæˆ

---

## ä¸€ã€å·¥å…·æ ˆæ€»è§ˆ / Tool Stack Overview

| ç±»åˆ« | å·¥å…· | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|------|
| å›¾åˆ†æ | NetworkX | 3.x | åŸºç¡€å›¾ç®—æ³• |
| å›¾åˆ†æ | igraph | 0.11+ | é«˜æ€§èƒ½å›¾ç®—æ³• |
| å›¾åˆ†æ | graph-tool | 2.x | ç»Ÿè®¡æ¨æ–­ |
| å¤§è§„æ¨¡ | Spark GraphX | 3.x | åˆ†å¸ƒå¼å›¾è®¡ç®— |
| å¯è§†åŒ– | Gephi | 0.10+ | äº¤äº’å¼å¯è§†åŒ– |
| å¯è§†åŒ– | PyVis | 0.3+ | Web å¯è§†åŒ– |
| å­˜å‚¨ | Neo4j | 5.x | å›¾æ•°æ®åº“ |
| æœºå™¨å­¦ä¹  | node2vec | 0.4+ | å›¾åµŒå…¥ |

---

## äºŒã€NetworkX é›†æˆ / NetworkX Integration

### 2.1 å®‰è£…ä¸åŸºç¡€ä½¿ç”¨

```bash
pip install networkx[default]
```

```python
import networkx as nx

# åˆ›å»ºç¤¾ä¼šç½‘ç»œ
G = nx.Graph()
G.add_edges_from([
    ("Alice", "Bob", {"weight": 0.9}),
    ("Bob", "Charlie", {"weight": 0.7}),
    ("Alice", "Charlie", {"weight": 0.5}),
])

# åŸºç¡€æŒ‡æ ‡
print(f"èŠ‚ç‚¹æ•°: {G.number_of_nodes()}")
print(f"è¾¹æ•°: {G.number_of_edges()}")
print(f"å¯†åº¦: {nx.density(G):.4f}")
```

### 2.2 ä¸­å¿ƒæ€§åˆ†æ

```python
class CentralityAnalyzer:
    """ä¸­å¿ƒæ€§åˆ†æå™¨"""

    def __init__(self, graph: nx.Graph):
        self.G = graph

    def analyze_all(self) -> dict:
        """è®¡ç®—æ‰€æœ‰ä¸­å¿ƒæ€§æŒ‡æ ‡"""
        return {
            "degree": nx.degree_centrality(self.G),
            "betweenness": nx.betweenness_centrality(self.G),
            "closeness": nx.closeness_centrality(self.G),
            "eigenvector": nx.eigenvector_centrality(self.G, max_iter=1000),
            "pagerank": nx.pagerank(self.G)
        }

    def find_key_nodes(self, metric: str = "pagerank", top_k: int = 10) -> list:
        """æ‰¾å‡ºå…³é”®èŠ‚ç‚¹"""
        centralities = self.analyze_all()[metric]
        sorted_nodes = sorted(centralities.items(), key=lambda x: x[1], reverse=True)
        return sorted_nodes[:top_k]
```

### 2.3 ç¤¾åŒºæ£€æµ‹

```python
from networkx.algorithms import community

class CommunityDetector:
    """ç¤¾åŒºæ£€æµ‹å™¨"""

    def __init__(self, graph: nx.Graph):
        self.G = graph

    def louvain(self) -> list:
        """Louvain ç®—æ³•"""
        return list(community.louvain_communities(self.G))

    def label_propagation(self) -> list:
        """æ ‡ç­¾ä¼ æ’­ç®—æ³•"""
        return list(community.label_propagation_communities(self.G))

    def girvan_newman(self, k: int = 5) -> list:
        """Girvan-Newman ç®—æ³•"""
        comp = community.girvan_newman(self.G)
        for _ in range(k - 1):
            communities = next(comp)
        return list(communities)

    def evaluate(self, communities: list) -> dict:
        """è¯„ä¼°ç¤¾åŒºè´¨é‡"""
        return {
            "modularity": community.modularity(self.G, communities),
            "num_communities": len(communities),
            "avg_size": sum(len(c) for c in communities) / len(communities)
        }
```

---

## ä¸‰ã€igraph é›†æˆ / igraph Integration

### 3.1 å®‰è£…ä¸å¤§è§„æ¨¡åˆ†æ

```bash
pip install igraph
```

```python
import igraph as ig

class HighPerformanceAnalyzer:
    """é«˜æ€§èƒ½å›¾åˆ†æå™¨ï¼ˆåŸºäº igraphï¼‰"""

    def __init__(self, edge_list: list):
        self.g = ig.Graph.TupleList(edge_list, directed=False)

    def fast_community_detection(self, method: str = "louvain") -> ig.VertexClustering:
        """å¿«é€Ÿç¤¾åŒºæ£€æµ‹"""
        if method == "louvain":
            return self.g.community_multilevel()
        elif method == "infomap":
            return self.g.community_infomap()
        elif method == "label_propagation":
            return self.g.community_label_propagation()

    def fast_centrality(self, metric: str = "betweenness") -> list:
        """å¿«é€Ÿä¸­å¿ƒæ€§è®¡ç®—"""
        if metric == "betweenness":
            return self.g.betweenness()
        elif metric == "closeness":
            return self.g.closeness()
        elif metric == "pagerank":
            return self.g.pagerank()

    def to_networkx(self) -> nx.Graph:
        """è½¬æ¢ä¸º NetworkX"""
        return self.g.to_networkx()
```

### 3.2 æ€§èƒ½å¯¹æ¯”

```python
import time

def benchmark(graph_size: int = 10000):
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    # ç”Ÿæˆéšæœºå›¾
    edges = [(i, (i + 1) % graph_size) for i in range(graph_size)]
    edges += [(i, (i + 100) % graph_size) for i in range(graph_size)]

    # NetworkX
    G_nx = nx.Graph(edges)
    start = time.time()
    nx.betweenness_centrality(G_nx)
    nx_time = time.time() - start

    # igraph
    G_ig = ig.Graph.TupleList(edges)
    start = time.time()
    G_ig.betweenness()
    ig_time = time.time() - start

    print(f"NetworkX: {nx_time:.2f}s, igraph: {ig_time:.2f}s")
    print(f"åŠ é€Ÿæ¯”: {nx_time / ig_time:.1f}x")
```

---

## å››ã€å½±å“åŠ›ä¼ æ’­åˆ†æ / Influence Propagation

### 4.1 ä¼ æ’­æ¨¡å‹

```python
import numpy as np
from typing import Set

class PropagationModels:
    """ä¼ æ’­æ¨¡å‹é›†åˆ"""

    def __init__(self, graph: nx.Graph):
        self.G = graph

    def independent_cascade(self, seeds: Set, p: float = 0.1) -> Set:
        """ç‹¬ç«‹çº§è”æ¨¡å‹"""
        activated = set(seeds)
        newly_activated = set(seeds)

        while newly_activated:
            next_activated = set()
            for node in newly_activated:
                for neighbor in self.G.neighbors(node):
                    if neighbor not in activated:
                        if np.random.random() < p:
                            next_activated.add(neighbor)
            activated.update(next_activated)
            newly_activated = next_activated

        return activated

    def linear_threshold(self, seeds: Set, thresholds: dict = None) -> Set:
        """çº¿æ€§é˜ˆå€¼æ¨¡å‹"""
        if thresholds is None:
            thresholds = {n: np.random.random() for n in self.G.nodes()}

        activated = set(seeds)
        changed = True

        while changed:
            changed = False
            for node in self.G.nodes():
                if node not in activated:
                    # è®¡ç®—é‚»å±…å½±å“
                    influence = sum(
                        self.G[neighbor][node].get('weight', 1.0)
                        for neighbor in self.G.neighbors(node)
                        if neighbor in activated
                    )
                    # å½’ä¸€åŒ–
                    total_weight = sum(
                        self.G[neighbor][node].get('weight', 1.0)
                        for neighbor in self.G.neighbors(node)
                    )
                    if total_weight > 0 and influence / total_weight >= thresholds[node]:
                        activated.add(node)
                        changed = True

        return activated

    def sir_model(self, seeds: Set, beta: float = 0.3, gamma: float = 0.1,
                  max_steps: int = 100) -> dict:
        """SIR ä¼ æ’­æ¨¡å‹"""
        susceptible = set(self.G.nodes()) - seeds
        infected = set(seeds)
        recovered = set()

        history = {"S": [len(susceptible)], "I": [len(infected)], "R": [len(recovered)]}

        for _ in range(max_steps):
            # æ„ŸæŸ“
            new_infected = set()
            for node in infected:
                for neighbor in self.G.neighbors(node):
                    if neighbor in susceptible and np.random.random() < beta:
                        new_infected.add(neighbor)

            # æ¢å¤
            new_recovered = {n for n in infected if np.random.random() < gamma}

            # æ›´æ–°çŠ¶æ€
            susceptible -= new_infected
            infected = (infected | new_infected) - new_recovered
            recovered |= new_recovered

            history["S"].append(len(susceptible))
            history["I"].append(len(infected))
            history["R"].append(len(recovered))

            if not infected:
                break

        return history
```

### 4.2 å½±å“åŠ›æœ€å¤§åŒ–

```python
class InfluenceMaximization:
    """å½±å“åŠ›æœ€å¤§åŒ–"""

    def __init__(self, graph: nx.Graph, model: PropagationModels):
        self.G = graph
        self.model = model

    def greedy(self, k: int, p: float = 0.1, simulations: int = 100) -> list:
        """è´ªå¿ƒç®—æ³•"""
        seeds = []

        for _ in range(k):
            best_node = None
            best_spread = 0

            for node in self.G.nodes():
                if node in seeds:
                    continue

                # æ¨¡æ‹Ÿä¼ æ’­
                total_spread = 0
                for _ in range(simulations):
                    spread = len(self.model.independent_cascade(set(seeds + [node]), p))
                    total_spread += spread
                avg_spread = total_spread / simulations

                if avg_spread > best_spread:
                    best_spread = avg_spread
                    best_node = node

            seeds.append(best_node)

        return seeds

    def celf(self, k: int, p: float = 0.1, simulations: int = 100) -> list:
        """CELF ä¼˜åŒ–ç®—æ³•"""
        import heapq

        # åˆå§‹åŒ–è¾¹é™…æ”¶ç›Š
        marginal_gains = []
        for node in self.G.nodes():
            spread = sum(
                len(self.model.independent_cascade({node}, p))
                for _ in range(simulations)
            ) / simulations
            heapq.heappush(marginal_gains, (-spread, 0, node))

        seeds = []
        current_spread = 0

        while len(seeds) < k:
            while True:
                neg_gain, iteration, node = heapq.heappop(marginal_gains)

                if iteration == len(seeds):
                    # è¾¹é™…æ”¶ç›Šæ˜¯æœ€æ–°çš„
                    seeds.append(node)
                    current_spread -= neg_gain
                    break
                else:
                    # é‡æ–°è®¡ç®—è¾¹é™…æ”¶ç›Š
                    new_spread = sum(
                        len(self.model.independent_cascade(set(seeds + [node]), p))
                        for _ in range(simulations)
                    ) / simulations
                    new_gain = new_spread - current_spread
                    heapq.heappush(marginal_gains, (-new_gain, len(seeds), node))

        return seeds
```

---

## äº”ã€å¯è§†åŒ–é›†æˆ / Visualization Integration

### 5.1 PyVis Web å¯è§†åŒ–

```python
from pyvis.network import Network

class SocialNetworkVisualizer:
    """ç¤¾ä¼šç½‘ç»œå¯è§†åŒ–å™¨"""

    def __init__(self, graph: nx.Graph):
        self.G = graph

    def create_interactive(self, output_path: str = "network.html",
                          communities: list = None):
        """åˆ›å»ºäº¤äº’å¼å¯è§†åŒ–"""
        net = Network(height="750px", width="100%", notebook=False)

        # æ·»åŠ èŠ‚ç‚¹
        if communities:
            colors = self._generate_colors(len(communities))
            node_colors = {}
            for i, comm in enumerate(communities):
                for node in comm:
                    node_colors[node] = colors[i]

        for node in self.G.nodes():
            color = node_colors.get(node, "#97c2fc") if communities else "#97c2fc"
            net.add_node(node, label=str(node), color=color)

        # æ·»åŠ è¾¹
        for src, dst, data in self.G.edges(data=True):
            weight = data.get('weight', 1.0)
            net.add_edge(src, dst, value=weight)

        # é…ç½®ç‰©ç†å¼•æ“
        net.set_options("""
        var options = {
          "physics": {
            "forceAtlas2Based": {
              "gravitationalConstant": -50,
              "centralGravity": 0.01,
              "springLength": 100,
              "springConstant": 0.08
            },
            "solver": "forceAtlas2Based"
          }
        }
        """)

        net.save_graph(output_path)
        return output_path

    def _generate_colors(self, n: int) -> list:
        """ç”Ÿæˆ n ç§é¢œè‰²"""
        import colorsys
        colors = []
        for i in range(n):
            hue = i / n
            rgb = colorsys.hsv_to_rgb(hue, 0.7, 0.9)
            colors.append('#%02x%02x%02x' % tuple(int(x * 255) for x in rgb))
        return colors
```

### 5.2 Gephi å¯¼å‡º

```python
def export_to_gephi(graph: nx.Graph, output_path: str):
    """å¯¼å‡ºä¸º Gephi æ ¼å¼"""
    nx.write_gexf(graph, output_path)
    print(f"å·²å¯¼å‡ºåˆ° {output_path}ï¼Œå¯åœ¨ Gephi ä¸­æ‰“å¼€")
```

---

## å…­ã€Neo4j å›¾æ•°æ®åº“é›†æˆ / Neo4j Integration

```python
from neo4j import GraphDatabase

class SocialGraphDB:
    """ç¤¾ä¼šç½‘ç»œå›¾æ•°æ®åº“"""

    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def import_from_networkx(self, G: nx.Graph):
        """ä» NetworkX å¯¼å…¥"""
        with self.driver.session() as session:
            # åˆ›å»ºèŠ‚ç‚¹
            for node, attrs in G.nodes(data=True):
                session.run(
                    "MERGE (n:Person {name: $name}) SET n += $attrs",
                    name=str(node), attrs=attrs
                )

            # åˆ›å»ºè¾¹
            for src, dst, attrs in G.edges(data=True):
                session.run("""
                    MATCH (a:Person {name: $src}), (b:Person {name: $dst})
                    MERGE (a)-[r:KNOWS]->(b)
                    SET r += $attrs
                """, src=str(src), dst=str(dst), attrs=attrs)

    def run_gds_algorithm(self, algorithm: str, config: dict) -> list:
        """è¿è¡Œ Neo4j GDS ç®—æ³•"""
        with self.driver.session() as session:
            if algorithm == "pagerank":
                result = session.run("""
                    CALL gds.pageRank.stream('myGraph')
                    YIELD nodeId, score
                    RETURN gds.util.asNode(nodeId).name AS name, score
                    ORDER BY score DESC
                    LIMIT 10
                """)
            elif algorithm == "louvain":
                result = session.run("""
                    CALL gds.louvain.stream('myGraph')
                    YIELD nodeId, communityId
                    RETURN gds.util.asNode(nodeId).name AS name, communityId
                """)
            return [record.data() for record in result]
```

---

## ä¸ƒã€å®Œæ•´é›†æˆç¤ºä¾‹ / Complete Integration Example

```python
class SocialNetworkAnalysisPipeline:
    """ç¤¾ä¼šç½‘ç»œåˆ†æå®Œæ•´æµæ°´çº¿"""

    def __init__(self, graph: nx.Graph):
        self.G = graph
        self.centrality = CentralityAnalyzer(graph)
        self.community = CommunityDetector(graph)
        self.propagation = PropagationModels(graph)
        self.visualizer = SocialNetworkVisualizer(graph)

    def full_analysis(self) -> dict:
        """å®Œæ•´åˆ†æ"""
        # 1. åŸºç¡€ç»Ÿè®¡
        stats = {
            "nodes": self.G.number_of_nodes(),
            "edges": self.G.number_of_edges(),
            "density": nx.density(self.G),
            "avg_clustering": nx.average_clustering(self.G)
        }

        # 2. ä¸­å¿ƒæ€§åˆ†æ
        key_nodes = self.centrality.find_key_nodes("pagerank", 10)

        # 3. ç¤¾åŒºæ£€æµ‹
        communities = self.community.louvain()
        community_metrics = self.community.evaluate(communities)

        # 4. å½±å“åŠ›åˆ†æ
        im = InfluenceMaximization(self.G, self.propagation)
        influencers = im.celf(k=5)

        # 5. å¯è§†åŒ–
        viz_path = self.visualizer.create_interactive(communities=communities)

        return {
            "statistics": stats,
            "key_nodes": key_nodes,
            "communities": community_metrics,
            "influencers": influencers,
            "visualization": viz_path
        }
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025å¹´2æœˆ
**æœ€åæ›´æ–°**: 2025å¹´2æœˆ
**ç»´æŠ¤è€…**: GraphNetWorkCommunicateé¡¹ç›®ç»„
