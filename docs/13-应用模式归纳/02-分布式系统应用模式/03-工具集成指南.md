# åˆ†å¸ƒå¼ç³»ç»Ÿåº”ç”¨æ¨¡å¼å·¥å…·é›†æˆæŒ‡å— / Distributed Systems Tools Integration Guide

## ğŸ“š **æ¦‚è¿° / Overview**

**æ–‡æ¡£ç›®çš„**: æä¾›åˆ†å¸ƒå¼ç³»ç»Ÿé¢†åŸŸåº”ç”¨æ¨¡å¼çš„å®Œæ•´å·¥å…·é›†æˆæŒ‡å—ï¼ŒåŒ…æ‹¬Petriç½‘ã€åŠ¨æ€å›¾è®ºã€æ‹“æ‰‘æ¨¡å‹ç›¸å…³å·¥å…·çš„å®‰è£…ã€é…ç½®ã€é›†æˆå’Œä½¿ç”¨æ–¹æ³•ã€‚

**é€‚ç”¨å¯¹è±¡**: åˆ†å¸ƒå¼ç³»ç»Ÿæ¶æ„å¸ˆã€ç³»ç»Ÿå·¥ç¨‹å¸ˆã€åˆ†å¸ƒå¼ç³»ç»Ÿç ”ç©¶äººå‘˜

**ç›¸å…³æ–‡æ¡£**:
- [åˆ†å¸ƒå¼ç³»ç»Ÿåº”ç”¨æ¨¡å¼æ¸…å•](åˆ†å¸ƒå¼ç³»ç»Ÿåº”ç”¨æ¨¡å¼æ¸…å•.md)
- [å·¥å…·é›†æˆä¸é…ç½®æŒ‡å—](../å·¥å…·é›†æˆä¸é…ç½®æŒ‡å—.md)

---

## ğŸ¯ **ä¸€ã€Petriç½‘å·¥å…·é›†æˆ / Part 1: Petri Net Tools Integration**

### 1.1 TLA+é›†æˆï¼ˆRaftåè®®éªŒè¯ï¼‰

**å®‰è£…**:
```bash
# ä¸‹è½½TLA+ Toolbox
wget https://github.com/tlaplus/tlaplus/releases/latest/download/TLAToolbox-linux.gtk.x86_64.zip
unzip TLAToolbox-linux.gtk.x86_64.zip -d /opt/tlaplus
export TLA_PATH=/opt/tlaplus
```

**Pythoné›†æˆ**:
```python
import subprocess
import os

class TLAIntegration:
    def verify_raft_protocol(self, spec_file: str):
        """éªŒè¯Raftåè®®"""
        cmd = [os.path.join(os.environ['TLA_PATH'], 'tlc'), spec_file]
        result = subprocess.run(cmd, capture_output=True, text=True)
        return {'success': result.returncode == 0, 'output': result.stdout}
```

### 1.2 CPN Toolsé›†æˆï¼ˆ2PCåè®®éªŒè¯ï¼‰

**Pythoné›†æˆ**:
```python
class CPNToolsIntegration:
    def verify_2pc_atomicity(self, model_file: str):
        """éªŒè¯2PCåŸå­æ€§"""
        # CPN Toolså‘½ä»¤æ‰§è¡Œ
        pass
```

---

## ğŸ”§ **äºŒã€åŠ¨æ€å›¾è®ºå·¥å…·é›†æˆ / Part 2: Dynamic Graph Tools Integration**

### 2.1 Jaegeré›†æˆï¼ˆåˆ†å¸ƒå¼è¿½è¸ªï¼‰

**å®‰è£…**:
```bash
docker run -d --name jaeger \
  -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 14250:14250 \
  -p 9411:9411 \
  jaegertracing/all-in-one:latest
```

**Pythoné›†æˆ**:
```python
from jaeger_client import Config

class JaegerIntegration:
    def __init__(self, service_name: str):
        config = Config(
            config={'sampler': {'type': 'const', 'param': 1}},
            service_name=service_name
        )
        self.tracer = config.initialize_tracer()
    
    def trace_service_call(self, caller: str, callee: str):
        """è¿½è¸ªæœåŠ¡è°ƒç”¨"""
        with self.tracer.start_span('service_call') as span:
            span.set_tag('caller', caller)
            span.set_tag('callee', callee)
            # æ‰§è¡Œè°ƒç”¨
            return result
```

### 2.2 Neo4jé›†æˆï¼ˆæœåŠ¡ä¾èµ–å›¾ï¼‰

**Pythoné›†æˆ**:
```python
from neo4j import GraphDatabase

class Neo4jIntegration:
    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
    
    def store_service_dependencies(self, dependencies: list):
        """å­˜å‚¨æœåŠ¡ä¾èµ–"""
        with self.driver.session() as session:
            for dep in dependencies:
                session.run("""
                    MERGE (a:Service {name: $caller})
                    MERGE (b:Service {name: $callee})
                    MERGE (a)-[r:CALLS]->(b)
                """, caller=dep['caller'], callee=dep['callee'])
```

### 2.3 Prometheusé›†æˆï¼ˆç›‘æ§ï¼‰

**å®‰è£…**:
```bash
wget https://github.com/prometheus/prometheus/releases/download/v2.45.0/prometheus-2.45.0.linux-amd64.tar.gz
tar -xzf prometheus-2.45.0.linux-amd64.tar.gz
cd prometheus-2.45.0
./prometheus --config.file=prometheus.yml
```

**Pythoné›†æˆ**:
```python
from prometheus_client import Counter, Histogram, start_http_server

class PrometheusIntegration:
    def __init__(self):
        self.request_count = Counter('service_requests_total', 'Total requests')
        self.request_latency = Histogram('service_latency_seconds', 'Request latency')
    
    def record_request(self, duration: float):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        self.request_count.inc()
        self.request_latency.observe(duration)
```

---

## ğŸ”¬ **ä¸‰ã€æ‹“æ‰‘åˆ†æå·¥å…·é›†æˆ / Part 3: Topological Analysis Tools Integration**

### 3.1 GUDHIé›†æˆï¼ˆæœåŠ¡ç½‘æ ¼æ‹“æ‰‘åˆ†æï¼‰

**Pythoné›†æˆ**:
```python
from gudhi import RipsComplex

class ServiceMeshTopologyAnalyzer:
    def analyze_mesh_topology(self, service_features: np.ndarray):
        """åˆ†ææœåŠ¡ç½‘æ ¼æ‹“æ‰‘"""
        rips_complex = RipsComplex(points=service_features, max_edge_length=10.0)
        simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)
        persistence = simplex_tree.persistence()
        return persistence
```

---

## ğŸ”„ **å››ã€å·¥å…·ç»„åˆä½¿ç”¨ç¤ºä¾‹ / Part 4: Tool Combination Examples**

### 4.1 å¾®æœåŠ¡è°ƒç”¨é“¾åˆ†æå®Œæ•´æµç¨‹

```python
class MicroserviceAnalysisPipeline:
    def __init__(self):
        self.jaeger = JaegerIntegration('analysis-service')
        self.neo4j = Neo4jIntegration('bolt://localhost:7687', 'neo4j', 'password')
        self.prometheus = PrometheusIntegration()
    
    def analyze_call_chain(self, trace_id: str):
        """åˆ†æè°ƒç”¨é“¾"""
        # 1. ä»Jaegerè·å–è¿½è¸ªæ•°æ®
        trace = self.jaeger.get_trace(trace_id)
        
        # 2. å­˜å‚¨åˆ°Neo4j
        self.neo4j.store_trace(trace)
        
        # 3. åˆ†æå…³é”®è·¯å¾„
        critical_paths = self.neo4j.find_critical_paths()
        
        # 4. è®°å½•æŒ‡æ ‡
        self.prometheus.record_analysis_metrics(critical_paths)
        
        return critical_paths
```

---

## ğŸš€ **äº”ã€Graph Transformerå’ŒPGNNå·¥å…·é›†æˆï¼ˆ2025æœ€æ–°ï¼‰/ Part 5: Graph Transformer and PGNN Tools Integration (2025 Latest)**

### 5.1 PyTorch Geometricé›†æˆï¼ˆGraph Transformerï¼‰

**å®‰è£…**:
```bash
pip install torch torch-geometric
```

**Pythoné›†æˆ**:
```python
import torch
import torch.nn as nn
from torch_geometric.data import Data
from torch_geometric.nn import TransformerConv

class DistributedSystemFaultPredictorGTIntegration:
    """åˆ†å¸ƒå¼ç³»ç»Ÿæ•…éšœé¢„æµ‹Graph Transformeré›†æˆ"""
    
    def __init__(self, input_dim, hidden_dim=128, num_layers=3, num_heads=8):
        self.model = self._build_model(input_dim, hidden_dim, num_layers, num_heads)
        self.fault_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
    
    def _build_model(self, input_dim, hidden_dim, num_layers, num_heads):
        """æ„å»ºGraph Transformeræ¨¡å‹"""
        layers = []
        layers.append(TransformerConv(input_dim, hidden_dim, heads=num_heads))
        
        for _ in range(num_layers - 1):
            layers.append(TransformerConv(hidden_dim, hidden_dim, heads=num_heads))
        
        return nn.Sequential(*layers)
    
    def predict_faults(self, node_features, edge_index):
        """é¢„æµ‹æ•…éšœ"""
        data = Data(x=node_features, edge_index=edge_index)
        node_embeddings = self.model(data.x, data.edge_index)
        fault_scores = self.fault_head(node_embeddings)
        return fault_scores
```

### 5.2 PyTorché›†æˆï¼ˆPGNNï¼‰

**Pythoné›†æˆ**:
```python
import torch
import torch.nn as nn
import networkx as nx

class DistributedSystemFaultPredictorPGNNIntegration:
    """åˆ†å¸ƒå¼ç³»ç»Ÿæ•…éšœé¢„æµ‹PGNNé›†æˆ"""
    
    def __init__(self, num_services, num_resources, hidden_dim=128):
        self.service_embedding = nn.Embedding(num_services, hidden_dim)
        self.resource_embedding = nn.Embedding(num_resources, hidden_dim)
        
        self.propagation_layers = nn.ModuleList([
            nn.Linear(hidden_dim, hidden_dim) for _ in range(3)
        ])
        
        self.fault_head = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
    
    def predict_faults(self, distributed_petri_net, service_features, resource_features):
        """é¢„æµ‹æ•…éšœ"""
        embeddings = {}
        for node in distributed_petri_net.nodes():
            if distributed_petri_net.nodes[node]['type'] == 'service':
                svc_idx = distributed_petri_net.nodes[node]['index']
                embeddings[node] = self.service_embedding(svc_idx) + service_features[svc_idx]
            else:
                res_idx = distributed_petri_net.nodes[node]['index']
                embeddings[node] = self.resource_embedding(res_idx) + resource_features[res_idx]
        
        # PGNNä¼ æ’­ï¼ˆåŸºäºPetriç½‘æµçº¦æŸï¼‰
        for layer in self.propagation_layers:
            new_embeddings = {}
            for node in distributed_petri_net.nodes():
                neighbor_embeddings = [embeddings[n] for n in distributed_petri_net.neighbors(node)]
                if neighbor_embeddings:
                    aggregated = torch.stack(neighbor_embeddings).mean(dim=0)
                    new_embeddings[node] = layer(aggregated)
                else:
                    new_embeddings[node] = embeddings[node]
            embeddings = new_embeddings
        
        # é¢„æµ‹æ•…éšœæ¦‚ç‡
        fault_scores = {}
        for service_node in distributed_petri_net.nodes():
            if distributed_petri_net.nodes[service_node]['type'] == 'service':
                node_emb = embeddings[service_node]
                fault_score = self.fault_head(node_emb)
                fault_scores[service_node] = fault_score
        
        return fault_scores
```

---

## ğŸ“‹ **å…­ã€æœ€ä½³å®è·µ / Part 6: Best Practices**

### 5.1 å·¥å…·é€‰æ‹©å»ºè®®

| åœºæ™¯ | æ¨èå·¥å…· | ç†ç”± |
|------|----------|------|
| åè®®éªŒè¯ | TLA+ / CPN Tools | å½¢å¼åŒ–éªŒè¯ |
| åˆ†å¸ƒå¼è¿½è¸ª | Jaeger / Zipkin | å®Œæ•´è°ƒç”¨é“¾ |
| æœåŠ¡ä¾èµ– | Neo4j | å¤æ‚æŸ¥è¯¢ |
| ç›‘æ§ | Prometheus | æ—¶é—´åºåˆ—æ•°æ® |
| æ•…éšœé¢„æµ‹ï¼ˆ2025ï¼‰ | Graph Transformer / PGNN | æ·±åº¦å­¦ä¹ æ•…éšœé¢„æµ‹ |
| æ€§èƒ½ä¼˜åŒ–ï¼ˆ2025ï¼‰ | Graph Transformer | å…¨å±€æ³¨æ„åŠ›æœºåˆ¶ |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ  
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ  
**çŠ¶æ€**: âœ… å®Œæˆ
