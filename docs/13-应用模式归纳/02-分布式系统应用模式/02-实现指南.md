# åˆ†å¸ƒå¼ç³»ç»Ÿåº”ç”¨æ¨¡å¼å®ç°æŒ‡å— / Distributed Systems Application Patterns Implementation Guide

## ğŸ“š **æ¦‚è¿° / Overview**

**æ–‡æ¡£ç›®çš„**: æä¾›åˆ†å¸ƒå¼ç³»ç»Ÿé¢†åŸŸåº”ç”¨æ¨¡å¼çš„è¯¦ç»†å®ç°æŒ‡å—ï¼ŒåŒ…æ‹¬å·¥å…·é…ç½®ã€ä»£ç ç¤ºä¾‹ã€æœ€ä½³å®è·µã€‚

**é€‚ç”¨å¯¹è±¡**: åˆ†å¸ƒå¼ç³»ç»Ÿæ¶æ„å¸ˆã€ç³»ç»Ÿå·¥ç¨‹å¸ˆã€åˆ†å¸ƒå¼ç³»ç»Ÿç ”ç©¶äººå‘˜

---

## ğŸ¯ **ä¸€ã€ç¯å¢ƒå‡†å¤‡ / Part 1: Environment Setup**

### 1.1 Petriç½‘å·¥å…·å®‰è£…

#### TLA+ Toolbox

**å®‰è£…æ­¥éª¤**:

1. ä¸‹è½½TLA+ Toolboxï¼š<https://github.com/tlaplus/tlaplus/releases>
2. å®‰è£…Javaè¿è¡Œç¯å¢ƒï¼ˆJRE 11+ï¼‰
3. é…ç½®TLA+è·¯å¾„

**é…ç½®è¦ç‚¹**:

```bash
export TLA_PATH=/path/to/tlaplus
export PATH=$PATH:$TLA_PATH/bin
```

#### CPN Tools

**å®‰è£…æ­¥éª¤**:

1. ä¸‹è½½CPN Toolsï¼š<https://cpntools.org/download>
2. å®‰è£…Javaè¿è¡Œç¯å¢ƒ
3. é…ç½®ç¯å¢ƒå˜é‡

### 1.2 åŠ¨æ€å›¾è®ºå·¥å…·å®‰è£…

#### NetworkX + Neo4j

**å®‰è£…æ­¥éª¤**:

```bash
pip install networkx
pip install neo4j
pip install py2neo
```

#### Apache Flink

**å®‰è£…æ­¥éª¤**:

1. ä¸‹è½½Flinkï¼š<https://flink.apache.org/downloads.html>
2. é…ç½®ç¯å¢ƒå˜é‡
3. å¯åŠ¨Flinké›†ç¾¤

### 1.3 åˆ†å¸ƒå¼ç³»ç»Ÿä¸“ç”¨å·¥å…·

#### Consul / etcd

**å®‰è£…æ­¥éª¤**:

```bash
# Consul
wget https://releases.hashicorp.com/consul/1.15.0/consul_1.15.0_linux_amd64.zip
unzip consul_1.15.0_linux_amd64.zip
sudo mv consul /usr/local/bin/

# etcd
wget https://github.com/etcd-io/etcd/releases/download/v3.5.0/etcd-v3.5.0-linux-amd64.tar.gz
tar -xzf etcd-v3.5.0-linux-amd64.tar.gz
```

---

## ğŸ”§ **äºŒã€å…±è¯†åè®®éªŒè¯å®ç° / Part 2: Consensus Protocol Verification Implementation**

### 2.1 Raftåè®®TLA+å®ç°

**å®Œæ•´TLA+è§„èŒƒ**:

```tla
EXTENDS Naturals, TLC, Sequences

CONSTANTS Nodes, Quorum, MaxTerm

VARIABLES
    nodeState,
    currentTerm,
    votedFor,
    log,
    commitIndex

TypeOK ==
    /\ nodeState \in [Nodes -> {"Follower", "Candidate", "Leader"}]
    /\ currentTerm \in [Nodes -> 1..MaxTerm]
    /\ votedFor \in [Nodes -> Nodes \cup {nil}]
    /\ log \in [Nodes -> Seq(LogEntry)]
    /\ commitIndex \in [Nodes -> 0..Len(log)]

Init ==
    /\ nodeState = [n \in Nodes |-> "Follower"]
    /\ currentTerm = [n \in Nodes |-> 1]
    /\ votedFor = [n \in Nodes |-> nil]
    /\ log = [n \in Nodes |-> <<>>]
    /\ commitIndex = [n \in Nodes |-> 0]

BecomeCandidate(n) ==
    /\ nodeState[n] = "Follower"
    /\ nodeState' = [nodeState EXCEPT ![n] = "Candidate"]
    /\ currentTerm' = [currentTerm EXCEPT ![n] = @ + 1]
    /\ votedFor' = [votedFor EXCEPT ![n] = n]
    /\ UNCHANGED <<log, commitIndex>>

RequestVote(n, m) ==
    /\ nodeState[n] = "Candidate"
    /\ nodeState[m] \in {"Follower", "Candidate"}
    /\ currentTerm[n] >= currentTerm[m]
    /\ (votedFor[m] = nil \/ votedFor[m] = n)
    /\ votedFor' = [votedFor EXCEPT ![m] = n]
    /\ UNCHANGED <<nodeState, currentTerm, log, commitIndex>>

BecomeLeader(n) ==
    /\ nodeState[n] = "Candidate"
    /\ Cardinality({m \in Nodes : votedFor[m] = n}) > Quorum
    /\ nodeState' = [nodeState EXCEPT ![n] = "Leader"]
    /\ UNCHANGED <<currentTerm, votedFor, log, commitIndex>>

AppendEntries(n, m) ==
    /\ nodeState[n] = "Leader"
    /\ nodeState[m] \in {"Follower", "Candidate"}
    /\ currentTerm[n] >= currentTerm[m]
    /\ log' = [log EXCEPT ![m] = Append(@, NewEntry())]
    /\ currentTerm' = [currentTerm EXCEPT ![m] = currentTerm[n]]
    /\ nodeState' = [nodeState EXCEPT ![m] = "Follower"]
    /\ UNCHANGED <<votedFor, commitIndex>>

Next ==
    \/ \E n \in Nodes : BecomeCandidate(n)
    \/ \E n, m \in Nodes : RequestVote(n, m)
    \/ \E n \in Nodes : BecomeLeader(n)
    \/ \E n, m \in Nodes : AppendEntries(n, m)

Spec == Init /\ [][Next]_<<nodeState, currentTerm, votedFor, log, commitIndex>>

SafetyProperty ==
    \A s \in ReachableStates :
        \A n1, n2 \in Nodes :
            /\ nodeState[n1] = "Leader"
            /\ nodeState[n2] = "Leader"
            /\ currentTerm[n1] = currentTerm[n2]
            => n1 = n2
```

### 2.2 éªŒè¯æ‰§è¡Œ

**TLCæ¨¡å‹æ£€éªŒå™¨é…ç½®**:

```tla
CONSTANTS
    Nodes = {n1, n2, n3}
    Quorum = 2
    MaxTerm = 10

INIT Init
NEXT Next

INVARIANTS
    SafetyProperty
    TypeOK
```

**è¿è¡ŒéªŒè¯**:

```bash
tlc Raft.tla
```

---

## ğŸ“Š **ä¸‰ã€å‰¯æœ¬æ‹“æ‰‘è¿½è¸ªå®ç° / Part 3: Replica Topology Tracking Implementation**

### 3.1 NetworkXå®ç°

**å‰¯æœ¬æ‹“æ‰‘å›¾æ„å»º**:

```python
import networkx as nx
from collections import defaultdict
from datetime import datetime

class ReplicaTopologyTracker:
    def __init__(self):
        self.graph = nx.DiGraph()
        self.replica_states = defaultdict(dict)
        self.sync_history = []

    def add_replica(self, replica_id, region, capacity):
        """
        æ·»åŠ å‰¯æœ¬èŠ‚ç‚¹
        """
        self.graph.add_node(replica_id,
                          region=region,
                          capacity=capacity,
                          state='active')
        self.replica_states[replica_id] = {
            'region': region,
            'capacity': capacity,
            'state': 'active'
        }

    def add_replication_link(self, source, target, latency, bandwidth):
        """
        æ·»åŠ å¤åˆ¶é“¾è·¯
        """
        self.graph.add_edge(source, target,
                          latency=latency,
                          bandwidth=bandwidth,
                          type='replication')

    def track_sync(self, source, target, data_size, timestamp):
        """
        è¿½è¸ªåŒæ­¥äº‹ä»¶
        """
        self.sync_history.append({
            'source': source,
            'target': target,
            'data_size': data_size,
            'timestamp': timestamp
        })

        # æ›´æ–°åŒæ­¥çŠ¶æ€
        if 'sync_count' not in self.graph[source][target]:
            self.graph[source][target]['sync_count'] = 0
        self.graph[source][target]['sync_count'] += 1

    def find_critical_replicas(self):
        """
        æ‰¾åˆ°å…³é”®å‰¯æœ¬ï¼ˆé«˜ä¸­å¿ƒæ€§ï¼‰
        """
        betweenness = nx.betweenness_centrality(self.graph)
        closeness = nx.closeness_centrality(self.graph)

        critical = sorted(
            betweenness.items(),
            key=lambda x: x[1],
            reverse=True
        )[:5]

        return critical

    def analyze_sync_paths(self, source, target):
        """
        åˆ†æåŒæ­¥è·¯å¾„
        """
        try:
            paths = list(nx.all_simple_paths(self.graph, source, target))

            # è®¡ç®—æ¯æ¡è·¯å¾„çš„å»¶è¿Ÿ
            path_delays = []
            for path in paths:
                total_latency = sum(
                    self.graph[path[i]][path[i+1]]['latency']
                    for i in range(len(path) - 1)
                )
                path_delays.append((path, total_latency))

            # è¿”å›æœ€çŸ­å»¶è¿Ÿè·¯å¾„
            return min(path_delays, key=lambda x: x[1])
        except nx.NetworkXNoPath:
            return None
```

### 3.2 Neo4jå®ç°

**Neo4jå›¾æ•°æ®åº“å­˜å‚¨**:

```python
from neo4j import GraphDatabase

class ReplicaTopologyNeo4j:
    def __init__(self, uri, user, password):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def close(self):
        self.driver.close()

    def create_replica(self, replica_id, region, capacity):
        """
        åˆ›å»ºå‰¯æœ¬èŠ‚ç‚¹
        """
        with self.driver.session() as session:
            session.write_transaction(self._create_replica,
                                    replica_id, region, capacity)

    @staticmethod
    def _create_replica(tx, replica_id, region, capacity):
        query = """
        CREATE (r:Replica {
            id: $replica_id,
            region: $region,
            capacity: $capacity,
            state: 'active'
        })
        """
        tx.run(query, replica_id=replica_id, region=region, capacity=capacity)

    def create_replication_link(self, source, target, latency, bandwidth):
        """
        åˆ›å»ºå¤åˆ¶é“¾è·¯
        """
        with self.driver.session() as session:
            session.write_transaction(self._create_link,
                                    source, target, latency, bandwidth)

    @staticmethod
    def _create_link(tx, source, target, latency, bandwidth):
        query = """
        MATCH (s:Replica {id: $source})
        MATCH (t:Replica {id: $target})
        CREATE (s)-[r:REPLICATES_TO {
            latency: $latency,
            bandwidth: $bandwidth
        }]->(t)
        """
        tx.run(query, source=source, target=target,
              latency=latency, bandwidth=bandwidth)

    def find_sync_paths(self, source, target):
        """
        æŸ¥æ‰¾åŒæ­¥è·¯å¾„
        """
        with self.driver.session() as session:
            result = session.read_transaction(self._find_paths, source, target)
            return result

    @staticmethod
    def _find_paths(tx, source, target):
        query = """
        MATCH path = shortestPath(
            (s:Replica {id: $source})-[*]-(t:Replica {id: $target})
        )
        RETURN path,
               reduce(total = 0, r in relationships(path) | total + r.latency) as total_latency
        ORDER BY total_latency
        LIMIT 5
        """
        result = tx.run(query, source=source, target=target)
        return [record for record in result]
```

---

## ğŸ”¬ **å››ã€æœåŠ¡ä¾èµ–åˆ†æå®ç° / Part 4: Service Dependency Analysis Implementation**

### 4.1 åŠ¨æ€å›¾æ„å»º

**æœåŠ¡è°ƒç”¨å›¾è¿½è¸ª**:

```python
import networkx as nx
from collections import deque
import time

class ServiceDependencyTracker:
    def __init__(self, window_size=10000):
        self.graph = nx.DiGraph()
        self.call_history = deque(maxlen=window_size)
        self.service_metrics = {}

    def add_service_call(self, caller, callee, latency, success, timestamp):
        """
        æ·»åŠ æœåŠ¡è°ƒç”¨
        """
        # æ·»åŠ èŠ‚ç‚¹
        self.graph.add_node(caller, type='service')
        self.graph.add_node(callee, type='service')

        # æ·»åŠ æˆ–æ›´æ–°è¾¹
        if self.graph.has_edge(caller, callee):
            edge_data = self.graph[caller][callee]
            edge_data['call_count'] += 1
            edge_data['total_latency'] += latency
            edge_data['success_count'] += (1 if success else 0)
        else:
            self.graph.add_edge(caller, callee,
                              call_count=1,
                              total_latency=latency,
                              success_count=(1 if success else 0),
                              first_seen=timestamp)

        # è®°å½•å†å²
        self.call_history.append({
            'caller': caller,
            'callee': callee,
            'latency': latency,
            'success': success,
            'timestamp': timestamp
        })

    def analyze_dependency_chain(self, service):
        """
        åˆ†æä¾èµ–é“¾
        """
        # æ‰¾åˆ°æ‰€æœ‰ä¾èµ–çš„æœåŠ¡ï¼ˆä¸‹æ¸¸ï¼‰
        dependencies = list(nx.descendants(self.graph, service))

        # æ‰¾åˆ°æ‰€æœ‰ä¾èµ–æ­¤æœåŠ¡çš„æœåŠ¡ï¼ˆä¸Šæ¸¸ï¼‰
        dependents = list(nx.ancestors(self.graph, service))

        return {
            'dependencies': dependencies,
            'dependents': dependents,
            'total_dependencies': len(dependencies),
            'total_dependents': len(dependents)
        }

    def find_critical_services(self):
        """
        æ‰¾åˆ°å…³é”®æœåŠ¡ï¼ˆé«˜ä¸­å¿ƒæ€§ï¼‰
        """
        betweenness = nx.betweenness_centrality(self.graph)
        closeness = nx.closeness_centrality(self.graph)

        critical = sorted(
            betweenness.items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]

        return critical

    def analyze_failure_propagation(self, failed_service):
        """
        åˆ†ææ•…éšœä¼ æ’­
        """
        # æ‰¾åˆ°æ‰€æœ‰å¯èƒ½å—å½±å“çš„æœåŠ¡
        affected_services = list(nx.descendants(self.graph, failed_service))

        # è®¡ç®—å½±å“èŒƒå›´
        impact_analysis = {
            'failed_service': failed_service,
            'directly_affected': len(list(self.graph.successors(failed_service))),
            'total_affected': len(affected_services),
            'affected_services': affected_services
        }

        return impact_analysis
```

### 4.2 Flinkæµå¤„ç†å®ç°

**Flinkæµå¼æœåŠ¡ä¾èµ–åˆ†æ**:

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.table import StreamTableEnvironment
from pyflink.datastream.functions import MapFunction, KeyedProcessFunction
import json

class ServiceCallMapper(MapFunction):
    def map(self, value):
        """
        è§£ææœåŠ¡è°ƒç”¨äº‹ä»¶
        """
        event = json.loads(value)
        return {
            'caller': event['caller'],
            'callee': event['callee'],
            'latency': event['latency'],
            'success': event['success'],
            'timestamp': event['timestamp']
        }

class DependencyAnalyzer(KeyedProcessFunction):
    def __init__(self):
        self.dependency_graph = {}

    def process_element(self, value, ctx, out):
        """
        å¤„ç†æœåŠ¡è°ƒç”¨äº‹ä»¶ï¼Œæ›´æ–°ä¾èµ–å›¾
        """
        caller = value['caller']
        callee = value['callee']

        # æ›´æ–°ä¾èµ–å›¾
        if caller not in self.dependency_graph:
            self.dependency_graph[caller] = set()
        self.dependency_graph[caller].add(callee)

        # è¾“å‡ºä¾èµ–å…³ç³»
        out.collect({
            'caller': caller,
            'callee': callee,
            'dependency_count': len(self.dependency_graph[caller])
        })

def process_service_calls():
    """
    æµå¼å¤„ç†æœåŠ¡è°ƒç”¨
    """
    env = StreamExecutionEnvironment.get_execution_environment()
    t_env = StreamTableEnvironment.create(env)

    # åˆ›å»ºæœåŠ¡è°ƒç”¨æµ
    service_call_stream = env.from_collection([
        '{"caller": "service_a", "callee": "service_b", "latency": 10, "success": true, "timestamp": 1000}',
        # ... æ›´å¤šäº‹ä»¶
    ])

    # è§£æäº‹ä»¶
    parsed_stream = service_call_stream.map(ServiceCallMapper())

    # åˆ†æä¾èµ–
    dependency_stream = parsed_stream.key_by(lambda x: x['caller']).process(DependencyAnalyzer())

    # è¾“å‡ºç»“æœ
    dependency_stream.print()

    env.execute("Service Dependency Analysis")
```

---

## ğŸ“‹ **äº”ã€æœ€ä½³å®è·µ / Part 5: Best Practices**

### 5.1 å»ºæ¨¡æœ€ä½³å®è·µ

1. **åˆ†å±‚å»ºæ¨¡**: å…ˆå»ºæ¨¡æ ¸å¿ƒåè®®ï¼Œå†æ·»åŠ æ•…éšœå’Œæ¢å¤æœºåˆ¶
2. **çŠ¶æ€æŠ½è±¡**: åˆç†æŠ½è±¡ç³»ç»ŸçŠ¶æ€ï¼Œé¿å…çŠ¶æ€çˆ†ç‚¸
3. **å¢é‡éªŒè¯**: å…ˆéªŒè¯å°è§„æ¨¡ç³»ç»Ÿï¼Œå†æ‰©å±•åˆ°å¤§è§„æ¨¡

### 5.2 å·¥å…·é€‰æ‹©æŒ‡å—

| åœºæ™¯ | æ¨èå·¥å…· | ç†ç”± |
|------|----------|------|
| åè®®å½¢å¼åŒ–éªŒè¯ | TLA+ | å¼ºå¤§çš„æ¨¡å‹æ£€éªŒèƒ½åŠ› |
| å¯è§†åŒ–å»ºæ¨¡ | CPN Tools | å›¾å½¢ç•Œé¢å‹å¥½ |
| å¤§è§„æ¨¡å›¾åˆ†æ | NetworkX + Neo4j | å¯æ‰©å±•æ€§å¼º |
| å®æ—¶ç›‘æ§ | Flink + Kafka | æµå¼å¤„ç† |
| æœåŠ¡å‘ç° | Consul / etcd | åˆ†å¸ƒå¼åè°ƒ |

### 5.3 æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **çŠ¶æ€ç©ºé—´ä¼˜åŒ–**: ä½¿ç”¨BDDç¬¦å·åŒ–è¡¨ç¤º
2. **å›¾ç®—æ³•ä¼˜åŒ–**: ä½¿ç”¨å¢é‡ç®—æ³•å’Œè¿‘ä¼¼ç®—æ³•
3. **åˆ†å¸ƒå¼è®¡ç®—**: å¯¹äºå¤§è§„æ¨¡ç³»ç»Ÿï¼Œä½¿ç”¨åˆ†å¸ƒå¼æ¡†æ¶

---

## ğŸ“š **å…­ã€å‚è€ƒæ–‡æ¡£ / Part 6: Reference Documents**

### 6.1 ç›¸å…³æ–‡æ¡£

- [åˆ†å¸ƒå¼ç³»ç»Ÿåº”ç”¨æ¨¡å¼æ¸…å•](./åˆ†å¸ƒå¼ç³»ç»Ÿåº”ç”¨æ¨¡å¼æ¸…å•.md)
- [è¯¦ç»†æ¡ˆä¾‹ï¼šRaftå…±è¯†åè®®éªŒè¯](./01-è¯¦ç»†æ¡ˆä¾‹-Raftå…±è¯†åè®®éªŒè¯.md)

### 6.2 å·¥å…·æ–‡æ¡£

- [TLA+å­¦ä¹ èµ„æº](https://learntla.com/)
- [CPN Toolsæ–‡æ¡£](https://cpntools.org/documentation/)
- [NetworkXæ–‡æ¡£](https://networkx.org/documentation/)
- [Flinkæ–‡æ¡£](https://flink.apache.org/docs/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025å¹´1æœˆ
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**çŠ¶æ€**: âœ… å®Œæˆ
**ç»´æŠ¤è€…**: GraphNetWorkCommunicateé¡¹ç›®ç»„
