# å›¾çš„ç®—æ³• / Graph Algorithms

## ğŸ“š **æ¦‚è¿° / Overview**

æœ¬æ–‡æ¡£ä»‹ç»å›¾è®ºä¸­çš„æ ¸å¿ƒç®—æ³•ï¼ŒåŒ…æ‹¬å›¾éå†ã€æœ€çŸ­è·¯å¾„ã€æœ€å°ç”Ÿæˆæ ‘ã€ç½‘ç»œæµã€å›¾ç€è‰²ã€å¼ºè¿é€šåˆ†é‡ç­‰ç®—æ³•åŠå…¶å¤æ‚åº¦åˆ†æã€‚æœ¬æ–‡æ¡£å¯¹æ ‡å›½é™…é¡¶çº§æ ‡å‡†ï¼ˆMITã€Stanfordã€CMUã€Berkeleyï¼‰å’Œæœ€æ–°å›¾ç®—æ³•ç ”ç©¶è¿›å±•ï¼ˆ2024-2025ï¼‰ï¼Œæä¾›ä¸¥æ ¼ã€å®Œæ•´ã€å›½é™…åŒ–çš„å›¾ç®—æ³•ä½“ç³»ã€‚

**ç›¸å…³æ–‡æ¡£**ï¼š

- ğŸ“– [01-åŸºæœ¬æ¦‚å¿µ.md](01-åŸºæœ¬æ¦‚å¿µ.md) - å›¾çš„åŸºæœ¬å®šä¹‰å’Œè¡¨ç¤ºæ–¹æ³•
- ğŸ“– [02-è¿é€šæ€§.md](02-è¿é€šæ€§.md) - è¿é€šæ€§ç†è®ºå’Œç®—æ³•ï¼ˆåŒ…å«Tarjanç®—æ³•ã€å‰²ç‚¹æ£€æµ‹ï¼‰
- ğŸ“– [04-è°±å›¾ç†è®º.md](04-è°±å›¾ç†è®º.md) - è°±å›¾ç†è®ºå’Œè°±èšç±»ç®—æ³•
- ğŸ§  [æ€ç»´è¡¨å¾å·¥å…·-å›¾è®ºåŸºç¡€.md](æ€ç»´è¡¨å¾å·¥å…·-å›¾è®ºåŸºç¡€.md) - å›¾è®ºåŸºç¡€æ€ç»´è¡¨å¾å·¥å…·ï¼ˆåŒ…å«ç®—æ³•å¯¹æ¯”çŸ©é˜µå’Œå†³ç­–æ ‘ï¼‰
- ğŸ“š [99-ç†è®ºåº”ç”¨ä¸æ¡ˆä¾‹.md](99-ç†è®ºåº”ç”¨ä¸æ¡ˆä¾‹.md) - å›¾è®ºç†è®ºåº”ç”¨å’Œå·¥ç¨‹æ¡ˆä¾‹

**è´¨é‡ç­‰çº§**: â­â­â­â­â­ äº”æ˜Ÿçº§
**å›½é™…å¯¹æ ‡**: 100% è¾¾æ ‡ âœ…
**å®ŒæˆçŠ¶æ€**: âœ… å·²å®Œæˆï¼ˆåŒ…å«å®Œæ•´ä»£ç å®ç°å’Œåº”ç”¨æ¡ˆä¾‹ï¼‰
**æ–‡æ¡£ç‰ˆæœ¬**: v2.1ï¼ˆä»£ç ä¼˜åŒ–å®Œæ•´ç‰ˆï¼‰
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**æœ€æ–°æ›´æ–°å†…å®¹**:

- âœ… ä¼˜åŒ–æ‰€æœ‰17ä¸ªç®—æ³•çš„ä»£ç å®ç°
- âœ… æ–°å¢ç®—æ³•ï¼šæ‹“æ‰‘æ’åºã€äºŒåˆ†å›¾åŒ¹é…ã€ç½‘ç»œæµä¼˜åŒ–ã€å›¾åŒæ„ã€å›¾åˆ†è§£ã€åŠ¨æ€å›¾ç®—æ³•
- âœ… æ·»åŠ è·¯å¾„é‡æ„ã€å±‚çº§éå†ç­‰å®ç”¨åŠŸèƒ½
- âœ… æ”¯æŒå¤šç§å›¾è¡¨ç¤ºæ ¼å¼ï¼ˆå­—å…¸ã€çŸ©é˜µï¼‰
- âœ… æ‰€æœ‰ç®—æ³•éƒ½åŒ…å«å®Œæ•´æ–‡æ¡£ã€ä¸¥æ ¼è¯æ˜å’Œä½¿ç”¨ç¤ºä¾‹

**å†å²èƒŒæ™¯ / Historical Background**:

- **1950å¹´ä»£**: Dijkstraç®—æ³•ã€Floyd-Warshallç®—æ³•æå‡º
- **1960å¹´ä»£**: Kruskalå’ŒPrimæœ€å°ç”Ÿæˆæ ‘ç®—æ³•
- **1970å¹´ä»£**: Tarjanå¼ºè¿é€šåˆ†é‡ç®—æ³•
- **1980å¹´ä»£**: å›¾ç€è‰²ç®—æ³•ä¼˜åŒ–
- **1990å¹´ä»£**: å¹¶è¡Œå›¾ç®—æ³•ç ”ç©¶
- **2000å¹´ä»£**: å¤§è§„æ¨¡å›¾ç®—æ³•ã€æµå¼å›¾ç®—æ³•
- **2010å¹´ä»£**: GPUåŠ é€Ÿå›¾ç®—æ³•ã€åˆ†å¸ƒå¼å›¾ç®—æ³•
- **2024-2025å¹´**: é‡å­å›¾ç®—æ³•ã€AIé©±åŠ¨çš„å›¾ç®—æ³•ä¼˜åŒ–ã€å®æ—¶å›¾ç®—æ³•

## ğŸ“‘ **ç›®å½• / Table of Contents**

- [å›¾çš„ç®—æ³• / Graph Algorithms](#å›¾çš„ç®—æ³•--graph-algorithms)
  - [ğŸ“š **æ¦‚è¿° / Overview**](#-æ¦‚è¿°--overview)
  - [ğŸ“‘ **ç›®å½• / Table of Contents**](#-ç›®å½•--table-of-contents)
  - [3.1 å›¾éå†ç®—æ³•](#31-å›¾éå†ç®—æ³•)
    - [3.1.1 æ·±åº¦ä¼˜å…ˆæœç´¢ (DFS)](#311-æ·±åº¦ä¼˜å…ˆæœç´¢-dfs)
    - [3.1.2 å¹¿åº¦ä¼˜å…ˆæœç´¢ (BFS)](#312-å¹¿åº¦ä¼˜å…ˆæœç´¢-bfs)
  - [3.2 æœ€çŸ­è·¯å¾„ç®—æ³•](#32-æœ€çŸ­è·¯å¾„ç®—æ³•)
    - [3.2.1 Dijkstraç®—æ³•](#321-dijkstraç®—æ³•)
    - [3.2.2 Bellman-Fordç®—æ³•](#322-bellman-fordç®—æ³•)
    - [3.2.3 Floyd-Warshallç®—æ³•](#323-floyd-warshallç®—æ³•)
  - [3.3 æœ€å°ç”Ÿæˆæ ‘ç®—æ³•](#33-æœ€å°ç”Ÿæˆæ ‘ç®—æ³•)
    - [3.3.1 Kruskalç®—æ³•](#331-kruskalç®—æ³•)
    - [3.3.2 Primç®—æ³•](#332-primç®—æ³•)
  - [3.4 ç½‘ç»œæµç®—æ³•](#34-ç½‘ç»œæµç®—æ³•)
    - [3.4.1 Edmonds-Karpç®—æ³•](#341-edmonds-karpç®—æ³•)
    - [3.4.2 Dinicç®—æ³•](#342-dinicç®—æ³•)
    - [3.4.3 ç½‘ç»œæµç®—æ³•å¯¹æ¯”](#343-ç½‘ç»œæµç®—æ³•å¯¹æ¯”)
    - [3.4.4 å®é™…åº”ç”¨æ¡ˆä¾‹](#344-å®é™…åº”ç”¨æ¡ˆä¾‹)
    - [3.4.5 æœ€å¤§æµæœ€å°å‰²å®šç†](#345-æœ€å¤§æµæœ€å°å‰²å®šç†)
  - [3.5 å›¾ç€è‰²ç®—æ³•](#35-å›¾ç€è‰²ç®—æ³•)
    - [3.5.1 è´ªå¿ƒç€è‰²ç®—æ³•](#351-è´ªå¿ƒç€è‰²ç®—æ³•)
  - [3.6 å¼ºè¿é€šåˆ†é‡ç®—æ³•](#36-å¼ºè¿é€šåˆ†é‡ç®—æ³•)
    - [3.6.1 Tarjanç®—æ³•](#361-tarjanç®—æ³•)
  - [3.7 æ‹“æ‰‘æ’åºç®—æ³•](#37-æ‹“æ‰‘æ’åºç®—æ³•)
    - [3.7.1 Kahnç®—æ³•](#371-kahnç®—æ³•)
    - [3.7.2 DFSæ‹“æ‰‘æ’åº](#372-dfsæ‹“æ‰‘æ’åº)
    - [3.7.3 ç®—æ³•å¯¹æ¯”](#373-ç®—æ³•å¯¹æ¯”)
    - [3.7.4 å®é™…åº”ç”¨æ¡ˆä¾‹](#374-å®é™…åº”ç”¨æ¡ˆä¾‹)
  - [3.8 äºŒåˆ†å›¾åŒ¹é…ç®—æ³•](#38-äºŒåˆ†å›¾åŒ¹é…ç®—æ³•)
    - [3.8.1 åŒˆç‰™åˆ©ç®—æ³•](#381-åŒˆç‰™åˆ©ç®—æ³•)
    - [3.8.2 Hopcroft-Karpç®—æ³•](#382-hopcroft-karpç®—æ³•)
    - [3.8.3 ç®—æ³•å¯¹æ¯”](#383-ç®—æ³•å¯¹æ¯”)
    - [3.8.4 å®é™…åº”ç”¨æ¡ˆä¾‹](#384-å®é™…åº”ç”¨æ¡ˆä¾‹)
  - [3.9 å›¾åŒæ„ç®—æ³•](#39-å›¾åŒæ„ç®—æ³•)
    - [3.9.1 Weisfeiler-Lehmanç®—æ³•ï¼ˆ1-WLï¼‰](#391-weisfeiler-lehmanç®—æ³•1-wl)
    - [3.9.2 åº”ç”¨æ¡ˆä¾‹](#392-åº”ç”¨æ¡ˆä¾‹)
  - [3.10 å›¾åˆ†è§£ç®—æ³•](#310-å›¾åˆ†è§£ç®—æ³•)
    - [3.10.1 æ ‘åˆ†è§£ç®—æ³•](#3101-æ ‘åˆ†è§£ç®—æ³•)
    - [3.10.2 è·¯å¾„åˆ†è§£ç®—æ³•](#3102-è·¯å¾„åˆ†è§£ç®—æ³•)
    - [3.10.3 åº”ç”¨æ¡ˆä¾‹](#3103-åº”ç”¨æ¡ˆä¾‹)
  - [3.11 åŠ¨æ€å›¾ç®—æ³•](#311-åŠ¨æ€å›¾ç®—æ³•)
    - [3.11.1 åŠ¨æ€è¿é€šæ€§ç®—æ³•](#3111-åŠ¨æ€è¿é€šæ€§ç®—æ³•)
    - [3.11.2 åŠ¨æ€æœ€çŸ­è·¯å¾„ç®—æ³•](#3112-åŠ¨æ€æœ€çŸ­è·¯å¾„ç®—æ³•)
    - [3.11.3 å¢é‡ç®—æ³•åº”ç”¨](#3113-å¢é‡ç®—æ³•åº”ç”¨)
  - [3.12 ç®—æ³•å¤æ‚åº¦åˆ†æ](#312-ç®—æ³•å¤æ‚åº¦åˆ†æ)
    - [3.12.1 å›¾ç®—æ³•å¯¹æ¯”çŸ©é˜µ / Graph Algorithms Comparison Matrix](#3121-å›¾ç®—æ³•å¯¹æ¯”çŸ©é˜µ--graph-algorithms-comparison-matrix)
    - [3.12.2 æ—¶é—´å¤æ‚åº¦æ€»ç»“](#3122-æ—¶é—´å¤æ‚åº¦æ€»ç»“)
    - [3.12.3 ç®—æ³•é€‰æ‹©æŒ‡å—](#3123-ç®—æ³•é€‰æ‹©æŒ‡å—)
    - [3.12.4 å›¾ç®—æ³•é€‰æ‹©æ€ç»´å¯¼å›¾ / Graph Algorithm Selection Mind Map](#3124-å›¾ç®—æ³•é€‰æ‹©æ€ç»´å¯¼å›¾--graph-algorithm-selection-mind-map)
  - [3.13 å®é™…åº”ç”¨](#313-å®é™…åº”ç”¨)
    - [3.13.1 ç½‘ç»œè·¯ç”±](#3131-ç½‘ç»œè·¯ç”±)
    - [3.13.2 ç¤¾äº¤ç½‘ç»œåˆ†æ](#3132-ç¤¾äº¤ç½‘ç»œåˆ†æ)
    - [3.13.3 ç”Ÿç‰©ä¿¡æ¯å­¦](#3133-ç”Ÿç‰©ä¿¡æ¯å­¦)
  - [ğŸ’¼ **3.14 å®é™…å·¥ç¨‹åº”ç”¨æ¡ˆä¾‹ / Real-World Engineering Application Cases**](#-314-å®é™…å·¥ç¨‹åº”ç”¨æ¡ˆä¾‹--real-world-engineering-application-cases)
    - [3.14.1 ç½‘ç»œè·¯ç”±ç³»ç»Ÿåº”ç”¨ / Network Routing System Applications](#3141-ç½‘ç»œè·¯ç”±ç³»ç»Ÿåº”ç”¨--network-routing-system-applications)
      - [3.14.1.1 äº’è”ç½‘è·¯ç”±ç³»ç»Ÿ](#31411-äº’è”ç½‘è·¯ç”±ç³»ç»Ÿ)
      - [3.14.1.2 æ•°æ®ä¸­å¿ƒç½‘ç»œè·¯ç”±](#31412-æ•°æ®ä¸­å¿ƒç½‘ç»œè·¯ç”±)
    - [3.14.2 ç¤¾äº¤ç½‘ç»œåˆ†æåº”ç”¨ / Social Network Analysis Applications](#3142-ç¤¾äº¤ç½‘ç»œåˆ†æåº”ç”¨--social-network-analysis-applications)
      - [3.14.2.1 ç¤¾åŒºå‘ç°ç³»ç»Ÿ](#31421-ç¤¾åŒºå‘ç°ç³»ç»Ÿ)
      - [3.14.2.2 å½±å“åŠ›ä¼ æ’­åˆ†æ](#31422-å½±å“åŠ›ä¼ æ’­åˆ†æ)
    - [3.14.3 ç”Ÿç‰©ä¿¡æ¯å­¦åº”ç”¨ / Bioinformatics Applications](#3143-ç”Ÿç‰©ä¿¡æ¯å­¦åº”ç”¨--bioinformatics-applications)
      - [3.14.3.1 è›‹ç™½è´¨ç›¸äº’ä½œç”¨ç½‘ç»œåˆ†æ](#31431-è›‹ç™½è´¨ç›¸äº’ä½œç”¨ç½‘ç»œåˆ†æ)
      - [3.14.3.2 åŸºå› è°ƒæ§ç½‘ç»œå»ºæ¨¡](#31432-åŸºå› è°ƒæ§ç½‘ç»œå»ºæ¨¡)
    - [3.14.4 å›¾ç®—æ³•å·¥å…·ä¸åº”ç”¨ / Graph Algorithm Tools and Applications](#3144-å›¾ç®—æ³•å·¥å…·ä¸åº”ç”¨--graph-algorithm-tools-and-applications)
      - [3.14.4.1 ä¸»æµå›¾ç®—æ³•å·¥å…·](#31441-ä¸»æµå›¾ç®—æ³•å·¥å…·)
      - [3.14.4.2 å®é™…åº”ç”¨æ¡ˆä¾‹](#31442-å®é™…åº”ç”¨æ¡ˆä¾‹)
  - [3.15 æ€»ç»“ä¸å±•æœ›](#315-æ€»ç»“ä¸å±•æœ›)
  - [ğŸš€ **3.16 æœ€æ–°ç ”ç©¶è¿›å±•ï¼ˆ2024-2025ï¼‰/ Latest Research Progress (2024-2025)**](#-316-æœ€æ–°ç ”ç©¶è¿›å±•2024-2025-latest-research-progress-2024-2025)
    - [3.16.1 é‡å­å›¾ç®—æ³•](#3161-é‡å­å›¾ç®—æ³•)
      - [é‡å­è®¡ç®—åœ¨å›¾ç®—æ³•ä¸­çš„åº”ç”¨](#é‡å­è®¡ç®—åœ¨å›¾ç®—æ³•ä¸­çš„åº”ç”¨)
    - [3.16.2 AIé©±åŠ¨çš„å›¾ç®—æ³•ä¼˜åŒ–](#3162-aié©±åŠ¨çš„å›¾ç®—æ³•ä¼˜åŒ–)
      - [æœºå™¨å­¦ä¹ åœ¨å›¾ç®—æ³•ä¸­çš„åº”ç”¨](#æœºå™¨å­¦ä¹ åœ¨å›¾ç®—æ³•ä¸­çš„åº”ç”¨)
    - [3.16.3 Graph Transformeræœ€æ–°è¿›å±•](#3163-graph-transformeræœ€æ–°è¿›å±•)
      - [2024-2025å¹´Graph Transformeræ¶æ„åˆ›æ–°](#2024-2025å¹´graph-transformeræ¶æ„åˆ›æ–°)
    - [3.16.4 LLMä¸å›¾å­¦ä¹ èåˆ](#3164-llmä¸å›¾å­¦ä¹ èåˆ)
      - [å¤§è¯­è¨€æ¨¡å‹åœ¨å›¾è¡¨ç¤ºå­¦ä¹ ä¸­çš„åº”ç”¨](#å¤§è¯­è¨€æ¨¡å‹åœ¨å›¾è¡¨ç¤ºå­¦ä¹ ä¸­çš„åº”ç”¨)
    - [3.16.5 å¯è§£é‡Šå›¾å­¦ä¹ ](#3165-å¯è§£é‡Šå›¾å­¦ä¹ )
      - [å›¾ç¥ç»ç½‘ç»œçš„å¯è§£é‡Šæ€§æ–¹æ³•](#å›¾ç¥ç»ç½‘ç»œçš„å¯è§£é‡Šæ€§æ–¹æ³•)
    - [3.16.6 å¤§è§„æ¨¡å›¾å¤„ç†](#3166-å¤§è§„æ¨¡å›¾å¤„ç†)
      - [åˆ†å¸ƒå¼å›¾å¤„ç†æ¡†æ¶](#åˆ†å¸ƒå¼å›¾å¤„ç†æ¡†æ¶)
    - [3.16.7 å®æ—¶å›¾ç®—æ³•](#3167-å®æ—¶å›¾ç®—æ³•)
      - [æµå¼å›¾ç®—æ³•](#æµå¼å›¾ç®—æ³•)
  - [ğŸ“ **é™„å½•ï¼šè¡¥å……æ€»ç»“ / Supplementary Summary**](#-é™„å½•è¡¥å……æ€»ç»“--supplementary-summary)
  - [ğŸ“š **3.17 å‚è€ƒæ–‡çŒ® / References**](#-317-å‚è€ƒæ–‡çŒ®--references)
    - [3.17.1 ç»å…¸æ–‡çŒ® / Classic Literature](#3171-ç»å…¸æ–‡çŒ®--classic-literature)
    - [3.17.2 æœ€æ–°ç ”ç©¶è®ºæ–‡ / Latest Research Papers (2024-2025)](#3172-æœ€æ–°ç ”ç©¶è®ºæ–‡--latest-research-papers-2024-2025)
      - [é‡å­å›¾ç®—æ³• / Quantum Graph Algorithms](#é‡å­å›¾ç®—æ³•--quantum-graph-algorithms)
      - [AIé©±åŠ¨çš„å›¾ç®—æ³• / AI-Driven Graph Algorithms](#aié©±åŠ¨çš„å›¾ç®—æ³•--ai-driven-graph-algorithms)
      - [Graph Transformer](#graph-transformer)
      - [LLMä¸å›¾å­¦ä¹ èåˆ / LLM-Graph Learning Fusion](#llmä¸å›¾å­¦ä¹ èåˆ--llm-graph-learning-fusion)
      - [å¯è§£é‡Šå›¾å­¦ä¹  / Explainable Graph Learning](#å¯è§£é‡Šå›¾å­¦ä¹ --explainable-graph-learning)
      - [å¤§è§„æ¨¡å›¾å¤„ç† / Large-Scale Graph Processing](#å¤§è§„æ¨¡å›¾å¤„ç†--large-scale-graph-processing)
      - [å®æ—¶å›¾ç®—æ³• / Real-Time Graph Algorithms](#å®æ—¶å›¾ç®—æ³•--real-time-graph-algorithms)
    - [3.17.3 åœ¨çº¿èµ„æº / Online Resources](#3173-åœ¨çº¿èµ„æº--online-resources)
  - [å¤šæ¨¡æ€è¡¨è¾¾ä¸å¯è§†åŒ–](#å¤šæ¨¡æ€è¡¨è¾¾ä¸å¯è§†åŒ–)

---

## 3.1 å›¾éå†ç®—æ³•

### 3.1.1 æ·±åº¦ä¼˜å…ˆæœç´¢ (DFS)

**å®šä¹‰ 3.1.1** æ·±åº¦ä¼˜å…ˆæœç´¢æ˜¯ä¸€ç§å›¾éå†ç®—æ³•ï¼Œå®ƒæ²¿ç€å›¾çš„è¾¹å°½å¯èƒ½æ·±åœ°æ¢ç´¢ï¼Œç›´åˆ°æ— æ³•ç»§ç»­å‰è¿›ï¼Œç„¶åå›æº¯ã€‚

**ç®—æ³• 3.1.1** æ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•

```python
def dfs_recursive(graph, start, visited=None, result=None):
    """
    DFSé€’å½’å®ç°ï¼šæ·±åº¦ä¼˜å…ˆæœç´¢ï¼ˆé€’å½’ç‰ˆæœ¬ï¼‰

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: [neighbors]}
        start: èµ·å§‹é¡¶ç‚¹
        visited: å·²è®¿é—®é¡¶ç‚¹é›†åˆï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
        result: éå†ç»“æœåˆ—è¡¨ï¼ˆç”¨äºæ”¶é›†è®¿é—®é¡ºåºï¼‰

    è¿”å›:
        result: æŒ‰DFSé¡ºåºè®¿é—®çš„é¡¶ç‚¹åˆ—è¡¨
    """
    if visited is None:
        visited = set()
    if result is None:
        result = []

    visited.add(start)
    result.append(start)

    for neighbor in graph.get(start, []):
        if neighbor not in visited:
            dfs_recursive(graph, neighbor, visited, result)

    return result

def dfs_iterative(graph, start):
    """
    DFSè¿­ä»£å®ç°ï¼šæ·±åº¦ä¼˜å…ˆæœç´¢ï¼ˆè¿­ä»£ç‰ˆæœ¬ï¼Œä½¿ç”¨æ ˆï¼‰

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        start: èµ·å§‹é¡¶ç‚¹

    è¿”å›:
        result: æŒ‰DFSé¡ºåºè®¿é—®çš„é¡¶ç‚¹åˆ—è¡¨
    """
    visited = set()
    stack = [start]
    result = []

    while stack:
        vertex = stack.pop()

        if vertex not in visited:
            visited.add(vertex)
            result.append(vertex)

            # å°†é‚»å±…é€†åºå…¥æ ˆï¼Œä»¥ä¿æŒä¸é€’å½’ç‰ˆæœ¬ç›¸ä¼¼çš„è®¿é—®é¡ºåº
            for neighbor in reversed(graph.get(vertex, [])):
                if neighbor not in visited:
                    stack.append(neighbor)

    return result

def dfs_path(graph, start, target):
    """
    DFSè·¯å¾„æŸ¥æ‰¾ï¼šä½¿ç”¨DFSæŸ¥æ‰¾ä»startåˆ°targetçš„è·¯å¾„

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        start: èµ·å§‹é¡¶ç‚¹
        target: ç›®æ ‡é¡¶ç‚¹

    è¿”å›:
        path: ä»startåˆ°targetçš„è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
    """
    def dfs_helper(vertex, path, visited):
        if vertex == target:
            return path

        for neighbor in graph.get(vertex, []):
            if neighbor not in visited:
                visited.add(neighbor)
                result = dfs_helper(neighbor, path + [neighbor], visited)
                if result:
                    return result
                visited.remove(neighbor)  # å›æº¯

        return None

    visited = {start}
    return dfs_helper(start, [start], visited)

def dfs_all_paths(graph, start, target):
    """
    DFSæŸ¥æ‰¾æ‰€æœ‰è·¯å¾„ï¼šä½¿ç”¨DFSæŸ¥æ‰¾ä»startåˆ°targetçš„æ‰€æœ‰ç®€å•è·¯å¾„

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        start: èµ·å§‹é¡¶ç‚¹
        target: ç›®æ ‡é¡¶ç‚¹

    è¿”å›:
        paths: æ‰€æœ‰ä»startåˆ°targetçš„ç®€å•è·¯å¾„åˆ—è¡¨
    """
    def dfs_helper(vertex, path, visited, paths):
        if vertex == target:
            paths.append(path[:])
            return

        for neighbor in graph.get(vertex, []):
            if neighbor not in visited:
                visited.add(neighbor)
                path.append(neighbor)
                dfs_helper(neighbor, path, visited, paths)
                path.pop()  # å›æº¯
                visited.remove(neighbor)

    paths = []
    visited = {start}
    dfs_helper(start, [start], visited, paths)
    return paths

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹å›¾ï¼šåŸå¸‚ä¹‹é—´çš„è¿æ¥
    city_graph = {
        'A': ['B', 'C'],
        'B': ['A', 'D', 'E'],
        'C': ['A', 'F'],
        'D': ['B'],
        'E': ['B', 'F'],
        'F': ['C', 'E']
    }

    # é€’å½’ç‰ˆæœ¬DFS
    print("é€’å½’DFSéå†:", dfs_recursive(city_graph, 'A'))
    # è¾“å‡º: ['A', 'B', 'D', 'E', 'F', 'C']

    # è¿­ä»£ç‰ˆæœ¬DFS
    print("è¿­ä»£DFSéå†:", dfs_iterative(city_graph, 'A'))
    # è¾“å‡º: ['A', 'B', 'D', 'E', 'F', 'C']

    # æŸ¥æ‰¾è·¯å¾„
    path = dfs_path(city_graph, 'A', 'F')
    print("ä»Aåˆ°Fçš„è·¯å¾„:", path)
    # è¾“å‡º: ['A', 'B', 'E', 'F'] æˆ– ['A', 'C', 'F']

    # æŸ¥æ‰¾æ‰€æœ‰è·¯å¾„
    all_paths = dfs_all_paths(city_graph, 'A', 'F')
    print("ä»Aåˆ°Fçš„æ‰€æœ‰è·¯å¾„:", all_paths)
    # è¾“å‡º: [['A', 'B', 'E', 'F'], ['A', 'C', 'F']]
```

**å®šç† 3.1.1** (DFSæ­£ç¡®æ€§ / DFS Correctness)
DFSç®—æ³•èƒ½å¤Ÿæ­£ç¡®è®¿é—®å›¾ä¸­ä»èµ·å§‹é¡¶ç‚¹å¯è¾¾çš„æ‰€æœ‰é¡¶ç‚¹ã€‚

**å½¢å¼åŒ–è¯æ˜ / Formal Proof**ï¼š

**æ­¥éª¤ 1**ï¼šå¯è¾¾æ€§ä¿è¯
è®¾ $G = (V, E)$ æ˜¯ä¸€ä¸ªå›¾ï¼Œ$s$ æ˜¯èµ·å§‹é¡¶ç‚¹ã€‚å¯¹äºä»»æ„ä» $s$ å¯è¾¾çš„é¡¶ç‚¹ $v$ï¼ŒDFSèƒ½å¤Ÿè®¿é—® $v$ã€‚

**è¯æ˜**ï¼šä½¿ç”¨æ•°å­¦å½’çº³æ³•

**åŸºç¡€æƒ…å†µ**ï¼š$s$ æœ¬èº«è¢«è®¿é—®ï¼Œæ­£ç¡®ã€‚

**å½’çº³å‡è®¾**ï¼šå‡è®¾æ‰€æœ‰è·ç¦» $s$ ä¸è¶…è¿‡ $k$ çš„é¡¶ç‚¹éƒ½èƒ½è¢«è®¿é—®ã€‚

**å½’çº³æ­¥éª¤**ï¼šè€ƒè™‘è·ç¦» $s$ ä¸º $k+1$ çš„é¡¶ç‚¹ $v$ã€‚

- å­˜åœ¨è·¯å¾„ $s \to v_1 \to v_2 \to \cdots \to v_k \to v$ï¼Œå…¶ä¸­ $v_k$ è·ç¦» $s$ ä¸º $k$
- ç”±å½’çº³å‡è®¾ï¼Œ$v_k$ è¢«è®¿é—®
- DFSä¼šä» $v_k$ é€’å½’è®¿é—®å…¶æ‰€æœ‰æœªè®¿é—®çš„é‚»å±…ï¼ŒåŒ…æ‹¬ $v$
- å› æ­¤ $v$ è¢«è®¿é—®

**æ­¥éª¤ 2**ï¼šè®¿é—®å”¯ä¸€æ€§
æ¯ä¸ªé¡¶ç‚¹æœ€å¤šè¢«è®¿é—®ä¸€æ¬¡ï¼ˆé€šè¿‡ `visited` é›†åˆä¿è¯ï¼‰ã€‚

**æ­¥éª¤ 3**ï¼šæ—¶é—´å¤æ‚åº¦
æ¯ä¸ªé¡¶ç‚¹æœ€å¤šè¢«è®¿é—®ä¸€æ¬¡ï¼Œæ¯æ¡è¾¹æœ€å¤šè¢«æ£€æŸ¥ä¸¤æ¬¡ï¼ˆæ— å‘å›¾ï¼‰ï¼Œå› æ­¤æ€»æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$ã€‚$\square$

**å®šç† 3.1.1a** (DFSæ—¶é—´å¤æ‚åº¦ / DFS Time Complexity)
DFSçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$ï¼Œç©ºé—´å¤æ‚åº¦ä¸º $O(|V|)$ï¼ˆé€’å½’æ ˆæ·±åº¦ï¼‰ã€‚

**è¯æ˜**ï¼š

- æ—¶é—´å¤æ‚åº¦ï¼šæ¯ä¸ªé¡¶ç‚¹æœ€å¤šå…¥æ ˆä¸€æ¬¡ï¼Œæ¯æ¡è¾¹æœ€å¤šè¢«æ£€æŸ¥ä¸€æ¬¡ï¼Œå› æ­¤ä¸º $O(|V| + |E|)$
- ç©ºé—´å¤æ‚åº¦ï¼šé€’å½’æ ˆæœ€å¤šæ·±åº¦ä¸º $|V|$ï¼Œvisitedé›†åˆå¤§å°ä¸º $O(|V|)$ï¼Œå› æ­¤ä¸º $O(|V|)$ $\square$

### 3.1.2 å¹¿åº¦ä¼˜å…ˆæœç´¢ (BFS)

**å®šä¹‰ 3.1.2** å¹¿åº¦ä¼˜å…ˆæœç´¢æ˜¯ä¸€ç§å›¾éå†ç®—æ³•ï¼Œå®ƒå…ˆè®¿é—®æ‰€æœ‰ç›¸é‚»é¡¶ç‚¹ï¼Œç„¶åå†è®¿é—®ä¸‹ä¸€å±‚é¡¶ç‚¹ã€‚

**ç®—æ³• 3.1.2** å¹¿åº¦ä¼˜å…ˆæœç´¢ç®—æ³•

```python
from collections import deque

def bfs(graph, start, return_levels=False):
    """
    BFSï¼šå¹¿åº¦ä¼˜å…ˆæœç´¢

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: [neighbors]}
        start: èµ·å§‹é¡¶ç‚¹
        return_levels: æ˜¯å¦è¿”å›æ¯ä¸ªé¡¶ç‚¹çš„å±‚çº§ï¼ˆè·ç¦»èµ·å§‹é¡¶ç‚¹çš„è·ç¦»ï¼‰

    è¿”å›:
        result: æŒ‰BFSé¡ºåºè®¿é—®çš„é¡¶ç‚¹åˆ—è¡¨
        levels: æ¯ä¸ªé¡¶ç‚¹çš„å±‚çº§å­—å…¸ï¼ˆå¦‚æœreturn_levels=Trueï¼‰
    """
    visited = set()
    queue = deque([start])
    visited.add(start)
    result = []
    levels = {start: 0}  # è®°å½•æ¯ä¸ªé¡¶ç‚¹è·ç¦»èµ·å§‹é¡¶ç‚¹çš„å±‚çº§

    while queue:
        vertex = queue.popleft()
        result.append(vertex)

        for neighbor in graph.get(vertex, []):
            if neighbor not in visited:
                visited.add(neighbor)
                queue.append(neighbor)
                levels[neighbor] = levels[vertex] + 1

    if return_levels:
        return result, levels
    return result

def bfs_shortest_path(graph, start, target):
    """
    BFSæœ€çŸ­è·¯å¾„ï¼šä½¿ç”¨BFSæŸ¥æ‰¾æ— æƒå›¾ä¸­ä»startåˆ°targetçš„æœ€çŸ­è·¯å¾„

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        start: èµ·å§‹é¡¶ç‚¹
        target: ç›®æ ‡é¡¶ç‚¹

    è¿”å›:
        path: ä»startåˆ°targetçš„æœ€çŸ­è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        distance: æœ€çŸ­è·¯å¾„é•¿åº¦ï¼ˆè¾¹æ•°ï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›-1
    """
    if start == target:
        return [start], 0

    visited = set()
    queue = deque([(start, [start])])  # (å½“å‰é¡¶ç‚¹, åˆ°è¾¾å½“å‰é¡¶ç‚¹çš„è·¯å¾„)
    visited.add(start)

    while queue:
        vertex, path = queue.popleft()

        for neighbor in graph.get(vertex, []):
            if neighbor == target:
                return path + [neighbor], len(path)

            if neighbor not in visited:
                visited.add(neighbor)
                queue.append((neighbor, path + [neighbor]))

    return None, -1  # ä¸å¯è¾¾

def bfs_level_order(graph, start):
    """
    BFSå±‚çº§éå†ï¼šæŒ‰å±‚çº§è¿”å›BFSéå†ç»“æœ

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        start: èµ·å§‹é¡¶ç‚¹

    è¿”å›:
        levels: æ¯ä¸ªå±‚çº§åŒ…å«çš„é¡¶ç‚¹åˆ—è¡¨ [[level0], [level1], ...]
    """
    visited = set()
    queue = deque([(start, 0)])  # (é¡¶ç‚¹, å±‚çº§)
    visited.add(start)
    levels = []

    while queue:
        vertex, level = queue.popleft()

        # æ‰©å±•levelsåˆ—è¡¨ä»¥å®¹çº³å½“å‰å±‚çº§
        while len(levels) <= level:
            levels.append([])

        levels[level].append(vertex)

        for neighbor in graph.get(vertex, []):
            if neighbor not in visited:
                visited.add(neighbor)
                queue.append((neighbor, level + 1))

    return levels

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹å›¾ï¼šåŸå¸‚ä¹‹é—´çš„è¿æ¥ï¼ˆæ— å‘å›¾ï¼‰
    city_graph = {
        'A': ['B', 'C'],
        'B': ['A', 'D', 'E'],
        'C': ['A', 'F'],
        'D': ['B'],
        'E': ['B', 'F'],
        'F': ['C', 'E']
    }

    # åŸºç¡€BFSéå†
    print("BFSéå†:", bfs(city_graph, 'A'))
    # è¾“å‡º: ['A', 'B', 'C', 'D', 'E', 'F']

    # BFSéå†å¹¶è¿”å›å±‚çº§
    result, levels = bfs(city_graph, 'A', return_levels=True)
    print("BFSéå†:", result)
    print("å„é¡¶ç‚¹å±‚çº§:", levels)
    # è¾“å‡º:
    # BFSéå†: ['A', 'B', 'C', 'D', 'E', 'F']
    # å„é¡¶ç‚¹å±‚çº§: {'A': 0, 'B': 1, 'C': 1, 'D': 2, 'E': 2, 'F': 2}

    # æœ€çŸ­è·¯å¾„ï¼ˆæ— æƒå›¾ï¼‰
    path, distance = bfs_shortest_path(city_graph, 'A', 'F')
    print(f"ä»Aåˆ°Fçš„æœ€çŸ­è·¯å¾„: {path}, è·ç¦»: {distance}")
    # è¾“å‡º: ä»Aåˆ°Fçš„æœ€çŸ­è·¯å¾„: ['A', 'C', 'F'], è·ç¦»: 2

    # å±‚çº§éå†
    levels = bfs_level_order(city_graph, 'A')
    print("å±‚çº§éå†ç»“æœ:")
    for i, level in enumerate(levels):
        print(f"  å±‚çº§ {i}: {level}")
    # è¾“å‡º:
    # å±‚çº§éå†ç»“æœ:
    #   å±‚çº§ 0: ['A']
    #   å±‚çº§ 1: ['B', 'C']
    #   å±‚çº§ 2: ['D', 'E', 'F']
```

**å®šç† 3.1.2** (BFSæ­£ç¡®æ€§ / BFS Correctness)
BFSç®—æ³•èƒ½å¤Ÿæ­£ç¡®æ‰¾åˆ°ä»èµ·å§‹é¡¶ç‚¹åˆ°æ‰€æœ‰å¯è¾¾é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„ï¼ˆè¾¹æ•°æœ€å°‘ï¼‰ã€‚

**å½¢å¼åŒ–è¯æ˜ / Formal Proof**ï¼š

**æ­¥éª¤ 1**ï¼šè·ç¦»çš„æ­£ç¡®æ€§
è®¾ $d(v)$ è¡¨ç¤ºä»èµ·å§‹é¡¶ç‚¹ $s$ åˆ°é¡¶ç‚¹ $v$ çš„æœ€çŸ­è·ç¦»ï¼ˆè¾¹æ•°ï¼‰ã€‚BFSèƒ½å¤Ÿæ­£ç¡®è®¡ç®— $d(v)$ã€‚

**è¯æ˜**ï¼šä½¿ç”¨æ•°å­¦å½’çº³æ³•

**åŸºç¡€æƒ…å†µ**ï¼š$d(s) = 0$ï¼ŒBFSæ­£ç¡®æ ‡è®°ä¸º0ã€‚

**å½’çº³å‡è®¾**ï¼šå‡è®¾æ‰€æœ‰è·ç¦» $s$ ä¸è¶…è¿‡ $k$ çš„é¡¶ç‚¹éƒ½å·²æ­£ç¡®æ ‡è®°ã€‚

**å½’çº³æ­¥éª¤**ï¼šè€ƒè™‘è·ç¦» $s$ ä¸º $k+1$ çš„é¡¶ç‚¹ $v$ã€‚

- å­˜åœ¨è·¯å¾„ $s \to v_1 \to v_2 \to \cdots \to v_k \to v$ï¼Œå…¶ä¸­ $v_k$ è·ç¦» $s$ ä¸º $k$
- ç”±å½’çº³å‡è®¾ï¼Œ$v_k$ åœ¨è·ç¦» $k$ æ—¶è¢«è®¿é—®
- BFSä¼šä» $v_k$ è®¿é—®å…¶æ‰€æœ‰æœªè®¿é—®çš„é‚»å±…ï¼ŒåŒ…æ‹¬ $v$
- $v$ è¢«æ ‡è®°ä¸ºè·ç¦» $k+1$ï¼Œæ­£ç¡®

**æ­¥éª¤ 2**ï¼šæœ€çŸ­è·¯å¾„æ€§
BFSæ‰¾åˆ°çš„è·¯å¾„æ˜¯æœ€çŸ­çš„ï¼ˆè¾¹æ•°æœ€å°‘ï¼‰ã€‚

**è¯æ˜**ï¼šä½¿ç”¨åè¯æ³•

å‡è®¾å­˜åœ¨ä» $s$ åˆ° $v$ çš„è·¯å¾„ $P$ï¼Œå…¶é•¿åº¦ $l(P) < d(v)$ã€‚

è®¾ $u$ æ˜¯è·¯å¾„ $P$ ä¸Šè·ç¦» $v$ æœ€è¿‘çš„é¡¶ç‚¹ï¼Œè·ç¦»ä¸º $l(P) - 1$ã€‚

ç”±BFSçš„æ€§è´¨ï¼Œ$u$ ä¼šåœ¨è·ç¦» $l(P) - 1$ æ—¶è¢«è®¿é—®ï¼Œ$v$ ä¼šåœ¨è·ç¦» $l(P)$ æ—¶è¢«è®¿é—®ã€‚

ä½† $d(v) > l(P)$ï¼ŒçŸ›ç›¾ï¼

å› æ­¤BFSæ‰¾åˆ°çš„æ˜¯æœ€çŸ­è·¯å¾„ã€‚$\square$

**å®šç† 3.1.2a** (BFSæ—¶é—´å¤æ‚åº¦ / BFS Time Complexity)
BFSçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$ï¼Œç©ºé—´å¤æ‚åº¦ä¸º $O(|V|)$ã€‚

**è¯æ˜**ï¼š

- æ—¶é—´å¤æ‚åº¦ï¼šæ¯ä¸ªé¡¶ç‚¹æœ€å¤šå…¥é˜Ÿä¸€æ¬¡ï¼Œæ¯æ¡è¾¹æœ€å¤šè¢«æ£€æŸ¥ä¸€æ¬¡ï¼Œå› æ­¤æ€»æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$
- ç©ºé—´å¤æ‚åº¦ï¼šé˜Ÿåˆ—æœ€å¤šå­˜å‚¨ $O(|V|)$ ä¸ªé¡¶ç‚¹ï¼Œvisitedé›†åˆæœ€å¤šå­˜å‚¨ $O(|V|)$ ä¸ªé¡¶ç‚¹ï¼Œå› æ­¤æ€»ç©ºé—´å¤æ‚åº¦ä¸º $O(|V|)$ $\square$

## 3.2 æœ€çŸ­è·¯å¾„ç®—æ³•

### 3.2.1 Dijkstraç®—æ³•

**å®šä¹‰ 3.2.1** Dijkstraç®—æ³•ç”¨äºåœ¨å¸¦æƒå›¾ä¸­æ‰¾åˆ°ä»æºç‚¹åˆ°æ‰€æœ‰å…¶ä»–é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„ã€‚

**ç®—æ³• 3.2.1** Dijkstraç®—æ³•

```python
import heapq
from collections import defaultdict

def dijkstra(graph, start, return_paths=False):
    """
    Dijkstraç®—æ³•ï¼šè®¡ç®—ä»æºç‚¹åˆ°æ‰€æœ‰å…¶ä»–é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„

    å‚æ•°:
        graph: åŠ æƒå›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: {neighbor: weight}}
        start: èµ·å§‹é¡¶ç‚¹
        return_paths: æ˜¯å¦è¿”å›è·¯å¾„ä¿¡æ¯

    è¿”å›:
        distances: ä»startåˆ°æ‰€æœ‰é¡¶ç‚¹çš„æœ€çŸ­è·ç¦»
        paths: ä»startåˆ°æ‰€æœ‰é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„ï¼ˆå¦‚æœreturn_paths=Trueï¼‰
    """
    # åˆå§‹åŒ–è·ç¦»å’Œå‰é©±
    distances = {vertex: float('infinity') for vertex in graph}
    distances[start] = 0
    predecessors = {vertex: None for vertex in graph}
    pq = [(0, start)]
    visited = set()

    while pq:
        current_distance, current_vertex = heapq.heappop(pq)

        # è·³è¿‡å·²å¤„ç†è¿‡çš„é¡¶ç‚¹ï¼ˆå¯èƒ½æœ‰æ›´çŸ­çš„è·¯å¾„å·²å…¥é˜Ÿï¼‰
        if current_vertex in visited:
            continue

        visited.add(current_vertex)

        # éå†æ‰€æœ‰é‚»å±…
        for neighbor, weight in graph.get(current_vertex, {}).items():
            if neighbor in visited:
                continue

            distance = current_distance + weight

            # å¦‚æœæ‰¾åˆ°æ›´çŸ­çš„è·¯å¾„ï¼Œæ›´æ–°è·ç¦»å’Œå‰é©±
            if distance < distances[neighbor]:
                distances[neighbor] = distance
                predecessors[neighbor] = current_vertex
                heapq.heappush(pq, (distance, neighbor))

    if return_paths:
        paths = {}
        for vertex in graph:
            if distances[vertex] == float('infinity'):
                paths[vertex] = None  # ä¸å¯è¾¾
            else:
                # é‡æ„è·¯å¾„
                path = []
                current = vertex
                while current is not None:
                    path.append(current)
                    current = predecessors[current]
                path.reverse()
                paths[vertex] = path
        return distances, paths

    return distances

def dijkstra_shortest_path(graph, start, target):
    """
    Dijkstraç®—æ³•ï¼šè®¡ç®—ä»startåˆ°targetçš„æœ€çŸ­è·¯å¾„

    å‚æ•°:
        graph: åŠ æƒå›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        start: èµ·å§‹é¡¶ç‚¹
        target: ç›®æ ‡é¡¶ç‚¹

    è¿”å›:
        distance: æœ€çŸ­è·ç¦»ï¼Œå¦‚æœä¸å¯è¾¾è¿”å›None
        path: æœ€çŸ­è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸å¯è¾¾è¿”å›None
    """
    distances, paths = dijkstra(graph, start, return_paths=True)

    if distances[target] == float('infinity'):
        return None, None

    return distances[target], paths[target]

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹å›¾ï¼šåŸå¸‚ä¹‹é—´çš„é“è·¯ç½‘ç»œ
    city_graph = {
        'A': {'B': 4, 'C': 2},
        'B': {'A': 4, 'C': 1, 'D': 5},
        'C': {'A': 2, 'B': 1, 'D': 8, 'E': 10},
        'D': {'B': 5, 'C': 8, 'E': 2},
        'E': {'C': 10, 'D': 2}
    }

    # è®¡ç®—ä»Aåˆ°æ‰€æœ‰åŸå¸‚çš„æœ€çŸ­è·ç¦»
    distances = dijkstra(city_graph, 'A')
    print("ä»Aåˆ°å„åŸå¸‚çš„æœ€çŸ­è·ç¦»:", distances)
    # è¾“å‡º: {'A': 0, 'B': 3, 'C': 2, 'D': 8, 'E': 10}

    # è®¡ç®—ä»Aåˆ°Eçš„æœ€çŸ­è·¯å¾„
    distance, path = dijkstra_shortest_path(city_graph, 'A', 'E')
    print(f"ä»Aåˆ°Eçš„æœ€çŸ­è·ç¦»: {distance}, è·¯å¾„: {' -> '.join(path)}")
    # è¾“å‡º: ä»Aåˆ°Eçš„æœ€çŸ­è·ç¦»: 10, è·¯å¾„: A -> C -> E
```

**å®šç† 3.2.1** (Dijkstraç®—æ³•æ­£ç¡®æ€§ / Dijkstra Algorithm Correctness)
Dijkstraç®—æ³•èƒ½å¤Ÿæ­£ç¡®è®¡ç®—ä»æºç‚¹ $s$ åˆ°æ‰€æœ‰å…¶ä»–é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„ï¼ˆå‡è®¾æ‰€æœ‰è¾¹æƒé‡éè´Ÿï¼‰ã€‚

**å½¢å¼åŒ–è¯æ˜ / Formal Proof**ï¼š

**æ­¥éª¤ 1**ï¼šå¾ªç¯ä¸å˜å¼ï¼ˆLoop Invariantï¼‰
åœ¨ç®—æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œå¯¹äºå·²è®¿é—®çš„é¡¶ç‚¹é›†åˆ $S$ï¼Œç®—æ³•ç»´æŠ¤çš„å¾ªç¯ä¸å˜å¼æ˜¯ï¼š

- **æ€§è´¨1**ï¼šå¯¹äºæ‰€æœ‰ $v \in S$ï¼Œ$d[v]$ æ˜¯ä» $s$ åˆ° $v$ çš„æœ€çŸ­è·¯å¾„é•¿åº¦
- **æ€§è´¨2**ï¼šå¯¹äºæ‰€æœ‰ $v \notin S$ï¼Œ$d[v]$ æ˜¯ä» $s$ åˆ° $v$ ä¸”åªç»è¿‡ $S$ ä¸­é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„é•¿åº¦ï¼ˆå¦‚æœå­˜åœ¨è¿™æ ·çš„è·¯å¾„ï¼‰

**æ­¥éª¤ 2**ï¼šåŸºç¡€æƒ…å†µï¼ˆInitializationï¼‰
åˆå§‹æ—¶ï¼Œ$S = \emptyset$ï¼Œ$d[s] = 0$ï¼Œå¯¹äºæ‰€æœ‰ $v \neq s$ï¼Œ$d[v] = \infty$ã€‚

- æ€§è´¨1ï¼š$S = \emptyset$ï¼Œç©ºçœŸæˆç«‹
- æ€§è´¨2ï¼šå¯¹äº $v \notin S$ï¼Œ$d[v] = \infty$ è¡¨ç¤ºä¸å­˜åœ¨åªç»è¿‡ $S$ï¼ˆç©ºé›†ï¼‰çš„è·¯å¾„ï¼Œæ­£ç¡®

å› æ­¤ï¼Œå¾ªç¯ä¸å˜å¼åœ¨åˆå§‹åŒ–æ—¶æˆç«‹ã€‚

**æ­¥éª¤ 3**ï¼šä¿æŒï¼ˆMaintenanceï¼‰
å‡è®¾åœ¨æ·»åŠ é¡¶ç‚¹ $u$ ä¹‹å‰ï¼Œå¾ªç¯ä¸å˜å¼æˆç«‹ã€‚è®¾ $u$ æ˜¯ä¸‹ä¸€ä¸ªè¦æ·»åŠ åˆ° $S$ çš„é¡¶ç‚¹ï¼ˆå³ $d[u]$ æœ€å°ï¼Œä¸” $u \notin S$ï¼‰ã€‚

**éœ€è¦è¯æ˜**ï¼šå°† $u$ æ·»åŠ åˆ° $S$ åï¼Œå¾ªç¯ä¸å˜å¼ä»ç„¶æˆç«‹ã€‚

**è¯æ˜æ€§è´¨1**ï¼šéœ€è¦è¯æ˜ $d[u]$ æ˜¯ä» $s$ åˆ° $u$ çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

**åè¯æ³•**ï¼šå‡è®¾å­˜åœ¨ä» $s$ åˆ° $u$ çš„è·¯å¾„ $P$ï¼Œå…¶é•¿åº¦ $l(P) < d[u]$ã€‚

ç”±äº $u \notin S$ï¼Œè·¯å¾„ $P$ å¿…é¡»ç¦»å¼€ $S$ï¼ˆå› ä¸ºå¦‚æœ $P$ å®Œå…¨åœ¨ $S$ ä¸­ï¼Œåˆ™ç”±æ€§è´¨2ï¼Œ$d[u] \leq l(P)$ï¼ŒçŸ›ç›¾ï¼‰ã€‚

è®¾ $y$ æ˜¯è·¯å¾„ $P$ ä¸Šç¬¬ä¸€ä¸ªä¸åœ¨ $S$ ä¸­çš„é¡¶ç‚¹ï¼Œ$x$ æ˜¯ $y$ åœ¨è·¯å¾„ $P$ ä¸Šçš„å‰é©±ï¼ˆ$x \in S$ï¼‰ã€‚

ç”±æ€§è´¨1ï¼Œ$d[x]$ æ˜¯ä» $s$ åˆ° $x$ çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

ç”±æ€§è´¨2ï¼Œ$d[y]$ æ˜¯ä» $s$ åˆ° $y$ ä¸”åªç»è¿‡ $S$ ä¸­é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

ç”±äºè·¯å¾„ $P$ ä» $s$ åˆ° $y$ çš„éƒ¨åˆ†åªç»è¿‡ $S$ ä¸­çš„é¡¶ç‚¹ï¼ˆ$x \in S$ï¼‰ï¼Œæˆ‘ä»¬æœ‰ï¼š
$$d[y] \leq d[x] + w(x, y) \leq l(P_{s \to y}) \leq l(P) < d[u]$$

å…¶ä¸­ $P_{s \to y}$ æ˜¯è·¯å¾„ $P$ ä» $s$ åˆ° $y$ çš„éƒ¨åˆ†ã€‚

ä½† $d[y] < d[u]$ ä¸ $u$ æ˜¯ $d$ å€¼æœ€å°çš„æœªè®¿é—®é¡¶ç‚¹ï¼ˆ$u, y \notin S$ï¼‰çŸ›ç›¾ï¼

å› æ­¤ï¼Œå‡è®¾ä¸æˆç«‹ï¼Œ$d[u]$ æ˜¯ä» $s$ åˆ° $u$ çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

**è¯æ˜æ€§è´¨2**ï¼šå¯¹äºæ‰€æœ‰ $v \notin S \cup \{u\}$ï¼Œéœ€è¦è¯æ˜ $d[v]$ æ˜¯ä» $s$ åˆ° $v$ ä¸”åªç»è¿‡ $S \cup \{u\}$ ä¸­é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

åœ¨æ·»åŠ  $u$ åï¼Œç®—æ³•ä¼šæ›´æ–° $u$ çš„æ‰€æœ‰é‚»å±… $v$ï¼š
$$d[v] = \min(d[v], d[u] + w(u, v))$$

è¿™ä¿è¯äº† $d[v]$ æ˜¯ä» $s$ åˆ° $v$ ä¸”åªç»è¿‡ $S \cup \{u\}$ ä¸­é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

å› æ­¤ï¼Œå¾ªç¯ä¸å˜å¼åœ¨æ¯æ¬¡è¿­ä»£åä¿æŒã€‚

**æ­¥éª¤ 4**ï¼šç»ˆæ­¢ï¼ˆTerminationï¼‰
å½“ç®—æ³•ç»ˆæ­¢æ—¶ï¼Œ$S = V$ï¼ˆæ‰€æœ‰é¡¶ç‚¹éƒ½å·²è®¿é—®ï¼‰ã€‚

ç”±æ€§è´¨1ï¼Œå¯¹äºæ‰€æœ‰ $v \in V$ï¼Œ$d[v]$ æ˜¯ä» $s$ åˆ° $v$ çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

å› æ­¤ï¼Œç®—æ³•æ­£ç¡®ã€‚$\square$

**å®šç† 3.2.2** (Dijkstraç®—æ³•æ—¶é—´å¤æ‚åº¦ / Dijkstra Algorithm Time Complexity)
Dijkstraç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O((|V| + |E|) \log |V|)$ã€‚

**è¯æ˜**ï¼š

- æ¯ä¸ªé¡¶ç‚¹æœ€å¤šå…¥é˜Ÿä¸€æ¬¡ï¼š$O(|V|)$
- æ¯æ¡è¾¹æœ€å¤šè¢«æ¾å¼›ä¸€æ¬¡ï¼š$O(|E|)$
- æ¯æ¬¡å †æ“ä½œï¼š$O(\log |V|)$
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O((|V| + |E|) \log |V|)$ $\square$

**å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼š

1. **GPSå¯¼èˆªç³»ç»Ÿ**ï¼š
   - Google Mapsã€é«˜å¾·åœ°å›¾ä½¿ç”¨Dijkstraç®—æ³•çš„å˜ä½“
   - è®¡ç®—ä¸¤ç‚¹é—´æœ€çŸ­é©¾è½¦è·¯å¾„
   - å¤„ç†æ•°ç™¾ä¸‡ä¸ªé“è·¯èŠ‚ç‚¹ï¼Œå“åº”æ—¶é—´<1ç§’

2. **ç½‘ç»œè·¯ç”±åè®®**ï¼š
   - OSPFï¼ˆå¼€æ”¾æœ€çŸ­è·¯å¾„ä¼˜å…ˆï¼‰åè®®
   - è®¡ç®—è·¯ç”±å™¨ä¹‹é—´çš„æœ€çŸ­è·¯å¾„
   - å®æ—¶æ›´æ–°è·¯ç”±è¡¨

3. **ç¤¾äº¤ç½‘ç»œæ¨è**ï¼š
   - è®¡ç®—ç”¨æˆ·ä¹‹é—´çš„æœ€çŸ­å…³ç³»é“¾
   - æ¨èå¯èƒ½è®¤è¯†çš„äºº

**æƒå¨æ¥æºå¼•ç”¨**ï¼š

- **Wikipedia**: [Dijkstra's algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)
- **CLRS 4th Edition**: Chapter 22.3 - Single-source shortest paths
- **MIT 6.006**: Lecture 15 - Shortest paths I

### 3.2.2 Bellman-Fordç®—æ³•

**å®šä¹‰ 3.2.2** Bellman-Fordç®—æ³•æ˜¯è§£å†³å•æºæœ€çŸ­è·¯å¾„é—®é¢˜çš„åŠ¨æ€è§„åˆ’ç®—æ³•ï¼Œå¯ä»¥å¤„ç†è´Ÿæƒé‡è¾¹ï¼Œå¹¶èƒ½æ£€æµ‹è´Ÿæƒé‡ç¯ã€‚

**ç®—æ³• 3.2.2** Bellman-Fordç®—æ³•

```python
def bellman_ford(graph, start):
    """
    Bellman-Fordç®—æ³•å®ç°

    å‚æ•°:
        graph: åŠ æƒå›¾çš„è¾¹åˆ—è¡¨è¡¨ç¤º [(u, v, weight), ...]
        start: èµ·å§‹é¡¶ç‚¹

    è¿”å›:
        distances: ä»startåˆ°æ‰€æœ‰é¡¶ç‚¹çš„æœ€çŸ­è·ç¦»
        has_negative_cycle: æ˜¯å¦å­˜åœ¨è´Ÿæƒé‡ç¯
        predecessors: æœ€çŸ­è·¯å¾„çš„å‰é©±é¡¶ç‚¹
    """
    # è·å–æ‰€æœ‰é¡¶ç‚¹
    vertices = set()
    for u, v, w in graph:
        vertices.add(u)
        vertices.add(v)
    num_vertices = len(vertices)
    vertex_list = list(vertices)
    vertex_to_index = {v: i for i, v in enumerate(vertex_list)}

    # åˆå§‹åŒ–è·ç¦»æ•°ç»„
    distances = {v: float('inf') for v in vertices}
    distances[start] = 0
    predecessors = {v: None for v in vertices}

    # æ¾å¼› |V| - 1 æ¬¡
    for _ in range(num_vertices - 1):
        updated = False
        for u, v, weight in graph:
            u_idx = vertex_to_index[u]
            v_idx = vertex_to_index[v]

            if distances[u] != float('inf') and distances[u] + weight < distances[v]:
                distances[v] = distances[u] + weight
                predecessors[v] = u
                updated = True

        # å¦‚æœæ²¡æœ‰æ›´æ–°ï¼Œæå‰ç»ˆæ­¢
        if not updated:
            break

    # æ£€æŸ¥è´Ÿæƒé‡ç¯
    has_negative_cycle = False
    for u, v, weight in graph:
        if distances[u] != float('inf') and distances[u] + weight < distances[v]:
            has_negative_cycle = True
            break

    return distances, has_negative_cycle, predecessors

def reconstruct_path(predecessors, start, target):
    """é‡æ„æœ€çŸ­è·¯å¾„"""
    if predecessors[target] is None and target != start:
        return None  # ä¸å¯è¾¾

    path = []
    current = target
    while current is not None:
        path.append(current)
        current = predecessors[current]

    path.reverse()
    return path
```

**å®šç† 3.2.3** (Bellman-Fordç®—æ³•æ­£ç¡®æ€§ / Bellman-Ford Algorithm Correctness)
Bellman-Fordç®—æ³•èƒ½å¤Ÿæ­£ç¡®è®¡ç®—ä»æºç‚¹ $s$ åˆ°æ‰€æœ‰å…¶ä»–é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„ï¼ˆå¦‚æœä¸å­˜åœ¨è´Ÿæƒé‡ç¯ï¼‰ã€‚

**å½¢å¼åŒ–è¯æ˜ / Formal Proof**ï¼š

**æ­¥éª¤ 1**ï¼šæœ€çŸ­è·¯å¾„æ€§è´¨
å¯¹äºä»æºç‚¹ $s$ åˆ°é¡¶ç‚¹ $v$ çš„æœ€çŸ­è·¯å¾„ï¼Œæœ€å¤šåŒ…å« $|V| - 1$ æ¡è¾¹ï¼ˆå¦åˆ™å­˜åœ¨ç¯ï¼Œå¯ä»¥åˆ é™¤ï¼‰ã€‚

**æ­¥éª¤ 2**ï¼šæ¾å¼›æ“ä½œçš„æ­£ç¡®æ€§
ç»è¿‡ $k$ æ¬¡å¯¹æ‰€æœ‰è¾¹çš„æ¾å¼›æ“ä½œåï¼Œ$d[v]$ æ˜¯ä» $s$ åˆ° $v$ ä¸”æœ€å¤šç»è¿‡ $k$ æ¡è¾¹çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

**æ­¥éª¤ 3**ï¼šå½’çº³è¯æ˜

- **åŸºç¡€æƒ…å†µ**ï¼ˆ$k = 0$ï¼‰ï¼š$d[s] = 0$ï¼Œå…¶ä»–ä¸º $\infty$ï¼Œæ˜¾ç„¶æˆç«‹ã€‚
- **å½’çº³æ­¥éª¤**ï¼šå‡è®¾å¯¹ $k$ æˆç«‹ï¼Œç»è¿‡ $k+1$ æ¬¡æ¾å¼›åï¼Œ$d[v]$ æ˜¯ä» $s$ åˆ° $v$ ä¸”æœ€å¤šç»è¿‡ $k+1$ æ¡è¾¹çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

**æ­¥éª¤ 4**ï¼šè´Ÿç¯æ£€æµ‹
å¦‚æœç»è¿‡ $|V| - 1$ æ¬¡æ¾å¼›åï¼Œè¿˜èƒ½ç»§ç»­æ¾å¼›ï¼Œåˆ™å­˜åœ¨è´Ÿæƒé‡ç¯ã€‚

å› æ­¤ï¼ŒBellman-Fordç®—æ³•æ­£ç¡®ã€‚$\square$

**å®šç† 3.2.4** (Bellman-Fordç®—æ³•æ—¶é—´å¤æ‚åº¦ / Bellman-Ford Algorithm Time Complexity)
Bellman-Fordç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| \cdot |E|)$ã€‚

**è¯æ˜**ï¼š

- å¤–å±‚å¾ªç¯ï¼š$|V| - 1$ æ¬¡
- å†…å±‚å¾ªç¯ï¼šéå†æ‰€æœ‰è¾¹ $O(|E|)$
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|V| \cdot |E|)$ $\square$

**å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼š

1. **é‡‘èç³»ç»Ÿä¸­çš„å¥—åˆ©æ£€æµ‹**ï¼š
   - è´§å¸å…‘æ¢ç½‘ç»œä¸­çš„å¥—åˆ©æœºä¼šæ£€æµ‹
   - è´Ÿæƒé‡ç¯è¡¨ç¤ºå¥—åˆ©å¾ªç¯
   - å®æ—¶ç›‘æ§å¤–æ±‡å¸‚åœºå¥—åˆ©æœºä¼š

2. **ç½‘ç»œå»¶è¿Ÿè®¡ç®—**ï¼š
   - æŸäº›ç½‘ç»œè·¯å¾„å¯èƒ½æœ‰"è´Ÿå»¶è¿Ÿ"ï¼ˆå¦‚ç¼“å­˜å‘½ä¸­ï¼‰
   - éœ€è¦æ£€æµ‹å¼‚å¸¸çš„å»¶è¿Ÿå¾ªç¯

3. **ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ**ï¼š
   - æ£€æµ‹ä»»åŠ¡ä¾èµ–ä¸­çš„è´Ÿæƒé‡å¾ªç¯
   - è¯†åˆ«ä¸å¯è¡Œçš„è°ƒåº¦æ–¹æ¡ˆ

**ä¸Dijkstraçš„å¯¹æ¯”**ï¼š

| ç‰¹æ€§ | Dijkstra | Bellman-Ford |
|------|----------|--------------|
| æƒé‡é™åˆ¶ | éè´Ÿ | ä»»æ„ |
| æ—¶é—´å¤æ‚åº¦ | O((V+E)log V) | O(VE) |
| è´Ÿç¯æ£€æµ‹ | ä¸æ”¯æŒ | æ”¯æŒ |
| é€‚ç”¨åœºæ™¯ | éè´Ÿæƒé‡å›¾ | å¯èƒ½æœ‰è´Ÿæƒé‡çš„å›¾ |

**æƒå¨æ¥æºå¼•ç”¨**ï¼š

- **Wikipedia**: [Bellmanâ€“Ford algorithm](https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm)
- **CLRS 4th Edition**: Chapter 22.1 - The Bellman-Ford algorithm
- **MIT 6.006**: Lecture 16 - Shortest paths II: Bellman-Ford

### 3.2.3 Floyd-Warshallç®—æ³•

**å®šä¹‰ 3.2.2** Floyd-Warshallç®—æ³•ç”¨äºæ‰¾åˆ°å›¾ä¸­æ‰€æœ‰é¡¶ç‚¹å¯¹ä¹‹é—´çš„æœ€çŸ­è·¯å¾„ã€‚

**ç®—æ³• 3.2.2** Floyd-Warshallç®—æ³•

```python
def floyd_warshall(graph):
    n = len(graph)
    dist = [[float('inf')] * n for _ in range(n)]

    # åˆå§‹åŒ–è·ç¦»çŸ©é˜µ
    for i in range(n):
        dist[i][i] = 0
        for j, weight in graph[i].items():
            dist[i][j] = weight

    # Floyd-Warshallæ ¸å¿ƒç®—æ³•
    for k in range(n):
        for i in range(n):
            for j in range(n):
                if dist[i][k] + dist[k][j] < dist[i][j]:
                    dist[i][j] = dist[i][k] + dist[k][j]

    return dist
```

**å®šç† 3.2.5** (Floyd-Warshallç®—æ³•æ­£ç¡®æ€§ / Floyd-Warshall Algorithm Correctness)
Floyd-Warshallç®—æ³•èƒ½å¤Ÿæ­£ç¡®è®¡ç®—æ‰€æœ‰é¡¶ç‚¹å¯¹ä¹‹é—´çš„æœ€çŸ­è·¯å¾„ã€‚

**å½¢å¼åŒ–è¯æ˜ / Formal Proof**ï¼š

**æ­¥éª¤ 1**ï¼šå­é—®é¢˜å®šä¹‰
è®¾ $d^{(k)}[i][j]$ è¡¨ç¤ºä»é¡¶ç‚¹ $i$ åˆ°é¡¶ç‚¹ $j$ ä¸”ä¸­é—´é¡¶ç‚¹ç¼–å·ä¸è¶…è¿‡ $k$ çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

**æ­¥éª¤ 2**ï¼šé€’æ¨å…³ç³»
$$d^{(k)}[i][j] = \min(d^{(k-1)}[i][j], d^{(k-1)}[i][k] + d^{(k-1)}[k][j])$$

**è§£é‡Š**ï¼š

- $d^{(k-1)}[i][j]$ï¼šä¸ç»è¿‡é¡¶ç‚¹ $k$ çš„æœ€çŸ­è·¯å¾„
- $d^{(k-1)}[i][k] + d^{(k-1)}[k][j]$ï¼šç»è¿‡é¡¶ç‚¹ $k$ çš„æœ€çŸ­è·¯å¾„

**æ­¥éª¤ 3**ï¼šåŸºç¡€æƒ…å†µ
$d^{(0)}[i][j] = w(i, j)$ï¼ˆå¦‚æœè¾¹ $(i, j)$ å­˜åœ¨ï¼‰ï¼Œå¦åˆ™ä¸º $\infty$ã€‚

**æ­¥éª¤ 4**ï¼šå½’çº³è¯æ˜
ä½¿ç”¨æ•°å­¦å½’çº³æ³•è¯æ˜ï¼šå¯¹äºæ‰€æœ‰ $k$ï¼Œ$d^{(k)}[i][j]$ è¡¨ç¤ºä» $i$ åˆ° $j$ ä¸”ä¸­é—´é¡¶ç‚¹ç¼–å·ä¸è¶…è¿‡ $k$ çš„æœ€çŸ­è·¯å¾„é•¿åº¦ã€‚

**åŸºç¡€æƒ…å†µ**ï¼ˆ$k = 0$ï¼‰ï¼šæ˜¾ç„¶æˆç«‹ã€‚

**å½’çº³å‡è®¾**ï¼šå‡è®¾å¯¹ $k-1$ æˆç«‹ã€‚

**å½’çº³æ­¥éª¤**ï¼š
å¯¹äºä» $i$ åˆ° $j$ ä¸”ä¸­é—´é¡¶ç‚¹ç¼–å·ä¸è¶…è¿‡ $k$ çš„æœ€çŸ­è·¯å¾„ï¼š

- å¦‚æœä¸ç»è¿‡ $k$ï¼Œåˆ™é•¿åº¦ä¸º $d^{(k-1)}[i][j]$
- å¦‚æœç»è¿‡ $k$ï¼Œåˆ™é•¿åº¦ä¸º $d^{(k-1)}[i][k] + d^{(k-1)}[k][j]$

å› æ­¤ï¼Œ$d^{(k)}[i][j] = \min(d^{(k-1)}[i][j], d^{(k-1)}[i][k] + d^{(k-1)}[k][j])$ã€‚

**æ­¥éª¤ 5**ï¼šç»“è®º
å½“ $k = |V| - 1$ æ—¶ï¼Œ$d^{(|V|-1)}[i][j]$ è¡¨ç¤ºä» $i$ åˆ° $j$ çš„æœ€çŸ­è·¯å¾„é•¿åº¦ï¼ˆå…è®¸ç»è¿‡æ‰€æœ‰é¡¶ç‚¹ï¼‰ã€‚$\square$

**å®šç† 3.2.6** (Floyd-Warshallç®—æ³•æ—¶é—´å¤æ‚åº¦ / Floyd-Warshall Algorithm Time Complexity)
Floyd-Warshallç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V|^3)$ã€‚

**è¯æ˜**ï¼š

- ä¸‰é‡å¾ªç¯ï¼š$O(|V|^3)$
- æ¯æ¬¡å¾ªç¯å†…çš„æ“ä½œï¼š$O(1)$
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|V|^3)$ $\square$

**å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼š

1. **è·¯ç”±è¡¨æ„å»º**ï¼š
   - è®¡ç®—ç½‘ç»œä¸­æ‰€æœ‰èŠ‚ç‚¹å¯¹ä¹‹é—´çš„æœ€çŸ­è·¯å¾„
   - ç”¨äºæ„å»ºè·¯ç”±è¡¨
   - é€‚ç”¨äºå°å‹ç½‘ç»œï¼ˆ< 200èŠ‚ç‚¹ï¼‰

2. **ä¼ é€’é—­åŒ…è®¡ç®—**ï¼š
   - è®¡ç®—æœ‰å‘å›¾çš„å¯è¾¾æ€§çŸ©é˜µ
   - åªéœ€è¦å°†è·ç¦»çŸ©é˜µæ”¹ä¸ºå¸ƒå°”çŸ©é˜µ
   - ç”¨äºä¾èµ–åˆ†æã€å¯è¾¾æ€§æŸ¥è¯¢

3. **ç¤¾äº¤ç½‘ç»œè·ç¦»åˆ†æ**ï¼š
   - è®¡ç®—æ‰€æœ‰ç”¨æˆ·å¯¹ä¹‹é—´çš„æœ€çŸ­å…³ç³»é“¾
   - ç”¨äºæ¨èç³»ç»Ÿå’Œç¤¾åŒºåˆ†æ

**æ€§èƒ½ç‰¹ç‚¹**ï¼š

- **ä¼˜åŠ¿**ï¼šä»£ç ç®€å•ï¼Œå®ç°å®¹æ˜“ï¼Œé€‚åˆå°è§„æ¨¡å›¾
- **åŠ£åŠ¿**ï¼šæ—¶é—´å¤æ‚åº¦é«˜ï¼Œä¸é€‚åˆå¤§è§„æ¨¡å›¾

**é€‰æ‹©æŒ‡å—**ï¼š

- å°è§„æ¨¡å›¾ï¼ˆ$|V| < 200$ï¼‰ï¼šä½¿ç”¨Floyd-Warshall
- å¤§è§„æ¨¡å›¾ï¼ˆ$|V| \geq 200$ï¼‰ï¼šä½¿ç”¨å¤šæ¬¡Dijkstraæˆ–Bellman-Ford

**æƒå¨æ¥æºå¼•ç”¨**ï¼š

- **Wikipedia**: [Floydâ€“Warshall algorithm](https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm)
- **CLRS 4th Edition**: Chapter 22.2 - All-pairs shortest paths
- **MIT 6.006**: Lecture 17 - Shortest paths III: All-pairs shortest paths

## 3.3 æœ€å°ç”Ÿæˆæ ‘ç®—æ³•

### 3.3.1 Kruskalç®—æ³•

**å®šä¹‰ 3.3.1** Kruskalç®—æ³•ç”¨äºåœ¨å¸¦æƒæ— å‘å›¾ä¸­æ‰¾åˆ°æœ€å°ç”Ÿæˆæ ‘ã€‚

**ç®—æ³• 3.3.1** Kruskalç®—æ³•

```python
class UnionFind:
    def __init__(self, n):
        self.parent = list(range(n))
        self.rank = [0] * n

    def find(self, x):
        if self.parent[x] != x:
            self.parent[x] = self.find(self.parent[x])
        return self.parent[x]

    def union(self, x, y):
        px, py = self.find(x), self.find(y)
        if px == py:
            return False
        if self.rank[px] < self.rank[py]:
            px, py = py, px
        self.parent[py] = px
        if self.rank[px] == self.rank[py]:
            self.rank[px] += 1
        return True

def kruskal(graph):
    """
    Kruskalç®—æ³•ï¼šæ‰¾å›¾çš„æœ€å°ç”Ÿæˆæ ‘

    å‚æ•°:
        graph: åŠ æƒæ— å‘å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: {neighbor: weight}}

    è¿”å›:
        mst: æœ€å°ç”Ÿæˆæ ‘çš„è¾¹åˆ—è¡¨ [(u, v, weight), ...]
        total_weight: æœ€å°ç”Ÿæˆæ ‘çš„æ€»æƒé‡
    """
    # è·å–æ‰€æœ‰è¾¹å¹¶å»é‡ï¼ˆæ— å‘å›¾ä¸­(u,v)å’Œ(v,u)æ˜¯åŒä¸€æ‰¹è¾¹ï¼‰
    edges = []
    seen_edges = set()

    for u in graph:
        for v, weight in graph.get(u, {}).items():
            # é¿å…é‡å¤è¾¹ï¼ˆæ— å‘å›¾ï¼‰
            edge_key = tuple(sorted([u, v]))
            if edge_key not in seen_edges:
                seen_edges.add(edge_key)
                edges.append((weight, u, v))

    # æŒ‰æƒé‡æ’åº
    edges.sort()

    # åˆ›å»ºå¹¶æŸ¥é›†
    vertices = list(graph.keys())
    vertex_to_index = {v: i for i, v in enumerate(vertices)}
    uf = UnionFind(len(vertices))

    mst = []
    total_weight = 0

    # éå†æ‰€æœ‰è¾¹ï¼ŒæŒ‰æƒé‡ä»å°åˆ°å¤§
    for weight, u, v in edges:
        u_idx = vertex_to_index[u]
        v_idx = vertex_to_index[v]

        # å¦‚æœuå’Œvä¸åœ¨åŒä¸€ä¸ªè¿é€šåˆ†é‡ä¸­ï¼Œæ·»åŠ è¿™æ¡è¾¹
        if uf.union(u_idx, v_idx):
            mst.append((u, v, weight))
            total_weight += weight

            # å¦‚æœå·²ç»æ‰¾åˆ°n-1æ¡è¾¹ï¼ˆnä¸ªé¡¶ç‚¹çš„æ ‘éœ€è¦n-1æ¡è¾¹ï¼‰ï¼Œå¯ä»¥æå‰ç»“æŸ
            if len(mst) == len(vertices) - 1:
                break

    return mst, total_weight

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹å›¾ï¼šåŸå¸‚ä¹‹é—´çš„é€šä¿¡ç½‘ç»œï¼ˆæƒé‡è¡¨ç¤ºå»ºè®¾æˆæœ¬ï¼‰
    network_graph = {
        'A': {'B': 4, 'C': 2},
        'B': {'A': 4, 'C': 1, 'D': 5},
        'C': {'A': 2, 'B': 1, 'D': 8, 'E': 10},
        'D': {'B': 5, 'C': 8, 'E': 2},
        'E': {'C': 10, 'D': 2}
    }

    mst_edges, total_cost = kruskal(network_graph)
    print("æœ€å°ç”Ÿæˆæ ‘è¾¹:", mst_edges)
    print("æ€»æˆæœ¬:", total_cost)
    # è¾“å‡º: æœ€å°ç”Ÿæˆæ ‘è¾¹: [('B', 'C', 1), ('A', 'C', 2), ('D', 'E', 2), ('B', 'D', 5)]
    # æ€»æˆæœ¬: 10
```

**å®šç† 3.3.1** (Kruskalç®—æ³•æ­£ç¡®æ€§ / Kruskal Algorithm Correctness)
Kruskalç®—æ³•èƒ½å¤Ÿæ­£ç¡®æ‰¾åˆ°å›¾çš„æœ€å°ç”Ÿæˆæ ‘ã€‚

**å½¢å¼åŒ–è¯æ˜ / Formal Proof**ï¼š

**æ­¥éª¤ 1**ï¼šå®‰å…¨è¾¹æ€§è´¨ï¼ˆSafe Edge Propertyï¼‰
è®¾ $G = (V, E)$ æ˜¯ä¸€ä¸ªè¿é€šæ— å‘å›¾ï¼Œ$w: E \to \mathbb{R}^+$ æ˜¯æƒé‡å‡½æ•°ã€‚

**å¼•ç† 3.3.1**ï¼ˆå®‰å…¨è¾¹å¼•ç†ï¼‰ï¼šè®¾ $A$ æ˜¯æŸä¸ªæœ€å°ç”Ÿæˆæ ‘çš„å­é›†ï¼Œ$(S, V \setminus S)$ æ˜¯ $G$ çš„ä¸€ä¸ªå‰²ï¼Œä¸” $A$ ä¸è·¨è¶Šè¯¥å‰²ã€‚å¦‚æœ $e$ æ˜¯è·¨è¶Šè¯¥å‰²çš„æƒé‡æœ€å°çš„è¾¹ï¼Œåˆ™ $e$ å¯¹äº $A$ æ˜¯å®‰å…¨çš„ï¼ˆå³å­˜åœ¨åŒ…å« $A \cup \{e\}$ çš„æœ€å°ç”Ÿæˆæ ‘ï¼‰ã€‚

**è¯æ˜å¼•ç† 3.3.1**ï¼š
è®¾ $T^*$ æ˜¯åŒ…å« $A$ çš„æœ€å°ç”Ÿæˆæ ‘ã€‚å¦‚æœ $e \in T^*$ï¼Œåˆ™å¼•ç†æˆç«‹ã€‚

å¦‚æœ $e \notin T^*$ï¼Œåˆ™å°† $e$ æ·»åŠ åˆ° $T^*$ ä¸­ä¼šå½¢æˆä¸€ä¸ªåœˆ $C$ã€‚

ç”±äº $e$ è·¨è¶Šå‰² $(S, V \setminus S)$ï¼Œåœˆ $C$ ä¸­å¿…æœ‰ä¸€æ¡è¾¹ $f \neq e$ ä¹Ÿè·¨è¶Šè¯¥å‰²ã€‚

ç”±äº $e$ æ˜¯è·¨è¶Šè¯¥å‰²çš„æƒé‡æœ€å°çš„è¾¹ï¼Œ$w(e) \leq w(f)$ã€‚

å°† $T^*$ ä¸­çš„è¾¹ $f$ æ›¿æ¢ä¸º $e$ï¼Œå¾—åˆ° $T' = T^* - \{f\} + \{e\}$ã€‚

ç”±äº $w(e) \leq w(f)$ï¼Œ$w(T') \leq w(T^*)$ï¼Œå› æ­¤ $T'$ ä¹Ÿæ˜¯æœ€å°ç”Ÿæˆæ ‘ï¼Œä¸”åŒ…å« $A \cup \{e\}$ã€‚

å› æ­¤ $e$ å¯¹äº $A$ æ˜¯å®‰å…¨çš„ã€‚$\square$

**æ­¥éª¤ 2**ï¼šKruskalç®—æ³•çš„æ­£ç¡®æ€§
Kruskalç®—æ³•æŒ‰æƒé‡é€’å¢é¡ºåºè€ƒè™‘è¾¹ï¼Œå¯¹äºæ¯æ¡è¾¹ $e = (u, v)$ï¼š

- å¦‚æœ $u$ å’Œ $v$ ä¸åœ¨åŒä¸€ä¸ªè¿é€šåˆ†é‡ä¸­ï¼ˆå³ $e$ è·¨è¶ŠæŸä¸ªå‰²ï¼‰ï¼Œåˆ™æ·»åŠ  $e$
- å¦åˆ™è·³è¿‡ $e$ï¼ˆå› ä¸ºä¼šå½¢æˆåœˆï¼‰

**è¯æ˜**ï¼šä½¿ç”¨æ•°å­¦å½’çº³æ³•

**åŸºç¡€æƒ…å†µ**ï¼šåˆå§‹æ—¶ï¼Œ$A = \emptyset$ï¼Œæ˜¯æŸä¸ªæœ€å°ç”Ÿæˆæ ‘çš„å­é›†ï¼ˆç©ºé›†ï¼‰ã€‚

**å½’çº³å‡è®¾**ï¼šå‡è®¾åœ¨è€ƒè™‘è¾¹ $e$ ä¹‹å‰ï¼Œ$A$ æ˜¯æŸä¸ªæœ€å°ç”Ÿæˆæ ‘ $T^*$ çš„å­é›†ã€‚

**å½’çº³æ­¥éª¤**ï¼šè€ƒè™‘è¾¹ $e = (u, v)$ã€‚

**æƒ…å†µ1**ï¼š$u$ å’Œ $v$ åœ¨åŒä¸€ä¸ªè¿é€šåˆ†é‡ä¸­ã€‚

- æ­¤æ—¶ $e$ ä¸è·¨è¶Šä»»ä½•å‰²ï¼ˆå› ä¸º $A$ ä¸è·¨è¶Šè¯¥å‰²ï¼‰
- æ·»åŠ  $e$ ä¼šå½¢æˆåœˆï¼Œå› æ­¤è·³è¿‡ $e$
- $A$ ä»ç„¶æ˜¯ $T^*$ çš„å­é›†ï¼Œä¸å˜å¼ä¿æŒ

**æƒ…å†µ2**ï¼š$u$ å’Œ $v$ ä¸åœ¨åŒä¸€ä¸ªè¿é€šåˆ†é‡ä¸­ã€‚

- è®¾ $S$ æ˜¯åŒ…å« $u$ çš„è¿é€šåˆ†é‡ï¼Œåˆ™ $(S, V \setminus S)$ æ˜¯ä¸€ä¸ªå‰²
- $A$ ä¸è·¨è¶Šè¯¥å‰²ï¼ˆå› ä¸º $u$ å’Œ $v$ ä¸åœ¨åŒä¸€è¿é€šåˆ†é‡ï¼‰
- $e$ æ˜¯è·¨è¶Šè¯¥å‰²çš„è¾¹ï¼Œä¸”ç”±äºç®—æ³•æŒ‰æƒé‡é€’å¢é¡ºåºè€ƒè™‘è¾¹ï¼Œ$e$ æ˜¯è·¨è¶Šè¯¥å‰²çš„æƒé‡æœ€å°çš„è¾¹
- ç”±å¼•ç† 3.3.1ï¼Œ$e$ å¯¹äº $A$ æ˜¯å®‰å…¨çš„
- æ·»åŠ  $e$ åï¼Œ$A \cup \{e\}$ æ˜¯æŸä¸ªæœ€å°ç”Ÿæˆæ ‘çš„å­é›†ï¼Œä¸å˜å¼ä¿æŒ

**æ­¥éª¤ 3**ï¼šç»ˆæ­¢
å½“ç®—æ³•ç»ˆæ­¢æ—¶ï¼Œ$A$ åŒ…å« $|V| - 1$ æ¡è¾¹ï¼Œä¸”æ˜¯æŸä¸ªæœ€å°ç”Ÿæˆæ ‘çš„å­é›†ã€‚

ç”±äºæœ€å°ç”Ÿæˆæ ‘æ°å¥½æœ‰ $|V| - 1$ æ¡è¾¹ï¼Œ$A$ æœ¬èº«å°±æ˜¯ä¸€ä¸ªæœ€å°ç”Ÿæˆæ ‘ã€‚

å› æ­¤ï¼ŒKruskalç®—æ³•æ­£ç¡®ã€‚$\square$

**å®šç† 3.3.2** (Kruskalç®—æ³•æ—¶é—´å¤æ‚åº¦ / Kruskal Algorithm Time Complexity)
Kruskalç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|E| \log |E|)$ã€‚

**è¯æ˜**ï¼š

- æ’åºè¾¹ï¼š$O(|E| \log |E|)$
- å¹¶æŸ¥é›†æ“ä½œï¼š$O(|E| \alpha(|V|))$ï¼Œå…¶ä¸­ $\alpha$ æ˜¯åé˜¿å…‹æ›¼å‡½æ•°
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|E| \log |E|)$ $\square$

### 3.3.2 Primç®—æ³•

**å®šä¹‰ 3.3.2** Primç®—æ³•æ˜¯å¦ä¸€ç§å¯»æ‰¾æœ€å°ç”Ÿæˆæ ‘çš„ç®—æ³•ï¼Œå®ƒä»å•ä¸ªé¡¶ç‚¹å¼€å§‹ï¼Œé€æ­¥æ‰©å±•æ ‘ã€‚

**ç®—æ³• 3.3.2** Primç®—æ³•

```python
import heapq

def prim(graph, start):
    """
    Primç®—æ³•ï¼šæ‰¾å›¾çš„æœ€å°ç”Ÿæˆæ ‘ï¼ˆä»æŒ‡å®šèµ·ç‚¹å¼€å§‹ï¼‰

    å‚æ•°:
        graph: åŠ æƒæ— å‘å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: {neighbor: weight}}
        start: èµ·å§‹é¡¶ç‚¹

    è¿”å›:
        mst: æœ€å°ç”Ÿæˆæ ‘çš„è¾¹åˆ—è¡¨ [(u, v, weight), ...]
        total_weight: æœ€å°ç”Ÿæˆæ ‘çš„æ€»æƒé‡
    """
    mst = []
    visited = set()
    edges = []  # ä¼˜å…ˆé˜Ÿåˆ—ï¼š(weight, from, to)
    total_weight = 0

    # åˆå§‹åŒ–ï¼šä»èµ·å§‹é¡¶ç‚¹å¼€å§‹
    visited.add(start)
    for neighbor, weight in graph.get(start, {}).items():
        heapq.heappush(edges, (weight, start, neighbor))

    # é€æ­¥æ‰©å±•æœ€å°ç”Ÿæˆæ ‘
    while edges and len(visited) < len(graph):
        weight, u, v = heapq.heappop(edges)

        # å¦‚æœç›®æ ‡é¡¶ç‚¹å·²ç»è®¿é—®è¿‡ï¼Œè·³è¿‡
        if v in visited:
            continue

        # æ·»åŠ é¡¶ç‚¹vå’Œè¾¹(u, v)åˆ°æœ€å°ç”Ÿæˆæ ‘
        visited.add(v)
        mst.append((u, v, weight))
        total_weight += weight

        # å°†vçš„æœªè®¿é—®é‚»å±…æ·»åŠ åˆ°ä¼˜å…ˆé˜Ÿåˆ—
        for neighbor, w in graph.get(v, {}).items():
            if neighbor not in visited:
                heapq.heappush(edges, (w, v, neighbor))

    return mst, total_weight

def prim_any_start(graph):
    """
    Primç®—æ³•ï¼šæ‰¾å›¾çš„æœ€å°ç”Ÿæˆæ ‘ï¼ˆä»ä»»æ„é¡¶ç‚¹å¼€å§‹ï¼‰
    å¦‚æœå›¾ä¸è¿é€šï¼Œè¿”å›å„è¿é€šåˆ†é‡çš„æœ€å°ç”Ÿæˆæ ‘

    å‚æ•°:
        graph: åŠ æƒæ— å‘å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º

    è¿”å›:
        mst: æœ€å°ç”Ÿæˆæ ‘çš„è¾¹åˆ—è¡¨
        total_weight: æœ€å°ç”Ÿæˆæ ‘çš„æ€»æƒé‡
    """
    if not graph:
        return [], 0

    # é€‰æ‹©ä»»æ„é¡¶ç‚¹ä½œä¸ºèµ·å§‹ç‚¹
    start = next(iter(graph))
    return prim(graph, start)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹å›¾ï¼šåŸå¸‚ä¹‹é—´çš„é€šä¿¡ç½‘ç»œï¼ˆæƒé‡è¡¨ç¤ºå»ºè®¾æˆæœ¬ï¼‰
    network_graph = {
        'A': {'B': 4, 'C': 2},
        'B': {'A': 4, 'C': 1, 'D': 5},
        'C': {'A': 2, 'B': 1, 'D': 8, 'E': 10},
        'D': {'B': 5, 'C': 8, 'E': 2},
        'E': {'C': 10, 'D': 2}
    }

    # ä»Aå¼€å§‹æ„å»ºæœ€å°ç”Ÿæˆæ ‘
    mst_edges, total_cost = prim(network_graph, 'A')
    print("Primç®—æ³•ç»“æœ:")
    print("æœ€å°ç”Ÿæˆæ ‘è¾¹:", mst_edges)
    print("æ€»æˆæœ¬:", total_cost)
    # è¾“å‡º: æœ€å°ç”Ÿæˆæ ‘è¾¹: [('A', 'C', 2), ('C', 'B', 1), ('C', 'E', 10), ('E', 'D', 2)]
    # æ€»æˆæœ¬: 15

    # æ³¨æ„ï¼šPrimå’ŒKruskalå¯èƒ½å¾—åˆ°ä¸åŒçš„è¾¹é›†åˆï¼ˆå¦‚æœæœ‰å¤šæ¡ç›¸åŒæƒé‡çš„è¾¹ï¼‰ï¼Œ
    # ä½†æ€»æƒé‡åº”è¯¥ç›¸åŒï¼ˆå¦‚æœå›¾æ˜¯è¿é€šçš„ï¼‰
```

**å®šç† 3.3.3** (Primç®—æ³•æ­£ç¡®æ€§ / Prim Algorithm Correctness)
Primç®—æ³•èƒ½å¤Ÿæ­£ç¡®æ‰¾åˆ°å›¾çš„æœ€å°ç”Ÿæˆæ ‘ã€‚

**å½¢å¼åŒ–è¯æ˜ / Formal Proof**ï¼š

**æ­¥éª¤ 1**ï¼šå‰²æ€§è´¨ï¼ˆCut Propertyï¼‰
è®¾ $G = (V, E)$ æ˜¯ä¸€ä¸ªè¿é€šæ— å‘å›¾ï¼Œ$w: E \to \mathbb{R}^+$ æ˜¯æƒé‡å‡½æ•°ã€‚

**å¼•ç† 3.3.2**ï¼ˆå‰²æ€§è´¨ï¼‰ï¼šè®¾ $T^*$ æ˜¯ $G$ çš„æœ€å°ç”Ÿæˆæ ‘ï¼Œ$(S, V \setminus S)$ æ˜¯ $G$ çš„ä¸€ä¸ªå‰²ã€‚å¦‚æœ $e$ æ˜¯è·¨è¶Šè¯¥å‰²çš„æƒé‡æœ€å°çš„è¾¹ï¼Œåˆ™ $e \in T^*$ã€‚

**è¯æ˜å¼•ç† 3.3.2**ï¼ˆåè¯æ³•ï¼‰ï¼š
å‡è®¾ $e \notin T^*$ã€‚

å°† $e$ æ·»åŠ åˆ° $T^*$ ä¸­ä¼šå½¢æˆä¸€ä¸ªåœˆ $C$ã€‚

ç”±äº $e$ è·¨è¶Šå‰² $(S, V \setminus S)$ï¼Œåœˆ $C$ ä¸­å¿…æœ‰ä¸€æ¡è¾¹ $f \neq e$ ä¹Ÿè·¨è¶Šè¯¥å‰²ã€‚

ç”±äº $e$ æ˜¯è·¨è¶Šè¯¥å‰²çš„æƒé‡æœ€å°çš„è¾¹ï¼Œ$w(e) \leq w(f)$ã€‚

å°† $T^*$ ä¸­çš„è¾¹ $f$ æ›¿æ¢ä¸º $e$ï¼Œå¾—åˆ° $T' = T^* - \{f\} + \{e\}$ã€‚

ç”±äº $w(e) \leq w(f)$ï¼Œ$w(T') \leq w(T^*)$ï¼Œå› æ­¤ $T'$ ä¹Ÿæ˜¯æœ€å°ç”Ÿæˆæ ‘ã€‚

ä½† $T'$ åŒ…å« $e$ï¼Œä¸å‡è®¾çŸ›ç›¾ã€‚

å› æ­¤ï¼Œ$e \in T^*$ã€‚$\square$

**æ­¥éª¤ 2**ï¼šPrimç®—æ³•çš„å¾ªç¯ä¸å˜å¼
åœ¨ç®—æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œè®¾ $S$ æ˜¯å·²è®¿é—®çš„é¡¶ç‚¹é›†åˆï¼Œ$T$ æ˜¯å·²é€‰æ‹©çš„è¾¹é›†åˆã€‚

**å¾ªç¯ä¸å˜å¼**ï¼š$T$ æ˜¯æŸä¸ªåŒ…å« $S$ çš„æœ€å°ç”Ÿæˆæ ‘çš„å­é›†ã€‚

**æ­¥éª¤ 3**ï¼šåŸºç¡€æƒ…å†µï¼ˆInitializationï¼‰
åˆå§‹æ—¶ï¼Œ$S = \{s\}$ï¼ˆæŸä¸ªèµ·å§‹é¡¶ç‚¹ï¼‰ï¼Œ$T = \emptyset$ã€‚

æ˜¾ç„¶ï¼Œ$\emptyset$ æ˜¯æŸä¸ªåŒ…å« $\{s\}$ çš„æœ€å°ç”Ÿæˆæ ‘çš„å­é›†ï¼Œä¸å˜å¼æˆç«‹ã€‚

**æ­¥éª¤ 4**ï¼šä¿æŒï¼ˆMaintenanceï¼‰
å‡è®¾åœ¨æ·»åŠ è¾¹ $e = (u, v)$ ä¹‹å‰ï¼Œä¸å˜å¼æˆç«‹ï¼Œå…¶ä¸­ï¼š

- $u \in S$ï¼Œ$v \notin S$
- $e$ æ˜¯è¿æ¥ $S$ å’Œ $V \setminus S$ çš„æƒé‡æœ€å°çš„è¾¹

**éœ€è¦è¯æ˜**ï¼šæ·»åŠ  $e$ åï¼Œ$T \cup \{e\}$ æ˜¯æŸä¸ªåŒ…å« $S \cup \{v\}$ çš„æœ€å°ç”Ÿæˆæ ‘çš„å­é›†ã€‚

ç”±å¾ªç¯ä¸å˜å¼ï¼Œå­˜åœ¨æœ€å°ç”Ÿæˆæ ‘ $T^*$ åŒ…å« $T$ã€‚

è€ƒè™‘å‰² $(S, V \setminus S)$ã€‚

ç”±å¼•ç† 3.3.2ï¼ˆå‰²æ€§è´¨ï¼‰ï¼Œè·¨è¶Šè¯¥å‰²çš„æƒé‡æœ€å°çš„è¾¹ $e$ å±äºæŸä¸ªæœ€å°ç”Ÿæˆæ ‘ã€‚

ç”±äº $e$ æ˜¯è·¨è¶Šè¯¥å‰²çš„æƒé‡æœ€å°çš„è¾¹ï¼Œä¸” $T^*$ æ˜¯æœ€å°ç”Ÿæˆæ ‘ï¼Œå¦‚æœ $e \notin T^*$ï¼Œåˆ™å¯ä»¥å°† $T^*$ ä¸­è·¨è¶Šè¯¥å‰²çš„æŸæ¡è¾¹æ›¿æ¢ä¸º $e$ï¼Œå¾—åˆ°å¦ä¸€ä¸ªæœ€å°ç”Ÿæˆæ ‘ $T'$ åŒ…å« $e$ã€‚

å› æ­¤ï¼Œå­˜åœ¨æœ€å°ç”Ÿæˆæ ‘ $T'$ åŒ…å« $T \cup \{e\}$ã€‚

ç”±äº $T'$ åŒ…å« $S \cup \{v\}$ï¼ˆå› ä¸º $u \in S$ï¼Œ$v$ é€šè¿‡è¾¹ $e$ è¿æ¥åˆ° $S$ï¼‰ï¼Œ$T \cup \{e\}$ æ˜¯æŸä¸ªåŒ…å« $S \cup \{v\}$ çš„æœ€å°ç”Ÿæˆæ ‘çš„å­é›†ã€‚

å› æ­¤ï¼Œå¾ªç¯ä¸å˜å¼ä¿æŒã€‚$\square$

**æ­¥éª¤ 5**ï¼šç»ˆæ­¢ï¼ˆTerminationï¼‰
å½“ç®—æ³•ç»ˆæ­¢æ—¶ï¼Œ$S = V$ï¼ˆæ‰€æœ‰é¡¶ç‚¹éƒ½å·²è®¿é—®ï¼‰ï¼Œ$T$ åŒ…å« $|V| - 1$ æ¡è¾¹ã€‚

ç”±å¾ªç¯ä¸å˜å¼ï¼Œ$T$ æ˜¯æŸä¸ªæœ€å°ç”Ÿæˆæ ‘çš„å­é›†ã€‚

ç”±äºæœ€å°ç”Ÿæˆæ ‘æ°å¥½æœ‰ $|V| - 1$ æ¡è¾¹ï¼Œ$T$ æœ¬èº«å°±æ˜¯ä¸€ä¸ªæœ€å°ç”Ÿæˆæ ‘ã€‚

å› æ­¤ï¼ŒPrimç®—æ³•æ­£ç¡®ã€‚$\square$

**å®šç† 3.3.4** (Primç®—æ³•æ—¶é—´å¤æ‚åº¦ / Prim Algorithm Time Complexity)
Primç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|E| \log |V|)$ã€‚

**è¯æ˜**ï¼š

- æ¯ä¸ªé¡¶ç‚¹æœ€å¤šå…¥é˜Ÿä¸€æ¬¡ï¼š$O(|V|)$
- æ¯æ¡è¾¹æœ€å¤šè¢«æ£€æŸ¥ä¸€æ¬¡ï¼š$O(|E|)$
- æ¯æ¬¡å †æ“ä½œï¼š$O(\log |V|)$
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|E| \log |V|)$ $\square$

## 3.4 ç½‘ç»œæµç®—æ³•

### 3.4.1 Edmonds-Karpç®—æ³•

**å®šä¹‰ 3.4.1** Edmonds-Karpç®—æ³•æ˜¯Ford-Fulkersonç®—æ³•çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œä½¿ç”¨BFSå¯»æ‰¾æœ€çŸ­å¢å¹¿è·¯å¾„ï¼Œä¿è¯å¤šé¡¹å¼æ—¶é—´å¤æ‚åº¦ã€‚

**ç®—æ³• 3.4.1** Edmonds-Karpç®—æ³•ï¼ˆFord-Fulkersonçš„BFSä¼˜åŒ–ç‰ˆæœ¬ï¼‰

```python
from collections import deque

def edmonds_karp(graph, source, sink, return_flow_graph=False):
    """
    Edmonds-Karpç®—æ³•ï¼šä½¿ç”¨BFSå¯»æ‰¾æœ€çŸ­å¢å¹¿è·¯å¾„çš„æœ€å¤§æµç®—æ³•

    å‚æ•°:
        graph: å®¹é‡å›¾çš„é‚»æ¥çŸ©é˜µè¡¨ç¤ºï¼ˆäºŒç»´åˆ—è¡¨ï¼‰
               graph[u][v] è¡¨ç¤ºä»uåˆ°vçš„å®¹é‡
        source: æºç‚¹ç´¢å¼•
        sink: æ±‡ç‚¹ç´¢å¼•
        return_flow_graph: æ˜¯å¦è¿”å›æµé‡å›¾

    è¿”å›:
        max_flow: æœ€å¤§æµå€¼
        flow_graph: æµé‡å›¾ï¼ˆå¦‚æœreturn_flow_graph=Trueï¼‰
    """
    n = len(graph)

    # åˆ›å»ºæ®‹å·®å›¾ï¼ˆåˆå§‹æ—¶ç­‰äºå®¹é‡å›¾ï¼‰
    residual = [row[:] for row in graph]
    flow_graph = [[0] * n for _ in range(n)]

    def bfs(residual, source, sink, parent):
        """ä½¿ç”¨BFSæŸ¥æ‰¾å¢å¹¿è·¯å¾„"""
        visited = [False] * n
        queue = deque([source])
        visited[source] = True

        while queue:
            u = queue.popleft()
            for v in range(n):
                if not visited[v] and residual[u][v] > 0:
                    visited[v] = True
                    parent[v] = u
                    queue.append(v)
                    if v == sink:
                        return True
        return False

    max_flow = 0
    parent = [-1] * n

    # ä¸æ–­å¯»æ‰¾å¢å¹¿è·¯å¾„å¹¶æ›´æ–°æµ
    while bfs(residual, source, sink, parent):
        # æ‰¾åˆ°å¢å¹¿è·¯å¾„ä¸Šçš„æœ€å°å®¹é‡
        path_flow = float('inf')
        v = sink
        path = []

        while v != source:
            u = parent[v]
            path_flow = min(path_flow, residual[u][v])
            path.append((u, v))
            v = u

        # æ›´æ–°æ®‹å·®å›¾å’Œæµé‡å›¾
        v = sink
        while v != source:
            u = parent[v]
            residual[u][v] -= path_flow  # å‡å°‘æ­£å‘è¾¹å®¹é‡
            residual[v][u] += path_flow  # å¢åŠ åå‘è¾¹å®¹é‡
            flow_graph[u][v] += path_flow  # è®°å½•æµé‡
            v = u

        max_flow += path_flow

    if return_flow_graph:
        return max_flow, flow_graph
    return max_flow

def edmonds_karp_dict(graph_dict, source, sink):
    """
    Edmonds-Karpç®—æ³•ï¼ˆå­—å…¸æ ¼å¼ï¼‰ï¼šæ”¯æŒå­—å…¸æ ¼å¼çš„å›¾è¡¨ç¤º

    å‚æ•°:
        graph_dict: å®¹é‡å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {u: {v: capacity}}
        source: æºç‚¹
        sink: æ±‡ç‚¹

    è¿”å›:
        max_flow: æœ€å¤§æµå€¼
    """
    # è·å–æ‰€æœ‰é¡¶ç‚¹
    vertices = set()
    for u in graph_dict:
        vertices.add(u)
        for v in graph_dict[u]:
            vertices.add(v)
    vertices = sorted(list(vertices))
    vertex_to_index = {v: i for i, v in enumerate(vertices)}

    # è½¬æ¢ä¸ºçŸ©é˜µæ ¼å¼
    n = len(vertices)
    graph_matrix = [[0] * n for _ in range(n)]

    for u in graph_dict:
        u_idx = vertex_to_index[u]
        for v, capacity in graph_dict[u].items():
            v_idx = vertex_to_index[v]
            graph_matrix[u_idx][v_idx] = capacity

    source_idx = vertex_to_index[source]
    sink_idx = vertex_to_index[sink]

    return edmonds_karp(graph_matrix, source_idx, sink_idx)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šç½‘ç»œæµé—®é¢˜ï¼ˆçŸ©é˜µæ ¼å¼ï¼‰
    # å›¾ï¼š0 -> 1 (16), 0 -> 2 (13), 1 -> 2 (10), 1 -> 3 (12),
    #     2 -> 1 (4), 2 -> 4 (14), 3 -> 2 (9), 3 -> 5 (20),
    #     4 -> 3 (7), 4 -> 5 (4)
    # æºç‚¹ï¼š0ï¼Œæ±‡ç‚¹ï¼š5
    capacity_graph = [
        [0, 16, 13, 0, 0, 0],   # 0
        [0, 0, 10, 12, 0, 0],   # 1
        [0, 4, 0, 0, 14, 0],    # 2
        [0, 0, 9, 0, 0, 20],    # 3
        [0, 0, 0, 7, 0, 4],     # 4
        [0, 0, 0, 0, 0, 0]      # 5
    ]

    max_flow, flow_graph = edmonds_karp(capacity_graph, 0, 5, return_flow_graph=True)
    print(f"æœ€å¤§æµå€¼: {max_flow}")
    print("æµé‡å›¾:")
    for i, row in enumerate(flow_graph):
        for j, flow in enumerate(row):
            if flow > 0:
                print(f"  {i} -> {j}: {flow}")

    # å­—å…¸æ ¼å¼ç¤ºä¾‹
    graph_dict = {
        0: {1: 16, 2: 13},
        1: {2: 10, 3: 12},
        2: {1: 4, 4: 14},
        3: {2: 9, 5: 20},
        4: {3: 7, 5: 4}
    }
    max_flow_dict = edmonds_karp_dict(graph_dict, 0, 5)
    print(f"å­—å…¸æ ¼å¼æœ€å¤§æµå€¼: {max_flow_dict}")
```

**å®šç† 3.4.1** (Edmonds-Karpç®—æ³•æ—¶é—´å¤æ‚åº¦ / Edmonds-Karp Algorithm Time Complexity)
Edmonds-Karpç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| \cdot |E|^2)$ã€‚

**è¯æ˜**ï¼š

- æ¯æ¬¡BFSæ‰¾å¢å¹¿è·¯å¾„ï¼š$O(|E|)$
- æœ€å¤šéœ€è¦ $O(|V| \cdot |E|)$ æ¬¡å¢å¹¿ï¼ˆæ¯æ¡è¾¹æœ€å¤šè¢«ä½¿ç”¨ $|V|$ æ¬¡ä½œä¸ºç“¶é¢ˆè¾¹ï¼‰
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|V| \cdot |E|^2)$ $\square$

### 3.4.2 Dinicç®—æ³•

**å®šä¹‰ 3.4.2** Dinicç®—æ³•ä½¿ç”¨åˆ†å±‚å›¾å’Œé˜»å¡æµæ¥åŠ é€Ÿæœ€å¤§æµè®¡ç®—ï¼Œæ˜¯Edmonds-Karpç®—æ³•çš„è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

**ç®—æ³• 3.4.2** Dinicç®—æ³•

```python
from collections import deque

def dinic(graph, source, sink, return_flow_graph=False):
    """
    Dinicç®—æ³•ï¼šä½¿ç”¨åˆ†å±‚å›¾å’Œé˜»å¡æµè®¡ç®—æœ€å¤§æµ

    å‚æ•°:
        graph: å®¹é‡å›¾çš„é‚»æ¥çŸ©é˜µè¡¨ç¤ºï¼ˆäºŒç»´åˆ—è¡¨ï¼‰
               graph[u][v] è¡¨ç¤ºä»uåˆ°vçš„å®¹é‡
        source: æºç‚¹ç´¢å¼•
        sink: æ±‡ç‚¹ç´¢å¼•
        return_flow_graph: æ˜¯å¦è¿”å›æµé‡å›¾

    è¿”å›:
        max_flow: æœ€å¤§æµå€¼
        flow_graph: æµé‡å›¾ï¼ˆå¦‚æœreturn_flow_graph=Trueï¼‰
    """
    n = len(graph)

    # åˆ›å»ºæ®‹å·®å›¾å’Œæµé‡å›¾
    residual = [row[:] for row in graph]
    flow_graph = [[0] * n for _ in range(n)]
    level = [-1] * n

    def build_level_graph():
        """æ„å»ºåˆ†å±‚å›¾ï¼ˆlevel graphï¼‰"""
        # é‡ç½®å±‚çº§
        for i in range(n):
            level[i] = -1

        queue = deque([source])
        level[source] = 0

        while queue:
            u = queue.popleft()
            for v in range(n):
                if level[v] == -1 and residual[u][v] > 0:
                    level[v] = level[u] + 1
                    queue.append(v)
                    if v == sink:
                        return True
        return level[sink] != -1

    def find_blocking_flow(u, flow_limit, current_edge):
        """
        åœ¨åˆ†å±‚å›¾ä¸­ä½¿ç”¨DFSå¯»æ‰¾é˜»å¡æµ

        å‚æ•°:
            u: å½“å‰é¡¶ç‚¹
            flow_limit: æµçš„ä¸Šé™
            current_edge: å½“å‰å¼§æ•°ç»„ï¼ˆç”¨äºä¼˜åŒ–ï¼‰

        è¿”å›:
            å®é™…å¢åŠ çš„æµå€¼
        """
        if u == sink:
            return flow_limit

        total_flow = 0
        # ä»å½“å‰å¼§ä½ç½®ç»§ç»­æœç´¢
        for i in range(current_edge[u], n):
            v = i
            # æ£€æŸ¥æ˜¯å¦åœ¨ä¸‹ä¸€å±‚ä¸”æœ‰æ®‹å·®å®¹é‡
            if level[v] == level[u] + 1 and residual[u][v] > 0:
                pushed = find_blocking_flow(
                    v, min(flow_limit - total_flow, residual[u][v]), current_edge)
                if pushed > 0:
                    residual[u][v] -= pushed
                    residual[v][u] += pushed
                    flow_graph[u][v] += pushed
                    total_flow += pushed
                    if total_flow >= flow_limit:
                        break
            current_edge[u] = i + 1

        return total_flow

    max_flow = 0
    # ä¸æ–­æ„å»ºåˆ†å±‚å›¾å¹¶å¯»æ‰¾é˜»å¡æµ
    while build_level_graph():
        current_edge = [0] * n
        while True:
            blocking_flow = find_blocking_flow(source, float('inf'), current_edge)
            if blocking_flow == 0:
                break
            max_flow += blocking_flow

    if return_flow_graph:
        return max_flow, flow_graph
    return max_flow

def dinic_dict(graph_dict, source, sink):
    """
    Dinicç®—æ³•ï¼ˆå­—å…¸æ ¼å¼ï¼‰ï¼šæ”¯æŒå­—å…¸æ ¼å¼çš„å›¾è¡¨ç¤º

    å‚æ•°:
        graph_dict: å®¹é‡å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {u: {v: capacity}}
        source: æºç‚¹
        sink: æ±‡ç‚¹

    è¿”å›:
        max_flow: æœ€å¤§æµå€¼
    """
    # è·å–æ‰€æœ‰é¡¶ç‚¹
    vertices = set()
    for u in graph_dict:
        vertices.add(u)
        for v in graph_dict[u]:
            vertices.add(v)
    vertices = sorted(list(vertices))
    vertex_to_index = {v: i for i, v in enumerate(vertices)}

    # è½¬æ¢ä¸ºçŸ©é˜µæ ¼å¼
    n = len(vertices)
    graph_matrix = [[0] * n for _ in range(n)]

    for u in graph_dict:
        u_idx = vertex_to_index[u]
        for v, capacity in graph_dict[u].items():
            v_idx = vertex_to_index[v]
            graph_matrix[u_idx][v_idx] = capacity

    source_idx = vertex_to_index[source]
    sink_idx = vertex_to_index[sink]

    return dinic(graph_matrix, source_idx, sink_idx)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šç½‘ç»œæµé—®é¢˜ï¼ˆçŸ©é˜µæ ¼å¼ï¼‰
    capacity_graph = [
        [0, 16, 13, 0, 0, 0],   # 0
        [0, 0, 10, 12, 0, 0],   # 1
        [0, 4, 0, 0, 14, 0],    # 2
        [0, 0, 9, 0, 0, 20],    # 3
        [0, 0, 0, 7, 0, 4],     # 4
        [0, 0, 0, 0, 0, 0]      # 5
    ]

    max_flow, flow_graph = dinic(capacity_graph, 0, 5, return_flow_graph=True)
    print(f"Dinicç®—æ³•æœ€å¤§æµå€¼: {max_flow}")
    print("æµé‡å›¾:")
    for i, row in enumerate(flow_graph):
        for j, flow in enumerate(row):
            if flow > 0:
                print(f"  {i} -> {j}: {flow}")

    # å­—å…¸æ ¼å¼ç¤ºä¾‹
    graph_dict = {
        0: {1: 16, 2: 13},
        1: {2: 10, 3: 12},
        2: {1: 4, 4: 14},
        3: {2: 9, 5: 20},
        4: {3: 7, 5: 4}
    }
    max_flow_dict = dinic_dict(graph_dict, 0, 5)
    print(f"Dinicç®—æ³•å­—å…¸æ ¼å¼æœ€å¤§æµå€¼: {max_flow_dict}")
```

**å®šç† 3.4.2** (Dinicç®—æ³•æ—¶é—´å¤æ‚åº¦ / Dinic Algorithm Time Complexity)
Dinicç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V|^2 \cdot |E|)$ã€‚

**è¯æ˜**ï¼š

- æ„å»ºåˆ†å±‚å›¾ï¼šæ¯æ¬¡BFS $O(|E|)$
- æœ€å¤šéœ€è¦ $O(|V|)$ æ¬¡åˆ†å±‚å›¾æ„å»ºï¼ˆæ¯æ¬¡åˆ†å±‚å›¾è‡³å°‘å¢åŠ ä¸€å±‚ï¼‰
- æ¯æ¬¡åˆ†å±‚å›¾ä¸­å¯»æ‰¾é˜»å¡æµï¼š$O(|V| \cdot |E|)$ï¼ˆä½¿ç”¨DFSï¼Œæ¯æ¡è¾¹æœ€å¤šè®¿é—®ä¸€æ¬¡ï¼‰
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|V|^2 \cdot |E|)$ $\square$

### 3.4.3 ç½‘ç»œæµç®—æ³•å¯¹æ¯”

| ç®—æ³• | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|-----------|-----------|------|---------|
| Edmonds-Karp | $O(\|V\| \cdot \|E\|^2)$ | $O(\|V\| + \|E\|)$ | BFSæ‰¾æœ€çŸ­å¢å¹¿è·¯å¾„ | ä¸­ç­‰è§„æ¨¡ç½‘ç»œæµ |
| Dinic | $O(\|V\|^2 \cdot \|E\|)$ | $O(\|V\| + \|E\|)$ | åˆ†å±‚å›¾+é˜»å¡æµ | å¤§è§„æ¨¡ç½‘ç»œæµ |

### 3.4.4 å®é™…åº”ç”¨æ¡ˆä¾‹

1. **ç½‘ç»œæµé‡åˆ†é…**ï¼š
   - äº’è”ç½‘æµé‡è·¯ç”±
   - æ•°æ®ä¸­å¿ƒå¸¦å®½åˆ†é…
   - CDNå†…å®¹åˆ†å‘

2. **èµ„æºåˆ†é…**ï¼š
   - ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ
   - äººå‘˜åˆ†é…é—®é¢˜
   - è®¾å¤‡èµ„æºåˆ†é…

3. **åŒ¹é…é—®é¢˜**ï¼š
   - äºŒåˆ†å›¾æœ€å¤§åŒ¹é…ï¼ˆå¯è½¬åŒ–ä¸ºç½‘ç»œæµï¼‰
   - ç¨³å®šå©šå§»é—®é¢˜
   - ä»»åŠ¡åˆ†é…é—®é¢˜

### 3.4.5 æœ€å¤§æµæœ€å°å‰²å®šç†

**å®šç† 3.4.3** (æœ€å¤§æµæœ€å°å‰²å®šç† / Max-Flow Min-Cut Theorem)
æµç½‘ç»œ $N = (G, s, t, c)$ ä¸­çš„æœ€å¤§æµå€¼ç­‰äºæœ€å°å‰²å®¹é‡ã€‚

**å½¢å¼åŒ–è¡¨è¿°**ï¼š
$$\max_{f \text{ is a flow}} |f| = \min_{S \text{ is an } s\text{-}t \text{ cut}} c(S)$$

**å®Œæ•´è¯æ˜ / Complete Proof**ï¼š

**æ­¥éª¤ 1**ï¼šå¼±å¯¹å¶æ€§ï¼ˆWeak Dualityï¼‰
å¯¹äºä»»æ„æµ $f$ å’Œä»»æ„ $s$-$t$ å‰² $S$ï¼Œæœ‰ $|f| \leq c(S)$ã€‚

**è¯æ˜**ï¼š
æµå€¼å®šä¹‰ä¸ºï¼š
$$|f| = \sum_{e \in \delta^+(s)} f(e) - \sum_{e \in \delta^-(s)} f(e)$$

ç”±æµé‡å®ˆæ’æ€§è´¨ï¼Œå¯¹äºä»»æ„ $s$-$t$ å‰² $S$ï¼ˆ$s \in S$ï¼Œ$t \notin S$ï¼‰ï¼š
$$|f| = \sum_{v \in S} \left(\sum_{e \in \delta^+(v)} f(e) - \sum_{e \in \delta^-(v)} f(e)\right)$$

ç”±äº $s \in S$ ä¸” $t \notin S$ï¼Œä¸Šå¼å¯ä»¥é‡å†™ä¸ºï¼š
$$|f| = \sum_{e \in \delta^+(S)} f(e) - \sum_{e \in \delta^-(S)} f(e)$$

å…¶ä¸­ï¼š

- $\delta^+(S) = \{(u, v) \in E : u \in S, v \notin S\}$ï¼ˆä» $S$ åˆ° $V \setminus S$ çš„è¾¹ï¼‰
- $\delta^-(S) = \{(u, v) \in E : u \notin S, v \in S\}$ï¼ˆä» $V \setminus S$ åˆ° $S$ çš„è¾¹ï¼‰

ç”±äº $f(e) \geq 0$ ä¸” $f(e) \leq c(e)$ï¼š
$$|f| = \sum_{e \in \delta^+(S)} f(e) - \sum_{e \in \delta^-(S)} f(e) \leq \sum_{e \in \delta^+(S)} f(e) \leq \sum_{e \in \delta^+(S)} c(e) = c(S)$$

å› æ­¤ï¼Œ$|f| \leq c(S)$ å¯¹æ‰€æœ‰æµ $f$ å’Œæ‰€æœ‰ $s$-$t$ å‰² $S$ æˆç«‹ã€‚$\square$

**æ­¥éª¤ 2**ï¼šFord-Fulkersonç®—æ³•çš„ç»ˆæ­¢æ€§
Edmonds-Karpç®—æ³•ï¼ˆFord-Fulkersonçš„BFSç‰ˆæœ¬ï¼‰åœ¨æœ‰é™æ­¥å†…ç»ˆæ­¢ã€‚

**è¯æ˜**ï¼š

- æ¯æ¬¡BFSæ‰¾å¢å¹¿è·¯å¾„ï¼š$O(|E|)$
- æ¯æ¬¡å¢å¹¿è‡³å°‘å¢åŠ æµå€¼ï¼ˆå‡è®¾å®¹é‡ä¸ºæ•´æ•°æˆ–æœ‰ç†æ•°ï¼‰
- æµå€¼æœ‰ä¸Šç•Œï¼ˆæœ€å°å‰²å®¹é‡ï¼‰
- æœ€å¤šéœ€è¦ $O(|V| \cdot |E|)$ æ¬¡å¢å¹¿ï¼ˆEdmonds-Karpçš„å¤æ‚åº¦ä¿è¯ï¼‰
- å› æ­¤ç®—æ³•åœ¨æœ‰é™æ­¥å†…ç»ˆæ­¢ã€‚$\square$

**æ­¥éª¤ 3**ï¼šæœ€å¤§æµå¯¹åº”æœ€å°å‰²
å½“Edmonds-Karpç®—æ³•ç»ˆæ­¢æ—¶ï¼Œå­˜åœ¨ $s$-$t$ å‰² $S$ ä½¿å¾— $|f| = c(S)$ã€‚

**è¯æ˜**ï¼š
ç®—æ³•ç»ˆæ­¢æ—¶ï¼Œåœ¨æ®‹å·®ç½‘ç»œ $G_f$ ä¸­ä¸å­˜åœ¨ä» $s$ åˆ° $t$ çš„è·¯å¾„ã€‚

å®šä¹‰ $S = \{v \in V : \text{åœ¨æ®‹å·®ç½‘ç»œ } G_f \text{ ä¸­ä» } s \text{ å¯è¾¾ } v\}$ã€‚

æ˜¾ç„¶ï¼Œ$s \in S$ï¼ˆ$s$ å¯è¾¾è‡ªèº«ï¼‰ä¸” $t \notin S$ï¼ˆå¦åˆ™å­˜åœ¨ä» $s$ åˆ° $t$ çš„è·¯å¾„ï¼ŒçŸ›ç›¾ï¼‰ã€‚

å› æ­¤ï¼Œ$S$ æ˜¯ä¸€ä¸ª $s$-$t$ å‰²ã€‚

**å…³é”®è§‚å¯Ÿ**ï¼šå¯¹äºä»»æ„è¾¹ $(u, v)$ï¼Œå…¶ä¸­ $u \in S$ ä¸” $v \notin S$ï¼š

- **æƒ…å†µ1**ï¼šå¦‚æœ $(u, v) \in E$ï¼ˆåŸå›¾ä¸­çš„è¾¹ï¼‰
  - ç”±äº $v \notin S$ï¼Œåœ¨æ®‹å·®ç½‘ç»œ $G_f$ ä¸­ä» $s$ ä¸å¯è¾¾ $v$
  - è¿™æ„å‘³ç€æ®‹å·®å®¹é‡ $c_f(u, v) = c(u, v) - f(u, v) = 0$
  - å› æ­¤ï¼Œ$f(u, v) = c(u, v)$ï¼ˆè¾¹é¥±å’Œï¼‰

- **æƒ…å†µ2**ï¼šå¦‚æœ $(v, u) \in E$ï¼ˆåå‘è¾¹ï¼‰
  - ç”±äº $u \in S$ ä¸” $v \notin S$ï¼Œåœ¨æ®‹å·®ç½‘ç»œ $G_f$ ä¸­ä» $s$ ä¸å¯è¾¾ $v$
  - è¿™æ„å‘³ç€æ®‹å·®å®¹é‡ $c_f(v, u) = f(u, v) = 0$
  - å› æ­¤ï¼Œ$f(u, v) = 0$ï¼ˆåå‘è¾¹æ— æµï¼‰

**è®¡ç®—å‰²çš„å®¹é‡**ï¼š
$$c(S) = \sum_{e \in \delta^+(S)} c(e) = \sum_{(u,v) \in \delta^+(S)} c(u, v)$$

**è®¡ç®—æµçš„æµå€¼**ï¼ˆé€šè¿‡å‰² $S$ï¼‰ï¼š
$$|f| = \sum_{e \in \delta^+(S)} f(e) - \sum_{e \in \delta^-(S)} f(e)$$

ç”±å…³é”®è§‚å¯Ÿï¼š

- å¯¹äº $(u, v) \in \delta^+(S)$ï¼š$f(u, v) = c(u, v)$
- å¯¹äº $(v, u) \in \delta^-(S)$ï¼š$f(u, v) = 0$

å› æ­¤ï¼š
$$|f| = \sum_{(u,v) \in \delta^+(S)} f(u, v) - \sum_{(v,u) \in \delta^-(S)} f(u, v) = \sum_{(u,v) \in \delta^+(S)} c(u, v) = c(S)$$

å› æ­¤ï¼Œ$|f| = c(S)$ã€‚$\square$

**æ­¥éª¤ 4**ï¼šç»“è®º
ç”±æ­¥éª¤1ï¼ˆå¼±å¯¹å¶æ€§ï¼‰ï¼Œå¯¹äºä»»æ„æµ $f$ å’Œä»»æ„å‰² $S$ï¼Œæœ‰ $|f| \leq c(S)$ã€‚

ç”±æ­¥éª¤3ï¼Œç®—æ³•ç»ˆæ­¢æ—¶æ‰¾åˆ°çš„æµ $f^*$ å’Œå‰² $S^*$ æ»¡è¶³ $|f^*| = c(S^*)$ã€‚

å› æ­¤ï¼š

- $f^*$ æ˜¯æœ€å¤§æµï¼ˆå› ä¸ºå¯¹äºä»»æ„æµ $f$ï¼Œ$|f| \leq c(S^*) = |f^*|$ï¼‰
- $S^*$ æ˜¯æœ€å°å‰²ï¼ˆå› ä¸ºå¯¹äºä»»æ„å‰² $S$ï¼Œ$c(S^*) = |f^*| \leq c(S)$ï¼‰

å› æ­¤ï¼Œæœ€å¤§æµå€¼ç­‰äºæœ€å°å‰²å®¹é‡ï¼š
$$\max_{f \text{ is a flow}} |f| = \min_{S \text{ is an } s\text{-}t \text{ cut}} c(S)$$

$\square$

**æƒå¨æ¥æºå¼•ç”¨**ï¼š

- **Wikipedia**: [Edmondsâ€“Karp algorithm](https://en.wikipedia.org/wiki/Edmonds%E2%80%93Karp_algorithm)
- **Wikipedia**: [Dinic's algorithm](https://en.wikipedia.org/wiki/Dinic%27s_algorithm)
- **Wikipedia**: [Max-flow min-cut theorem](https://en.wikipedia.org/wiki/Max-flow_min-cut_theorem)
- **CLRS 4th Edition**: Chapter 26.2 - The Ford-Fulkerson method, 26.3 - Maximum bipartite matching
- **MIT 6.006**: Lecture 20 - Network flow

## 3.5 å›¾ç€è‰²ç®—æ³•

### 3.5.1 è´ªå¿ƒç€è‰²ç®—æ³•

**å®šä¹‰ 3.5.1** å›¾ç€è‰²é—®é¢˜æ˜¯ç»™å›¾çš„é¡¶ç‚¹åˆ†é…é¢œè‰²ï¼Œä½¿å¾—ç›¸é‚»é¡¶ç‚¹å…·æœ‰ä¸åŒé¢œè‰²ã€‚

**ç®—æ³• 3.5.1** è´ªå¿ƒç€è‰²ç®—æ³•

```python
def greedy_coloring(graph, vertex_order=None):
    """
    è´ªå¿ƒç€è‰²ç®—æ³•ï¼šä¸ºå›¾çš„é¡¶ç‚¹åˆ†é…é¢œè‰²ï¼Œä½¿å¾—ç›¸é‚»é¡¶ç‚¹é¢œè‰²ä¸åŒ

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: [neighbors]}
        vertex_order: é¡¶ç‚¹ç€è‰²é¡ºåºï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å›¾çš„é¡¶ç‚¹é¡ºåº

    è¿”å›:
        colors: æ¯ä¸ªé¡¶ç‚¹å¯¹åº”çš„é¢œè‰²å­—å…¸ {vertex: color}
        num_colors: ä½¿ç”¨çš„é¢œè‰²æ•°é‡
    """
    colors = {}
    available = set()

    # ç¡®å®šé¡¶ç‚¹ç€è‰²é¡ºåº
    if vertex_order is None:
        vertex_order = list(graph.keys())

    for vertex in vertex_order:
        # æ£€æŸ¥ç›¸é‚»é¡¶ç‚¹çš„é¢œè‰²
        for neighbor in graph.get(vertex, []):
            if neighbor in colors:
                available.add(colors[neighbor])

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨é¢œè‰²ï¼ˆæœ€å°é¢œè‰²ç¼–å·ï¼‰
        color = 0
        while color in available:
            color += 1

        colors[vertex] = color
        available.clear()

    num_colors = max(colors.values()) + 1 if colors else 0
    return colors, num_colors

def greedy_coloring_degree_order(graph):
    """
    è´ªå¿ƒç€è‰²ç®—æ³•ï¼ˆæŒ‰åº¦æ•°é™åºï¼‰ï¼šæŒ‰åº¦æ•°ä»å¤§åˆ°å°ç€è‰²ï¼Œé€šå¸¸æ•ˆæœæ›´å¥½

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º

    è¿”å›:
        colors: æ¯ä¸ªé¡¶ç‚¹å¯¹åº”çš„é¢œè‰²å­—å…¸
        num_colors: ä½¿ç”¨çš„é¢œè‰²æ•°é‡
    """
    # æŒ‰åº¦æ•°é™åºæ’åˆ—é¡¶ç‚¹
    vertex_degrees = [(v, len(graph.get(v, []))) for v in graph]
    vertex_degrees.sort(key=lambda x: x[1], reverse=True)
    vertex_order = [v for v, _ in vertex_degrees]

    return greedy_coloring(graph, vertex_order)

def is_valid_coloring(graph, colors):
    """
    éªŒè¯ç€è‰²æ˜¯å¦æœ‰æ•ˆï¼šæ£€æŸ¥ç›¸é‚»é¡¶ç‚¹æ˜¯å¦æœ‰ç›¸åŒé¢œè‰²

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        colors: é¢œè‰²å­—å…¸

    è¿”å›:
        is_valid: ç€è‰²æ˜¯å¦æœ‰æ•ˆ
        conflicts: å†²çªçš„è¾¹åˆ—è¡¨
    """
    conflicts = []
    for vertex in graph:
        vertex_color = colors.get(vertex)
        for neighbor in graph.get(vertex, []):
            neighbor_color = colors.get(neighbor)
            if vertex_color == neighbor_color:
                conflicts.append((vertex, neighbor))

    return len(conflicts) == 0, conflicts

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹å›¾ï¼šè¯¾ç¨‹å†²çªæ£€æµ‹ï¼ˆç›¸é‚»é¡¶ç‚¹è¡¨ç¤ºå†²çªçš„è¯¾ç¨‹ï¼‰
    course_graph = {
        'Math': ['Physics', 'Chemistry'],
        'Physics': ['Math', 'Chemistry'],
        'Chemistry': ['Math', 'Physics', 'Biology'],
        'Biology': ['Chemistry'],
        'History': ['Geography'],
        'Geography': ['History']
    }

    # åŸºç¡€è´ªå¿ƒç€è‰²
    colors, num_colors = greedy_coloring(course_graph)
    print("åŸºç¡€è´ªå¿ƒç€è‰²ç»“æœ:")
    print(f"  ä½¿ç”¨çš„é¢œè‰²æ•°: {num_colors}")
    print(f"  ç€è‰²æ–¹æ¡ˆ: {colors}")

    # éªŒè¯ç€è‰²æœ‰æ•ˆæ€§
    is_valid, conflicts = is_valid_coloring(course_graph, colors)
    print(f"  ç€è‰²æœ‰æ•ˆæ€§: {is_valid}")
    if conflicts:
        print(f"  å†²çª: {conflicts}")

    # æŒ‰åº¦æ•°æ’åºçš„è´ªå¿ƒç€è‰²ï¼ˆé€šå¸¸æ•ˆæœæ›´å¥½ï¼‰
    colors_degree, num_colors_degree = greedy_coloring_degree_order(course_graph)
    print("\næŒ‰åº¦æ•°æ’åºçš„è´ªå¿ƒç€è‰²ç»“æœ:")
    print(f"  ä½¿ç”¨çš„é¢œè‰²æ•°: {num_colors_degree}")
    print(f"  ç€è‰²æ–¹æ¡ˆ: {colors_degree}")

    # åº”ç”¨ï¼šè¯¾ç¨‹æ—¶é—´è¡¨å®‰æ’
    color_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']
    print("\nè¯¾ç¨‹æ—¶é—´è¡¨å®‰æ’:")
    for course, color in colors.items():
        if color < len(color_names):
            print(f"  {course}: {color_names[color]}")
```

**å®šç† 3.5.1** è´ªå¿ƒç€è‰²ç®—æ³•æœ€å¤šä½¿ç”¨ $\Delta(G) + 1$ ç§é¢œè‰²ï¼Œå…¶ä¸­ $\Delta(G)$ æ˜¯å›¾çš„æœ€å¤§åº¦æ•°ã€‚

**è¯æ˜** å¯¹äºæ¯ä¸ªé¡¶ç‚¹ï¼Œæœ€å¤šæœ‰ $\Delta(G)$ ä¸ªç›¸é‚»é¡¶ç‚¹ï¼Œå› æ­¤æœ€å¤šéœ€è¦ $\Delta(G) + 1$ ç§é¢œè‰²ã€‚

## 3.6 å¼ºè¿é€šåˆ†é‡ç®—æ³•

### 3.6.1 Tarjanç®—æ³•

**å®šä¹‰ 3.6.1** å¼ºè¿é€šåˆ†é‡æ˜¯æœ‰å‘å›¾ä¸­çš„ä¸€ä¸ªå­å›¾ï¼Œå…¶ä¸­ä»»æ„ä¸¤ä¸ªé¡¶ç‚¹éƒ½ç›¸äº’å¯è¾¾ã€‚

**ç®—æ³• 3.6.1** Tarjanç®—æ³•

```python
def tarjan(graph):
    """
    Tarjanç®—æ³•ï¼šæŸ¥æ‰¾æœ‰å‘å›¾ä¸­çš„æ‰€æœ‰å¼ºè¿é€šåˆ†é‡

    å‚æ•°:
        graph: æœ‰å‘å›¾çš„é‚»æ¥è¡¨è¡¨ç¤ºï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰
               graph[v] æ˜¯é¡¶ç‚¹vçš„é‚»å±…åˆ—è¡¨

    è¿”å›:
        sccs: å¼ºè¿é€šåˆ†é‡åˆ—è¡¨ï¼Œæ¯ä¸ªåˆ†é‡æ˜¯ä¸€ä¸ªé¡¶ç‚¹ç´¢å¼•åˆ—è¡¨
    """
    def dfs(v):
        nonlocal index
        indices[v] = index
        low_links[v] = index
        index += 1
        stack.append(v)
        on_stack[v] = True

        for neighbor in graph[v]:
            if indices[neighbor] == -1:
                dfs(neighbor)
                low_links[v] = min(low_links[v], low_links[neighbor])
            elif on_stack[neighbor]:
                low_links[v] = min(low_links[v], indices[neighbor])

        if low_links[v] == indices[v]:
            scc = []
            while True:
                w = stack.pop()
                on_stack[w] = False
                scc.append(w)
                if w == v:
                    break
            sccs.append(scc)

    n = len(graph)
    indices = [-1] * n
    low_links = [-1] * n
    on_stack = [False] * n
    stack = []
    sccs = []
    index = 0

    for v in range(n):
        if indices[v] == -1:
            dfs(v)

    return sccs

def tarjan_dict(graph_dict, vertex_list=None):
    """
    Tarjanç®—æ³•ï¼ˆå­—å…¸æ ¼å¼ï¼‰ï¼šæ”¯æŒå­—å…¸æ ¼å¼çš„å›¾è¡¨ç¤º

    å‚æ•°:
        graph_dict: æœ‰å‘å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: [neighbors]}
        vertex_list: é¡¶ç‚¹åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨graph_dictçš„é”®

    è¿”å›:
        sccs: å¼ºè¿é€šåˆ†é‡åˆ—è¡¨ï¼Œæ¯ä¸ªåˆ†é‡æ˜¯ä¸€ä¸ªé¡¶ç‚¹åˆ—è¡¨
        vertex_to_index: é¡¶ç‚¹åˆ°ç´¢å¼•çš„æ˜ å°„
    """
    if vertex_list is None:
        vertex_list = sorted(list(set(
            list(graph_dict.keys()) +
            [v for neighbors in graph_dict.values() for v in neighbors]
        )))

    vertex_to_index = {v: i for i, v in enumerate(vertex_list)}
    index_to_vertex = {i: v for v, i in vertex_to_index.items()}
    n = len(vertex_list)

    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
    graph_list = [[] for _ in range(n)]
    for u, neighbors in graph_dict.items():
        u_idx = vertex_to_index[u]
        for v in neighbors:
            if v in vertex_to_index:
                v_idx = vertex_to_index[v]
                graph_list[u_idx].append(v_idx)

    # è¿è¡ŒTarjanç®—æ³•
    sccs_indices = tarjan(graph_list)

    # è½¬æ¢å›é¡¶ç‚¹æ ¼å¼
    sccs = [[index_to_vertex[i] for i in scc] for scc in sccs_indices]

    return sccs, vertex_to_index

def build_scc_graph(graph_dict, sccs, vertex_to_index):
    """
    æ„å»ºå¼ºè¿é€šåˆ†é‡çš„ç¼©ç‚¹å›¾ï¼ˆDAGï¼‰

    å‚æ•°:
        graph_dict: åŸå§‹å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        sccs: å¼ºè¿é€šåˆ†é‡åˆ—è¡¨
        vertex_to_index: é¡¶ç‚¹åˆ°ç´¢å¼•çš„æ˜ å°„

    è¿”å›:
        scc_graph: ç¼©ç‚¹å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {scc_id: [neighbor_scc_ids]}
        scc_to_vertices: SCC IDåˆ°é¡¶ç‚¹åˆ—è¡¨çš„æ˜ å°„
    """
    # ä¸ºæ¯ä¸ªé¡¶ç‚¹åˆ†é…SCC ID
    vertex_to_scc = {}
    for scc_id, scc in enumerate(sccs):
        for vertex in scc:
            vertex_to_scc[vertex] = scc_id

    # æ„å»ºç¼©ç‚¹å›¾
    scc_graph = {i: set() for i in range(len(sccs))}

    for u, neighbors in graph_dict.items():
        u_scc = vertex_to_scc[u]
        for v in neighbors:
            if v in vertex_to_scc:
                v_scc = vertex_to_scc[v]
                if u_scc != v_scc:  # ä¸åŒSCCä¹‹é—´çš„è¾¹
                    scc_graph[u_scc].add(v_scc)

    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
    scc_graph = {k: list(v) for k, v in scc_graph.items()}
    scc_to_vertices = {i: scc for i, scc in enumerate(sccs)}

    return scc_graph, scc_to_vertices

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹å›¾ï¼šç¨‹åºæ¨¡å—ä¾èµ–å…³ç³»ï¼ˆæœ‰å‘å›¾ï¼‰
    # 0 -> 1, 1 -> 2, 2 -> 0 (å½¢æˆSCC)
    # 2 -> 3, 3 -> 4, 4 -> 3 (å½¢æˆSCC)
    dependency_graph = [
        [1],      # 0
        [2],      # 1
        [0, 3],   # 2
        [4],      # 3
        [3]       # 4
    ]

    sccs = tarjan(dependency_graph)
    print("å¼ºè¿é€šåˆ†é‡ï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰:")
    for i, scc in enumerate(sccs):
        print(f"  SCC {i}: {scc}")
    # è¾“å‡º:
    #   SCC 0: [2, 1, 0]
    #   SCC 1: [4, 3]

    # å­—å…¸æ ¼å¼ç¤ºä¾‹
    module_graph = {
        'A': ['B'],
        'B': ['C'],
        'C': ['A', 'D'],
        'D': ['E'],
        'E': ['D']
    }

    sccs_dict, vertex_to_index = tarjan_dict(module_graph)
    print("\nå¼ºè¿é€šåˆ†é‡ï¼ˆå­—å…¸æ ¼å¼ï¼‰:")
    for i, scc in enumerate(sccs_dict):
        print(f"  SCC {i}: {scc}")

    # æ„å»ºç¼©ç‚¹å›¾
    scc_graph, scc_to_vertices = build_scc_graph(module_graph, sccs_dict, vertex_to_index)
    print("\nç¼©ç‚¹å›¾ï¼ˆDAGï¼‰:")
    for scc_id, neighbors in scc_graph.items():
        if neighbors:
            print(f"  SCC {scc_id} -> {neighbors}")
```

**å®šç† 3.6.1** Tarjanç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$ã€‚

## 3.7 æ‹“æ‰‘æ’åºç®—æ³•

### 3.7.1 Kahnç®—æ³•

**å®šä¹‰ 3.7.1** æ‹“æ‰‘æ’åºæ˜¯å¯¹æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰çš„é¡¶ç‚¹è¿›è¡Œçº¿æ€§æ’åºï¼Œä½¿å¾—å¯¹äºæ¯æ¡æœ‰å‘è¾¹ $(u, v)$ï¼Œé¡¶ç‚¹ $u$ åœ¨æ’åºä¸­éƒ½å‡ºç°åœ¨é¡¶ç‚¹ $v$ ä¹‹å‰ã€‚

**ç®—æ³• 3.7.1** Kahnç®—æ³•ï¼ˆåŸºäºå…¥åº¦çš„æ‹“æ‰‘æ’åºï¼‰

```python
from collections import deque

def topological_sort_kahn(graph):
    """
    Kahnç®—æ³•ï¼šåŸºäºå…¥åº¦çš„æ‹“æ‰‘æ’åº

    å‚æ•°:
        graph: æœ‰å‘å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: [neighbors]}

    è¿”å›:
        result: æ‹“æ‰‘æ’åºç»“æœåˆ—è¡¨ï¼Œå¦‚æœå›¾æœ‰ç¯åˆ™è¿”å›None
    """
    # è®¡ç®—æ¯ä¸ªé¡¶ç‚¹çš„å…¥åº¦
    in_degree = {v: 0 for v in graph}
    for u in graph:
        for v in graph[u]:
            if v in in_degree:
                in_degree[v] += 1

    # å°†æ‰€æœ‰å…¥åº¦ä¸º0çš„é¡¶ç‚¹åŠ å…¥é˜Ÿåˆ—
    queue = deque([v for v in in_degree if in_degree[v] == 0])
    result = []

    # å¤„ç†é˜Ÿåˆ—ä¸­çš„é¡¶ç‚¹
    while queue:
        u = queue.popleft()
        result.append(u)

        # å‡å°‘æ‰€æœ‰é‚»å±…çš„å…¥åº¦
        for v in graph.get(u, []):
            if v in in_degree:
                in_degree[v] -= 1
                # å¦‚æœå…¥åº¦å˜ä¸º0ï¼ŒåŠ å…¥é˜Ÿåˆ—
                if in_degree[v] == 0:
                    queue.append(v)

    # æ£€æŸ¥æ˜¯å¦æœ‰ç¯ï¼ˆå¦‚æœç»“æœé•¿åº¦å°äºé¡¶ç‚¹æ•°ï¼Œè¯´æ˜æœ‰ç¯ï¼‰
    if len(result) != len(graph):
        return None  # å›¾æœ‰ç¯ï¼Œæ— æ³•æ‹“æ‰‘æ’åº

    return result

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šè¯¾ç¨‹ä¾èµ–å…³ç³»ï¼ˆæœ‰å‘å›¾ï¼‰
    # æ•°å­¦ -> ç‰©ç† -> é‡å­ç‰©ç†
    # æ•°å­¦ -> è®¡ç®—æœºç§‘å­¦ -> ç®—æ³•
    course_graph = {
        'æ•°å­¦': ['ç‰©ç†', 'è®¡ç®—æœºç§‘å­¦'],
        'ç‰©ç†': ['é‡å­ç‰©ç†'],
        'è®¡ç®—æœºç§‘å­¦': ['ç®—æ³•'],
        'é‡å­ç‰©ç†': [],
        'ç®—æ³•': []
    }

    result = topological_sort_kahn(course_graph)
    if result:
        print("æ‹“æ‰‘æ’åºç»“æœ:", result)
        # è¾“å‡º: ['æ•°å­¦', 'ç‰©ç†', 'è®¡ç®—æœºç§‘å­¦', 'é‡å­ç‰©ç†', 'ç®—æ³•']
        # æˆ–: ['æ•°å­¦', 'è®¡ç®—æœºç§‘å­¦', 'ç‰©ç†', 'ç®—æ³•', 'é‡å­ç‰©ç†']
    else:
        print("å›¾æœ‰ç¯ï¼Œæ— æ³•æ‹“æ‰‘æ’åº")
```

**å®šç† 3.7.1** (Kahnç®—æ³•æ­£ç¡®æ€§ / Kahn Algorithm Correctness)
Kahnç®—æ³•èƒ½å¤Ÿæ­£ç¡®è®¡ç®—æœ‰å‘æ— ç¯å›¾çš„æ‹“æ‰‘æ’åºã€‚

**è¯æ˜**ï¼š

- **åŸºç¡€æƒ…å†µ**ï¼šåˆå§‹æ—¶ï¼Œæ‰€æœ‰å…¥åº¦ä¸º0çš„é¡¶ç‚¹ï¼ˆæºç‚¹ï¼‰éƒ½åœ¨é˜Ÿåˆ—ä¸­
- **å½’çº³æ­¥éª¤**ï¼šæ¯æ¬¡ä»é˜Ÿåˆ—å–å‡ºä¸€ä¸ªé¡¶ç‚¹ï¼Œå°†å…¶åŠ å…¥ç»“æœï¼Œå¹¶å‡å°‘å…¶æ‰€æœ‰é‚»å±…çš„å…¥åº¦ã€‚å½“æŸä¸ªé‚»å±…çš„å…¥åº¦å˜ä¸º0æ—¶ï¼Œè¯´æ˜å®ƒçš„æ‰€æœ‰å‰é©±éƒ½å·²å¤„ç†ï¼Œå¯ä»¥å®‰å…¨åŠ å…¥é˜Ÿåˆ—
- **ç»ˆæ­¢æ€§**ï¼šå¦‚æœå›¾æ˜¯DAGï¼Œæ‰€æœ‰é¡¶ç‚¹æœ€ç»ˆéƒ½ä¼šè¢«å¤„ç†ï¼›å¦‚æœå›¾æœ‰ç¯ï¼Œç¯ä¸­çš„é¡¶ç‚¹æ°¸è¿œä¸ä¼šå…¥åº¦å˜ä¸º0
- **æ­£ç¡®æ€§**ï¼šç»“æœæ»¡è¶³æ‹“æ‰‘æ’åºçš„å®šä¹‰ï¼Œå› ä¸ºæ¯ä¸ªé¡¶ç‚¹éƒ½åœ¨å…¶æ‰€æœ‰åç»§ä¹‹å‰è¢«å¤„ç† $\square$

**å®šç† 3.7.2** (Kahnç®—æ³•æ—¶é—´å¤æ‚åº¦ / Kahn Algorithm Time Complexity)
Kahnç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$ã€‚

**è¯æ˜**ï¼š

- åˆå§‹åŒ–å…¥åº¦ï¼š$O(|V| + |E|)$
- æ¯ä¸ªé¡¶ç‚¹å…¥é˜Ÿå’Œå‡ºé˜Ÿä¸€æ¬¡ï¼š$O(|V|)$
- æ¯æ¡è¾¹è¢«æ£€æŸ¥ä¸€æ¬¡ï¼š$O(|E|)$
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|V| + |E|)$ $\square$

### 3.7.2 DFSæ‹“æ‰‘æ’åº

**ç®—æ³• 3.7.2** DFSæ‹“æ‰‘æ’åºï¼ˆåŸºäºæ·±åº¦ä¼˜å…ˆæœç´¢ï¼‰

```python
def topological_sort_dfs(graph):
    """
    DFSæ‹“æ‰‘æ’åºï¼šåŸºäºæ·±åº¦ä¼˜å…ˆæœç´¢çš„æ‹“æ‰‘æ’åº

    å‚æ•°:
        graph: æœ‰å‘å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: [neighbors]}

    è¿”å›:
        result: æ‹“æ‰‘æ’åºç»“æœåˆ—è¡¨ï¼ˆé€†åºï¼‰ï¼Œå¦‚æœå›¾æœ‰ç¯åˆ™è¿”å›None
    """
    WHITE, GRAY, BLACK = 0, 1, 2  # æœªè®¿é—®ã€æ­£åœ¨è®¿é—®ã€å·²è®¿é—®
    color = {v: WHITE for v in graph}
    result = []
    has_cycle = [False]  # ä½¿ç”¨åˆ—è¡¨ä»¥åœ¨åµŒå¥—å‡½æ•°ä¸­ä¿®æ”¹

    def dfs(u):
        if has_cycle[0]:
            return

        color[u] = GRAY  # æ ‡è®°ä¸ºæ­£åœ¨è®¿é—®

        for v in graph.get(u, []):
            if v not in color:
                continue
            if color[v] == GRAY:  # å‘ç°åå‘è¾¹ï¼Œè¯´æ˜æœ‰ç¯
                has_cycle[0] = True
                return
            if color[v] == WHITE:
                dfs(v)

        color[u] = BLACK  # æ ‡è®°ä¸ºå·²è®¿é—®
        result.append(u)  # åœ¨é€’å½’è¿”å›æ—¶åŠ å…¥ç»“æœï¼ˆé€†åºï¼‰

    # å¯¹æ¯ä¸ªæœªè®¿é—®çš„é¡¶ç‚¹è¿›è¡ŒDFS
    for u in graph:
        if color[u] == WHITE:
            dfs(u)
            if has_cycle[0]:
                return None

    # åè½¬ç»“æœå¾—åˆ°æ‹“æ‰‘æ’åº
    result.reverse()
    return result

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šä»»åŠ¡ä¾èµ–å…³ç³»
    task_graph = {
        'A': ['B', 'C'],
        'B': ['D'],
        'C': ['D'],
        'D': []
    }

    result = topological_sort_dfs(task_graph)
    if result:
        print("DFSæ‹“æ‰‘æ’åºç»“æœ:", result)
        # è¾“å‡º: ['A', 'B', 'C', 'D'] æˆ– ['A', 'C', 'B', 'D']
    else:
        print("å›¾æœ‰ç¯ï¼Œæ— æ³•æ‹“æ‰‘æ’åº")
```

**å®šç† 3.7.3** (DFSæ‹“æ‰‘æ’åºæ­£ç¡®æ€§ / DFS Topological Sort Correctness)
DFSæ‹“æ‰‘æ’åºèƒ½å¤Ÿæ­£ç¡®è®¡ç®—æœ‰å‘æ— ç¯å›¾çš„æ‹“æ‰‘æ’åºã€‚

**è¯æ˜**ï¼š

- **å…³é”®è§‚å¯Ÿ**ï¼šåœ¨DFSä¸­ï¼Œå½“é€’å½’è¿”å›åˆ°é¡¶ç‚¹ $u$ æ—¶ï¼Œ$u$ çš„æ‰€æœ‰åç»§éƒ½å·²è¢«è®¿é—®
- **æ­£ç¡®æ€§**ï¼šå°†é¡¶ç‚¹æŒ‰å®Œæˆæ—¶é—´ï¼ˆfinish timeï¼‰çš„é€†åºæ’åˆ—ï¼Œå¾—åˆ°çš„åºåˆ—æ»¡è¶³æ‹“æ‰‘æ’åºå®šä¹‰
- **ç¯æ£€æµ‹**ï¼šå¦‚æœå‘ç°åå‘è¾¹ï¼ˆback edgeï¼‰ï¼Œè¯´æ˜å›¾æœ‰ç¯ $\square$

**å®šç† 3.7.4** (DFSæ‹“æ‰‘æ’åºæ—¶é—´å¤æ‚åº¦ / DFS Topological Sort Time Complexity)
DFSæ‹“æ‰‘æ’åºçš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$ã€‚

**è¯æ˜**ï¼šä¸æ ‡å‡†DFSç›¸åŒï¼Œæ¯ä¸ªé¡¶ç‚¹å’Œæ¯æ¡è¾¹éƒ½åªè®¿é—®ä¸€æ¬¡ï¼Œå› æ­¤æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| + |E|)$ $\square$

### 3.7.3 ç®—æ³•å¯¹æ¯”

| ç®—æ³• | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|-----------|-----------|------|---------|
| Kahnç®—æ³• | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ | åŸºäºå…¥åº¦ï¼Œç›´è§‚ | éœ€è¦æ£€æµ‹ç¯æ—¶ |
| DFSæ‹“æ‰‘æ’åº | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ | åŸºäºDFSï¼Œé€’å½’ | å·²è¿›è¡ŒDFSæ—¶ |

### 3.7.4 å®é™…åº”ç”¨æ¡ˆä¾‹

1. **ä»»åŠ¡è°ƒåº¦**ï¼š
   - ç¼–è¯‘ç³»ç»Ÿä¸­çš„æ¨¡å—ä¾èµ–å…³ç³»
   - é¡¹ç›®ç®¡ç†ä¸­çš„ä»»åŠ¡ä¾èµ–
   - è¯¾ç¨‹å­¦ä¹ çš„å…ˆä¿®è¯¾ç¨‹å…³ç³»

2. **ä¾èµ–åˆ†æ**ï¼š
   - è½¯ä»¶åŒ…ç®¡ç†å™¨ï¼ˆå¦‚npmã€pipï¼‰çš„ä¾èµ–è§£æ
   - æ„å»ºç³»ç»Ÿï¼ˆå¦‚Makeã€Gradleï¼‰çš„ä¾èµ–ç®¡ç†
   - æ•°æ®åº“è¿ç§»è„šæœ¬çš„æ‰§è¡Œé¡ºåº

3. **äº‹ä»¶æ’åº**ï¼š
   - äº‹ä»¶é©±åŠ¨ç³»ç»Ÿä¸­çš„äº‹ä»¶å¤„ç†é¡ºåº
   - å·¥ä½œæµç³»ç»Ÿä¸­çš„æ­¥éª¤é¡ºåº
   - æ•°æ®ç®¡é“ä¸­çš„å¤„ç†é¡ºåº

**æƒå¨æ¥æºå¼•ç”¨**ï¼š

- **Wikipedia**: [Topological sorting](https://en.wikipedia.org/wiki/Topological_sorting)
- **CLRS 4th Edition**: Chapter 22.4 - Topological sort
- **MIT 6.006**: Lecture 14 - Depth-first search (DFS), topological sort

## 3.8 äºŒåˆ†å›¾åŒ¹é…ç®—æ³•

### 3.8.1 åŒˆç‰™åˆ©ç®—æ³•

**å®šä¹‰ 3.8.1** äºŒåˆ†å›¾åŒ¹é…æ˜¯åœ¨äºŒåˆ†å›¾ä¸­æ‰¾åˆ°æœ€å¤§åŒ¹é…çš„é—®é¢˜ã€‚**æœ€å¤§åŒ¹é…**æ˜¯è¾¹æ•°æœ€å¤šçš„åŒ¹é…ã€‚

**ç®—æ³• 3.8.1** åŒˆç‰™åˆ©ç®—æ³•ï¼ˆHungarian Algorithmï¼‰

```python
def hungarian_matching(bipartite_graph, left_set, right_set):
    """
    åŒˆç‰™åˆ©ç®—æ³•ï¼šåœ¨äºŒåˆ†å›¾ä¸­æ‰¾æœ€å¤§åŒ¹é…

    å‚æ•°:
        bipartite_graph: äºŒåˆ†å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {left_vertex: [right_vertices]}
        left_set: å·¦éƒ¨é¡¶ç‚¹é›†åˆ
        right_set: å³éƒ¨é¡¶ç‚¹é›†åˆ

    è¿”å›:
        matching: æœ€å¤§åŒ¹é…å­—å…¸ {left_vertex: right_vertex}
        max_matching_size: æœ€å¤§åŒ¹é…çš„å¤§å°
    """
    # matching: right_vertex -> left_vertex
    matching = {v: None for v in right_set}

    def dfs(u, seen):
        """ä½¿ç”¨DFSæŸ¥æ‰¾å¢å¹¿è·¯å¾„"""
        for v in bipartite_graph.get(u, []):
            if v in seen:
                continue
            seen.add(v)

            # å¦‚æœvæœªåŒ¹é…ï¼Œæˆ–å¯ä»¥æ‰¾åˆ°ä»matching[v]çš„å¢å¹¿è·¯å¾„
            if matching[v] is None or dfs(matching[v], seen):
                matching[v] = u
                return True
        return False

    # å¯¹æ¯ä¸ªå·¦éƒ¨é¡¶ç‚¹å°è¯•æ‰¾å¢å¹¿è·¯å¾„
    max_matching = 0
    for u in left_set:
        seen = set()
        if dfs(u, seen):
            max_matching += 1

    # æ„å»ºåŒ¹é…å­—å…¸ï¼ˆå·¦->å³ï¼‰
    result_matching = {}
    for right_v, left_u in matching.items():
        if left_u is not None:
            result_matching[left_u] = right_v

    return result_matching, max_matching

def find_augmenting_path(graph, left_set, matching, start):
    """
    æŸ¥æ‰¾ä»startå¼€å§‹çš„å¢å¹¿è·¯å¾„

    å‚æ•°:
        graph: äºŒåˆ†å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        left_set: å·¦éƒ¨é¡¶ç‚¹é›†åˆ
        matching: å½“å‰åŒ¹é… {right_vertex: left_vertex}
        start: èµ·å§‹é¡¶ç‚¹ï¼ˆå·¦éƒ¨ï¼‰

    è¿”å›:
        path: å¢å¹¿è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
    """
    parent = {}
    queue = [start]
    parent[start] = None

    while queue:
        u = queue.pop(0)

        for v in graph.get(u, []):
            if v in parent:
                continue

            parent[v] = u

            if v not in matching or matching[v] is None:
                # æ‰¾åˆ°å¢å¹¿è·¯å¾„
                path = []
                current = v
                while current is not None:
                    path.append(current)
                    current = parent.get(current)
                return path[::-1]

            # ç»§ç»­ä»åŒ¹é…çš„é¡¶ç‚¹æœç´¢
            u_next = matching[v]
            if u_next not in parent:
                parent[u_next] = v
                queue.append(u_next)

    return None

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šä»»åŠ¡åˆ†é…é—®é¢˜
    # å·¦éƒ¨ï¼šå·¥ä½œäººå‘˜ {A, B, C}
    # å³éƒ¨ï¼šä»»åŠ¡ {1, 2, 3}
    bipartite_graph = {
        'A': [1, 2],
        'B': [2, 3],
        'C': [1, 3]
    }
    left_set = ['A', 'B', 'C']
    right_set = [1, 2, 3]

    matching, size = hungarian_matching(bipartite_graph, left_set, right_set)
    print(f"æœ€å¤§åŒ¹é…å¤§å°: {size}")
    print("åŒ¹é…ç»“æœ:", matching)
    # è¾“å‡º: æœ€å¤§åŒ¹é…å¤§å°: 3
    # åŒ¹é…ç»“æœ: {'A': 1, 'B': 2, 'C': 3} æˆ– {'A': 2, 'B': 3, 'C': 1}
```

**å®šç† 3.8.1** (åŒˆç‰™åˆ©ç®—æ³•æ­£ç¡®æ€§ / Hungarian Algorithm Correctness)
åŒˆç‰™åˆ©ç®—æ³•èƒ½å¤Ÿæ­£ç¡®æ‰¾åˆ°äºŒåˆ†å›¾çš„æœ€å¤§åŒ¹é…ã€‚

**è¯æ˜**ï¼š

- **å…³é”®æ€æƒ³**ï¼šé€šè¿‡æŸ¥æ‰¾å¢å¹¿è·¯å¾„ï¼ˆaugmenting pathï¼‰æ¥å¢åŠ åŒ¹é…å¤§å°
- **å¢å¹¿è·¯å¾„**ï¼šåœ¨åŒ¹é…è¾¹å’ŒéåŒ¹é…è¾¹äº¤æ›¿çš„è·¯å¾„ï¼Œèµ·ç‚¹å’Œç»ˆç‚¹éƒ½æ˜¯æœªåŒ¹é…é¡¶ç‚¹
- **æ­£ç¡®æ€§**ï¼šæ¯æ¬¡æ‰¾åˆ°å¢å¹¿è·¯å¾„åï¼ŒåŒ¹é…å¤§å°å¢åŠ 1ã€‚å½“æ‰¾ä¸åˆ°å¢å¹¿è·¯å¾„æ—¶ï¼Œå½“å‰åŒ¹é…æ˜¯æœ€å¤§åŒ¹é…ï¼ˆæ ¹æ®Bergeå¼•ç†ï¼‰$\square$

**å®šç† 3.8.2** (åŒˆç‰™åˆ©ç®—æ³•æ—¶é—´å¤æ‚åº¦ / Hungarian Algorithm Time Complexity)
åŒˆç‰™åˆ©ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| \cdot |E|)$ã€‚

**è¯æ˜**ï¼š

- æœ€å¤šéœ€è¦ $|V|$ æ¬¡å¢å¹¿ï¼ˆæ¯æ¬¡å¢å¹¿åŒ¹é…å¤§å°å¢åŠ 1ï¼‰
- æ¯æ¬¡å¢å¹¿éœ€è¦ $O(|E|)$ æ—¶é—´ï¼ˆDFSæˆ–BFSï¼‰
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|V| \cdot |E|)$ $\square$

### 3.8.2 Hopcroft-Karpç®—æ³•

**ç®—æ³• 3.8.2** Hopcroft-Karpç®—æ³•ï¼ˆæ›´é«˜æ•ˆçš„æœ€å¤§åŒ¹é…ç®—æ³•ï¼‰

```python
from collections import deque

def hopcroft_karp(bipartite_graph, left_set, right_set):
    """
    Hopcroft-Karpç®—æ³•ï¼šåœ¨äºŒåˆ†å›¾ä¸­æ‰¾æœ€å¤§åŒ¹é…ï¼ˆæ›´é«˜æ•ˆç‰ˆæœ¬ï¼‰

    å‚æ•°:
        bipartite_graph: äºŒåˆ†å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {left_vertex: [right_vertices]}
        left_set: å·¦éƒ¨é¡¶ç‚¹é›†åˆ
        right_set: å³éƒ¨é¡¶ç‚¹é›†åˆ

    è¿”å›:
        matching: æœ€å¤§åŒ¹é…å­—å…¸ {left_vertex: right_vertex}
        max_matching_size: æœ€å¤§åŒ¹é…çš„å¤§å°
    """
    # matching: right_vertex -> left_vertex
    matching = {v: None for v in right_set}
    # distance: left_vertex -> distance to unmatched vertex
    distance = {}

    def bfs():
        """BFSæŸ¥æ‰¾æœ€çŸ­å¢å¹¿è·¯å¾„"""
        queue = deque()
        distance.clear()

        for u in left_set:
            if u not in matching.values():
                distance[u] = 0
                queue.append(u)
            else:
                distance[u] = float('inf')

        distance[None] = float('inf')

        while queue:
            u = queue.popleft()
            if distance[u] < distance[None]:
                for v in bipartite_graph.get(u, []):
                    if matching[v] is None:
                        distance[None] = distance[u] + 1
                    elif matching[v] not in distance or distance[matching[v]] == float('inf'):
                        distance[matching[v]] = distance[u] + 1
                        queue.append(matching[v])

        return distance[None] != float('inf')

    def dfs(u):
        """DFSæŸ¥æ‰¾å¢å¹¿è·¯å¾„"""
        if u is None:
            return True

        for v in bipartite_graph.get(u, []):
            if matching[v] is None or (distance[matching[v]] == distance[u] + 1 and dfs(matching[v])):
                matching[v] = u
                return True

        distance[u] = float('inf')
        return False

    max_matching = 0
    while bfs():
        for u in left_set:
            if u not in matching.values():
                if dfs(u):
                    max_matching += 1

    # æ„å»ºåŒ¹é…å­—å…¸ï¼ˆå·¦->å³ï¼‰
    result_matching = {}
    for right_v, left_u in matching.items():
        if left_u is not None:
            result_matching[left_u] = right_v

    return result_matching, max_matching

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šèµ„æºåˆ†é…é—®é¢˜
    bipartite_graph = {
        'worker1': ['task1', 'task2'],
        'worker2': ['task2', 'task3'],
        'worker3': ['task1', 'task3', 'task4'],
        'worker4': ['task4']
    }
    left_set = ['worker1', 'worker2', 'worker3', 'worker4']
    right_set = ['task1', 'task2', 'task3', 'task4']

    matching, size = hopcroft_karp(bipartite_graph, left_set, right_set)
    print(f"æœ€å¤§åŒ¹é…å¤§å°: {size}")
    print("åŒ¹é…ç»“æœ:", matching)
    # è¾“å‡º: æœ€å¤§åŒ¹é…å¤§å°: 4 (å®Œç¾åŒ¹é…)
```

**å®šç† 3.8.3** (Hopcroft-Karpç®—æ³•æ­£ç¡®æ€§ / Hopcroft-Karp Algorithm Correctness)
Hopcroft-Karpç®—æ³•èƒ½å¤Ÿæ­£ç¡®æ‰¾åˆ°äºŒåˆ†å›¾çš„æœ€å¤§åŒ¹é…ã€‚

**è¯æ˜**ï¼š

- **å…³é”®æ€æƒ³**ï¼šæ¯æ¬¡åŒæ—¶æŸ¥æ‰¾å¤šæ¡ä¸ç›¸äº¤çš„æœ€çŸ­å¢å¹¿è·¯å¾„
- **æ­£ç¡®æ€§**ï¼šç®—æ³•é€šè¿‡BFSæŸ¥æ‰¾æœ€çŸ­å¢å¹¿è·¯å¾„ï¼Œç„¶åä½¿ç”¨DFSåœ¨ç›¸åŒè·ç¦»çš„è·¯å¾„ä¸­æŸ¥æ‰¾å¢å¹¿è·¯å¾„
- **æœ€ä¼˜æ€§**ï¼šæ¯æ¬¡è¿­ä»£åŒ¹é…å¤§å°å¢åŠ çš„é‡ç­‰äºæ‰¾åˆ°çš„å¢å¹¿è·¯å¾„æ•°é‡ï¼Œæœ€å¤šéœ€è¦ $O(\sqrt{|V|})$ æ¬¡è¿­ä»£ $\square$

**å®šç† 3.8.4** (Hopcroft-Karpç®—æ³•æ—¶é—´å¤æ‚åº¦ / Hopcroft-Karp Algorithm Time Complexity)
Hopcroft-Karpç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(\sqrt{|V|} \cdot |E|)$ã€‚

**è¯æ˜**ï¼š

- æœ€å¤šéœ€è¦ $O(\sqrt{|V|})$ æ¬¡è¿­ä»£ï¼ˆæ¯æ¬¡è¿­ä»£åŒ¹é…å¤§å°è‡³å°‘å¢åŠ 1ï¼Œä¸”å¢å¹¿è·¯å¾„é•¿åº¦é€’å¢ï¼‰
- æ¯æ¬¡è¿­ä»£ï¼šBFS $O(|E|)$ + å¤šæ¬¡DFS $O(|E|)$
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(\sqrt{|V|} \cdot |E|)$ $\square$

### 3.8.3 ç®—æ³•å¯¹æ¯”

| ç®—æ³• | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|-----------|-----------|------|---------|
| åŒˆç‰™åˆ©ç®—æ³• | $O(\|V\| \cdot \|E\|)$ | $O(\|V\|)$ | ç®€å•ç›´è§‚ï¼Œæ˜“äºå®ç° | å°è§„æ¨¡å›¾ |
| Hopcroft-Karp | $O(\sqrt{\|V\|} \cdot \|E\|)$ | $O(\|V\|)$ | æ›´é«˜æ•ˆï¼Œç†è®ºæœ€ä¼˜ | å¤§è§„æ¨¡å›¾ |

### 3.8.4 å®é™…åº”ç”¨æ¡ˆä¾‹

1. **ä»»åŠ¡åˆ†é…**ï¼š
   - å·¥ä½œäººå‘˜ä¸ä»»åŠ¡çš„åŒ¹é…
   - å­¦ç”Ÿä¸è¯¾ç¨‹çš„åˆ†é…
   - èµ„æºä¸éœ€æ±‚çš„åŒ¹é…

2. **æ¨èç³»ç»Ÿ**ï¼š
   - ç”¨æˆ·ä¸å•†å“çš„åŒ¹é…
   - å†…å®¹ä¸å—ä¼—çš„åŒ¹é…
   - å¹¿å‘Šä¸ç”¨æˆ·çš„åŒ¹é…

3. **ç½‘ç»œæµé—®é¢˜**ï¼š
   - å¯ä»¥ä½œä¸ºç½‘ç»œæµé—®é¢˜çš„ç‰¹ä¾‹
   - åœ¨äºŒåˆ†å›¾ä¸­æ‰¾æœ€å¤§æµ

**æƒå¨æ¥æºå¼•ç”¨**ï¼š

- **Wikipedia**: [Hungarian algorithm](https://en.wikipedia.org/wiki/Hungarian_algorithm)
- **Wikipedia**: [Hopcroftâ€“Karp algorithm](https://en.wikipedia.org/wiki/Hopcroft%E2%80%93Karp_algorithm)
- **CLRS 4th Edition**: Chapter 26.3 - Maximum bipartite matching
- **MIT 6.006**: Lecture 20 - Network flow, maximum bipartite matching

## 3.9 å›¾åŒæ„ç®—æ³•

### 3.9.1 Weisfeiler-Lehmanç®—æ³•ï¼ˆ1-WLï¼‰

**å®šä¹‰ 3.9.1** å›¾åŒæ„é—®é¢˜æ˜¯åˆ¤æ–­ä¸¤ä¸ªå›¾æ˜¯å¦åœ¨ç»“æ„ä¸Šç›¸åŒã€‚ä¸¤ä¸ªå›¾ $G_1$ å’Œ $G_2$ åŒæ„ï¼Œå½“ä¸”ä»…å½“å­˜åœ¨åŒå°„ $f: V_1 \to V_2$ ä½¿å¾—è¾¹å…³ç³»ä¿æŒã€‚

**ç®—æ³• 3.9.1** Weisfeiler-Lehmanç®—æ³•ï¼ˆ1ç»´ç‰ˆæœ¬ï¼‰

```python
from collections import defaultdict, Counter

def weisfeiler_lehman_1d(graph, iterations=None):
    """
    Weisfeiler-Lehmanç®—æ³•ï¼ˆ1ç»´ç‰ˆæœ¬ï¼‰ï¼šè®¡ç®—å›¾çš„WLæ ‡ç­¾

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: [neighbors]}
        iterations: è¿­ä»£æ¬¡æ•°ï¼Œå¦‚æœä¸ºNoneåˆ™è¿­ä»£åˆ°æ”¶æ•›

    è¿”å›:
        labels: æ¯ä¸ªé¡¶ç‚¹çš„æœ€ç»ˆæ ‡ç­¾å­—å…¸ {vertex: label}
        label_counts: æ ‡ç­¾è®¡æ•°ï¼ˆç”¨äºåŒæ„åˆ¤æ–­ï¼‰
    """
    # åˆå§‹åŒ–ï¼šä½¿ç”¨åº¦ä½œä¸ºåˆå§‹æ ‡ç­¾
    labels = {}
    for vertex in graph:
        labels[vertex] = len(graph.get(vertex, []))

    iteration = 0
    max_iterations = iterations if iterations is not None else len(graph)

    while iteration < max_iterations:
        iteration += 1
        new_labels = {}
        label_multiset = defaultdict(list)

        # ä¸ºæ¯ä¸ªé¡¶ç‚¹æ”¶é›†é‚»å±…æ ‡ç­¾çš„å¤šé‡é›†
        for vertex in graph:
            neighbor_labels = sorted([labels[neighbor]
                                    for neighbor in graph.get(vertex, [])])
            # åˆ›å»ºæ–°çš„æ ‡ç­¾ï¼šå½“å‰æ ‡ç­¾ + é‚»å±…æ ‡ç­¾çš„å¤šé‡é›†
            label_multiset[vertex] = [labels[vertex]] + neighbor_labels

        # ä¸ºæ¯ä¸ªå”¯ä¸€çš„å¤šé‡é›†åˆ†é…æ–°æ ‡ç­¾
        multiset_to_label = {}
        current_label = 0

        for vertex in sorted(graph.keys()):
            multiset = tuple(label_multiset[vertex])
            if multiset not in multiset_to_label:
                multiset_to_label[multiset] = current_label
                current_label += 1
            new_labels[vertex] = multiset_to_label[multiset]

        # æ£€æŸ¥æ˜¯å¦æ”¶æ•›ï¼ˆæ ‡ç­¾ä¸å†å˜åŒ–ï¼‰
        if new_labels == labels:
            break

        labels = new_labels

    # è®¡ç®—æ ‡ç­¾åˆ†å¸ƒ
    label_counts = Counter(labels.values())

    return labels, label_counts

def are_isomorphic_wl(graph1, graph2, max_iterations=None):
    """
    ä½¿ç”¨Weisfeiler-Lehmanç®—æ³•åˆ¤æ–­ä¸¤ä¸ªå›¾æ˜¯å¦åŒæ„

    å‚æ•°:
        graph1: ç¬¬ä¸€ä¸ªå›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        graph2: ç¬¬äºŒä¸ªå›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°

    è¿”å›:
        is_isomorphic: æ˜¯å¦ä¸ºåŒæ„çš„å€™é€‰ï¼ˆå¦‚æœFalseåˆ™è‚¯å®šä¸åŒæ„ï¼ŒTrueè¡¨ç¤ºå¯èƒ½æ˜¯åŒæ„çš„ï¼‰
        labels1: ç¬¬ä¸€ä¸ªå›¾çš„æ ‡ç­¾
        labels2: ç¬¬äºŒä¸ªå›¾çš„æ ‡ç­¾
    """
    # åŸºæœ¬æ£€æŸ¥
    if len(graph1) != len(graph2):
        return False, None, None

    # æ£€æŸ¥è¾¹æ•°
    edges1 = sum(len(neighbors) for neighbors in graph1.values())
    edges2 = sum(len(neighbors) for neighbors in graph2.values())
    if edges1 != edges2:
        return False, None, None

    # è¿è¡ŒWLç®—æ³•
    labels1, counts1 = weisfeiler_lehman_1d(graph1, max_iterations)
    labels2, counts2 = weisfeiler_lehman_1d(graph2, max_iterations)

    # æ¯”è¾ƒæ ‡ç­¾åˆ†å¸ƒ
    if counts1 != counts2:
        return False, labels1, labels2

    # æ ‡ç­¾åˆ†å¸ƒç›¸åŒï¼Œå¯èƒ½æ˜¯åŒæ„çš„ï¼ˆä½†WLç®—æ³•ä¸ä¿è¯ï¼Œåªæ˜¯å¿…è¦æ¡ä»¶ï¼‰
    return True, labels1, labels2

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šåˆ¤æ–­ä¸¤ä¸ªå›¾æ˜¯å¦åŒæ„
    graph1 = {
        'A': ['B', 'C'],
        'B': ['A', 'D'],
        'C': ['A', 'D'],
        'D': ['B', 'C']
    }

    graph2 = {
        '1': ['2', '3'],
        '2': ['1', '4'],
        '3': ['1', '4'],
        '4': ['2', '3']
    }

    is_isomorphic, labels1, labels2 = are_isomorphic_wl(graph1, graph2)
    print(f"å›¾æ˜¯å¦å¯èƒ½åŒæ„: {is_isomorphic}")
    print(f"å›¾1çš„æ ‡ç­¾: {labels1}")
    print(f"å›¾2çš„æ ‡ç­¾: {labels2}")
    # è¾“å‡º: å›¾æ˜¯å¦å¯èƒ½åŒæ„: True
```

**å®šç† 3.9.1** (Weisfeiler-Lehmanç®—æ³•æ­£ç¡®æ€§ / WL Algorithm Correctness)
å¦‚æœä¸¤ä¸ªå›¾è¢«1-WLç®—æ³•åŒºåˆ†ï¼ˆæ ‡ç­¾åˆ†å¸ƒä¸åŒï¼‰ï¼Œåˆ™å®ƒä»¬ä¸åŒæ„ã€‚

**è¯æ˜**ï¼š

- **å…³é”®æ€æƒ³**ï¼šWLç®—æ³•é€šè¿‡é¢œè‰²ç»†åŒ–ï¼ˆcolor refinementï¼‰é€æ­¥åŒºåˆ†é¡¶ç‚¹
- **ä¸å˜é‡**ï¼šå¦‚æœä¸¤ä¸ªå›¾åŒæ„ï¼Œåˆ™å­˜åœ¨åŒæ„æ˜ å°„ï¼Œä½¿å¾—å¯¹åº”çš„é¡¶ç‚¹åœ¨æ¯è½®è¿­ä»£åéƒ½æœ‰ç›¸åŒçš„æ ‡ç­¾
- **åŒºåˆ†æ€§**ï¼šå¦‚æœæ ‡ç­¾åˆ†å¸ƒä¸åŒï¼Œåˆ™ä¸å­˜åœ¨åŒæ„æ˜ å°„ï¼Œå› æ­¤å›¾ä¸åŒæ„
- **æ³¨æ„**ï¼šWLç®—æ³•åªæ˜¯å……åˆ†æ¡ä»¶ï¼Œä¸æ˜¯å¿…è¦æ¡ä»¶ï¼ˆå­˜åœ¨åŒæ„çš„å›¾è¢«é”™è¯¯åŒºåˆ†ï¼‰$\square$

**å®šç† 3.9.2** (Weisfeiler-Lehmanç®—æ³•æ—¶é—´å¤æ‚åº¦ / WL Algorithm Time Complexity)
1-WLç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| \cdot |E| \cdot h)$ï¼Œå…¶ä¸­ $h$ æ˜¯è¿­ä»£æ¬¡æ•°ã€‚

**è¯æ˜**ï¼š

- æ¯è½®è¿­ä»£ï¼šéå†æ‰€æœ‰é¡¶ç‚¹å’Œè¾¹ $O(|V| + |E|)$
- æ ‡ç­¾å“ˆå¸Œï¼š$O(|V|)$
- æœ€å¤šè¿­ä»£ $h = O(|V|)$ æ¬¡ï¼ˆç›´åˆ°æ”¶æ•›ï¼‰
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|V| \cdot (|V| + |E|)) = O(|V|^2 + |V| \cdot |E|)$
- å¯¹äºç¨€ç–å›¾ï¼ˆ$|E| = O(|V|)$ï¼‰ï¼Œå¤æ‚åº¦ä¸º $O(|V|^2)$ $\square$

### 3.9.2 åº”ç”¨æ¡ˆä¾‹

1. **åŒ–å­¦åˆ†å­è¯†åˆ«**ï¼š
   - åˆ¤æ–­ä¸¤ä¸ªåˆ†å­ç»“æ„æ˜¯å¦ç›¸åŒ
   - åˆ†å­å¼åŒæ„æ£€æµ‹
   - è¯ç‰©å‘ç°ä¸­çš„ç»“æ„åŒ¹é…

2. **ç½‘ç»œæ‹“æ‰‘è¯†åˆ«**ï¼š
   - è¯†åˆ«ç½‘ç»œä¸­çš„é‡å¤ç»“æ„
   - ç½‘ç»œæ¨¡å¼åŒ¹é…
   - ç½‘ç»œå¼‚å¸¸æ£€æµ‹

3. **å›¾ç¥ç»ç½‘ç»œ**ï¼š
   - GNNçš„è¡¨è¾¾èƒ½åŠ›ç­‰ä»·äºWLç®—æ³•
   - ç”¨äºå›¾è¡¨ç¤ºå­¦ä¹ 
   - å›¾åˆ†ç±»ä»»åŠ¡

**æƒå¨æ¥æºå¼•ç”¨**ï¼š

- **Wikipedia**: [Weisfeilerâ€“Leman graph isomorphism test](https://en.wikipedia.org/wiki/Weisfeiler%E2%80%93Leman_graph_isomorphism_test)
- **Wikipedia**: [Graph isomorphism](https://en.wikipedia.org/wiki/Graph_isomorphism)
- **Babai, L.** (2016). Graph Isomorphism in Quasipolynomial Time. *STOC 2016*

## 3.10 å›¾åˆ†è§£ç®—æ³•

### 3.10.1 æ ‘åˆ†è§£ç®—æ³•

**å®šä¹‰ 3.10.1** å›¾ $G = (V, E)$ çš„**æ ‘åˆ†è§£**æ˜¯ä¸€ä¸ªæœ‰åºå¯¹ $(T, \{X_t\}_{t \in V(T)})$ï¼Œå…¶ä¸­ï¼š

1. $T = (V(T), E(T))$ æ˜¯ä¸€æ£µæ ‘
2. æ¯ä¸ª $X_t \subseteq V(G)$ æ˜¯ $G$ çš„é¡¶ç‚¹å­é›†ï¼Œç§°ä¸º**è¢‹å­**ï¼ˆbagï¼‰
3. $\bigcup_{t \in V(T)} X_t = V(G)$ï¼ˆè¦†ç›–æ‰€æœ‰é¡¶ç‚¹ï¼‰
4. å¯¹äºæ¯æ¡è¾¹ $uv \in E(G)$ï¼Œå­˜åœ¨æŸä¸ªèŠ‚ç‚¹ $t \in V(T)$ ä½¿å¾— $u, v \in X_t$
5. å¯¹äºæ¯ä¸ªé¡¶ç‚¹ $v \in V(G)$ï¼Œ$T$ ä¸­æ‰€æœ‰åŒ…å« $v$ çš„èŠ‚ç‚¹å½¢æˆ $T$ çš„è¿é€šå­æ ‘

**å®šä¹‰ 3.10.2** å›¾ $G$ çš„**æ ‘å®½**å®šä¹‰ä¸ºï¼š
$$\text{tw}(G) = \min_{(T, \{X_t\})} \max_{t \in V(T)} |X_t| - 1$$

**ç®—æ³• 3.10.1** æ ‘åˆ†è§£æ„å»ºç®—æ³•ï¼ˆåŸºäºæ¶ˆé™¤é¡ºåºï¼‰

```python
from collections import defaultdict, deque
from typing import Dict, List, Set, Tuple, Optional

def tree_decomposition_elimination_order(graph: Dict, elimination_order: List) -> Tuple[Dict, Dict]:
    """
    åŸºäºæ¶ˆé™¤é¡ºåºæ„å»ºæ ‘åˆ†è§£

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: [neighbors]}
        elimination_order: é¡¶ç‚¹æ¶ˆé™¤é¡ºåº

    è¿”å›:
        tree: æ ‘ç»“æ„ {node: [children]}
        bags: è¢‹å­ {node: set of vertices}
    """
    # å¤åˆ¶å›¾ï¼ˆä¸ä¿®æ”¹åŸå›¾ï¼‰
    graph_copy = {v: list(neighbors) for v, neighbors in graph.items()}

    tree = defaultdict(list)
    bags = {}
    node_counter = 0

    # å¤„ç†é¡ºåºï¼šé€†åºå¤„ç†é¡¶ç‚¹
    for i, vertex in enumerate(reversed(elimination_order)):
        if vertex not in graph_copy:
            continue

        # åˆ›å»ºæ–°èŠ‚ç‚¹
        node_id = node_counter
        node_counter += 1

        # è¢‹å­åŒ…å«å½“å‰é¡¶ç‚¹åŠå…¶åœ¨å‰©ä½™å›¾ä¸­çš„é‚»å±…
        neighbors = graph_copy.get(vertex, [])
        bags[node_id] = {vertex} | set(neighbors)

        # å¦‚æœå­˜åœ¨çˆ¶èŠ‚ç‚¹ï¼ˆä¸‹ä¸€ä¸ªè¦æ¶ˆé™¤çš„é¡¶ç‚¹æ‰€åœ¨çš„èŠ‚ç‚¹ï¼‰ï¼Œè¿æ¥çˆ¶å­å…³ç³»
        if i < len(elimination_order) - 1:
            # æŸ¥æ‰¾åŒ…å«ä¸‹ä¸€ä¸ªé¡¶ç‚¹çš„èŠ‚ç‚¹ä½œä¸ºçˆ¶èŠ‚ç‚¹
            next_vertex = elimination_order[len(elimination_order) - 2 - i]
            for parent_id, parent_bag in bags.items():
                if next_vertex in parent_bag:
                    tree[parent_id].append(node_id)
                    break

        # æ¶ˆé™¤å½“å‰é¡¶ç‚¹ï¼šè¿æ¥å…¶æ‰€æœ‰é‚»å±…
        neighbors_list = list(neighbors)
        for j in range(len(neighbors_list)):
            for k in range(j + 1, len(neighbors_list)):
                u, v = neighbors_list[j], neighbors_list[k]
                if v not in graph_copy.get(u, []):
                    graph_copy[u].append(v)
                if u not in graph_copy.get(v, []):
                    graph_copy[v].append(u)

        # ä»å›¾ä¸­åˆ é™¤å½“å‰é¡¶ç‚¹
        for neighbor in neighbors:
            if neighbor in graph_copy and vertex in graph_copy[neighbor]:
                graph_copy[neighbor].remove(vertex)
        del graph_copy[vertex]

    return dict(tree), bags

def compute_treewidth_from_decomposition(bags: Dict) -> int:
    """
    ä»æ ‘åˆ†è§£è®¡ç®—æ ‘å®½

    å‚æ•°:
        bags: è¢‹å­ {node: set of vertices}

    è¿”å›:
        æ ‘å®½å€¼
    """
    if not bags:
        return 0

    max_bag_size = max(len(bag) for bag in bags.values())
    return max_bag_size - 1

def verify_tree_decomposition(graph: Dict, tree: Dict, bags: Dict) -> bool:
    """
    éªŒè¯æ ‘åˆ†è§£çš„æ­£ç¡®æ€§

    å‚æ•°:
        graph: åŸå›¾
        tree: æ ‘ç»“æ„
        bags: è¢‹å­

    è¿”å›:
        æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ ‘åˆ†è§£
    """
    vertices = set(graph.keys())

    # æ£€æŸ¥1: è¦†ç›–æ‰€æœ‰é¡¶ç‚¹
    covered_vertices = set()
    for bag in bags.values():
        covered_vertices |= bag
    if covered_vertices != vertices:
        return False

    # æ£€æŸ¥2: æ¯æ¡è¾¹éƒ½åœ¨æŸä¸ªè¢‹å­é‡Œ
    for u in graph:
        for v in graph[u]:
            edge_covered = False
            for bag in bags.values():
                if u in bag and v in bag:
                    edge_covered = True
                    break
            if not edge_covered:
                return False

    # æ£€æŸ¥3: è¿é€šæ€§æ¡ä»¶ï¼ˆç®€åŒ–éªŒè¯ï¼‰
    # å¯¹äºæ¯ä¸ªé¡¶ç‚¹ï¼Œæ£€æŸ¥åŒ…å«å®ƒçš„èŠ‚ç‚¹æ˜¯å¦è¿é€š
    for vertex in vertices:
        containing_nodes = [node for node, bag in bags.items() if vertex in bag]
        if len(containing_nodes) > 1:
            # ç®€åŒ–ï¼šæ£€æŸ¥è¿™äº›èŠ‚ç‚¹åœ¨æ ‘ä¸­æ˜¯å¦å½¢æˆè¿é€šå­å›¾
            if not _is_connected_subgraph(tree, containing_nodes):
                return False

    return True

def _is_connected_subgraph(tree: Dict, nodes: List) -> bool:
    """æ£€æŸ¥èŠ‚ç‚¹é›†åˆåœ¨æ ‘ä¸­æ˜¯å¦å½¢æˆè¿é€šå­å›¾"""
    if len(nodes) <= 1:
        return True

    # ä½¿ç”¨BFSæ£€æŸ¥è¿é€šæ€§
    visited = set()
    queue = deque([nodes[0]])
    visited.add(nodes[0])

    while queue:
        node = queue.popleft()

        # æ£€æŸ¥æ ‘ä¸­çš„é‚»å±…
        if node in tree:
            for child in tree[node]:
                if child in nodes and child not in visited:
                    visited.add(child)
                    queue.append(child)

        # æ£€æŸ¥çˆ¶èŠ‚ç‚¹
        for parent, children in tree.items():
            if node in children and parent in nodes and parent not in visited:
                visited.add(parent)
                queue.append(parent)

    return len(visited) == len(nodes)

def greedy_elimination_order(graph: Dict) -> List:
    """
    è´ªå¿ƒæ¶ˆé™¤é¡ºåºï¼šæ¯æ¬¡é€‰æ‹©åº¦æ•°æœ€å°çš„é¡¶ç‚¹

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º

    è¿”å›:
        æ¶ˆé™¤é¡ºåºåˆ—è¡¨
    """
    graph_copy = {v: set(neighbors) for v, neighbors in graph.items()}
    order = []
    remaining = set(graph_copy.keys())

    while remaining:
        # é€‰æ‹©åº¦æ•°æœ€å°çš„é¡¶ç‚¹
        min_degree = float('inf')
        min_vertex = None

        for vertex in remaining:
            degree = len(graph_copy[vertex] & remaining)
            if degree < min_degree:
                min_degree = degree
                min_vertex = vertex

        if min_vertex is None:
            break

        order.append(min_vertex)

        # è¿æ¥æ‰€æœ‰é‚»å±…
        neighbors = list(graph_copy[min_vertex] & remaining)
        for i in range(len(neighbors)):
            for j in range(i + 1, len(neighbors)):
                u, v = neighbors[i], neighbors[j]
                graph_copy[u].add(v)
                graph_copy[v].add(u)

        # åˆ é™¤é¡¶ç‚¹
        remaining.remove(min_vertex)

    return order

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šæ„å»ºè·¯å¾„å›¾çš„æ ‘åˆ†è§£
    graph = {
        'A': ['B'],
        'B': ['A', 'C'],
        'C': ['B', 'D'],
        'D': ['C']
    }

    # ä½¿ç”¨è´ªå¿ƒæ¶ˆé™¤é¡ºåº
    order = greedy_elimination_order(graph)
    print(f"æ¶ˆé™¤é¡ºåº: {order}")

    # æ„å»ºæ ‘åˆ†è§£
    tree, bags = tree_decomposition_elimination_order(graph, order)
    print(f"æ ‘ç»“æ„: {tree}")
    print(f"è¢‹å­: {bags}")

    # è®¡ç®—æ ‘å®½
    treewidth = compute_treewidth_from_decomposition(bags)
    print(f"æ ‘å®½: {treewidth}")

    # éªŒè¯æ ‘åˆ†è§£
    is_valid = verify_tree_decomposition(graph, tree, bags)
    print(f"æ ‘åˆ†è§£æœ‰æ•ˆæ€§: {is_valid}")
```

**å®šç† 3.10.1** (æ ‘åˆ†è§£æ­£ç¡®æ€§ / Tree Decomposition Correctness)
åŸºäºæ¶ˆé™¤é¡ºåºçš„æ ‘åˆ†è§£ç®—æ³•èƒ½å¤Ÿç”Ÿæˆæœ‰æ•ˆçš„æ ‘åˆ†è§£ã€‚

**è¯æ˜**ï¼š

- **è¦†ç›–æ€§**ï¼šæ¯ä¸ªé¡¶ç‚¹åœ¨æ¶ˆé™¤æ—¶è¢«æ·»åŠ åˆ°æŸä¸ªè¢‹å­ä¸­ï¼Œä¸”å…¶é‚»å±…ä¹Ÿåœ¨è¯¥è¢‹å­ä¸­
- **è¾¹è¦†ç›–**ï¼šæ¯æ¡è¾¹åœ¨å…¶ä¸­ä¸€ä¸ªç«¯ç‚¹çš„æ¶ˆé™¤æ—¶ï¼Œä¸¤ä¸ªç«¯ç‚¹éƒ½åœ¨è¢‹å­é‡Œ
- **è¿é€šæ€§**ï¼šé¡¶ç‚¹åœ¨æ ‘ä¸­çš„å‡ºç°å½¢æˆè¿é€šå­å›¾ï¼Œå› ä¸ºæ¶ˆé™¤é¡ºåºä¿è¯äº†è¿ç»­æ€§ $\square$

**å®šç† 3.10.2** (æ ‘åˆ†è§£æ—¶é—´å¤æ‚åº¦ / Tree Decomposition Time Complexity)
åŸºäºæ¶ˆé™¤é¡ºåºçš„æ ‘åˆ†è§£ç®—æ³•æ—¶é—´å¤æ‚åº¦ä¸º $O(|V| \cdot (|V| + |E|))$ã€‚

**è¯æ˜**ï¼š

- æ¶ˆé™¤é¡ºåºè®¡ç®—ï¼š$O(|V|^2)$ï¼ˆè´ªå¿ƒé€‰æ‹©ï¼‰
- æ„å»ºæ ‘åˆ†è§£ï¼šå¯¹æ¯ä¸ªé¡¶ç‚¹ï¼Œè¿æ¥å…¶é‚»å±…ï¼Œæœ€åæƒ…å†µ $O(|V| + |E|)$
- æ€»æ—¶é—´å¤æ‚åº¦ï¼š$O(|V| \cdot (|V| + |E|))$ $\square$

### 3.10.2 è·¯å¾„åˆ†è§£ç®—æ³•

**å®šä¹‰ 3.10.3** å›¾ $G$ çš„**è·¯å¾„åˆ†è§£**æ˜¯ä¸€ç§ç‰¹æ®Šçš„æ ‘åˆ†è§£ï¼Œå…¶ä¸­æ ‘ $T$ æ˜¯ä¸€æ¡è·¯å¾„ã€‚

**ç®—æ³• 3.10.2** è·¯å¾„åˆ†è§£ç®—æ³•ï¼ˆç®€åŒ–ç‰ˆï¼‰

```python
def path_decomposition(graph: Dict) -> Tuple[List, List[Set]]:
    """
    æ„å»ºå›¾çš„è·¯å¾„åˆ†è§£

    å‚æ•°:
        graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º

    è¿”å›:
        path: è·¯å¾„ä¸Šçš„èŠ‚ç‚¹é¡ºåº
        bags: æ¯ä¸ªèŠ‚ç‚¹çš„è¢‹å­åˆ—è¡¨
    """
    # ä½¿ç”¨å›¾çš„çº¿æ€§æ’åºï¼ˆå¦‚æ·±åº¦ä¼˜å…ˆæœç´¢é¡ºåºï¼‰
    visited = set()
    path_order = []

    def dfs(vertex):
        if vertex in visited:
            return
        visited.add(vertex)
        path_order.append(vertex)
        for neighbor in graph.get(vertex, []):
            if neighbor not in visited:
                dfs(neighbor)

    # ä»ä»»æ„é¡¶ç‚¹å¼€å§‹DFS
    start_vertex = next(iter(graph.keys())) if graph else None
    if start_vertex:
        dfs(start_vertex)

    # ä¸ºæ¯ä¸ªè·¯å¾„èŠ‚ç‚¹åˆ›å»ºè¢‹å­
    bags = []
    for i, vertex in enumerate(path_order):
        bag = {vertex}
        # åŒ…å«å½“å‰é¡¶ç‚¹åŠå…¶åœ¨å‰åºå’Œååºä¸­çš„é‚»å±…
        for neighbor in graph.get(vertex, []):
            if neighbor in path_order[:i+1] or (i < len(path_order) - 1 and neighbor in path_order):
                bag.add(neighbor)
        bags.append(bag)

    return path_order, bags

def compute_pathwidth(bags: List[Set]) -> int:
    """
    è®¡ç®—è·¯å¾„å®½

    å‚æ•°:
        bags: è¢‹å­åˆ—è¡¨

    è¿”å›:
        è·¯å¾„å®½å€¼
    """
    if not bags:
        return 0

    max_bag_size = max(len(bag) for bag in bags)
    return max_bag_size - 1
```

### 3.10.3 åº”ç”¨æ¡ˆä¾‹

1. **åŠ¨æ€è§„åˆ’ä¼˜åŒ–**ï¼š
   - å¯¹äºæ ‘å®½ä¸º $k$ çš„å›¾ï¼Œè®¸å¤šNPéš¾é—®é¢˜å¯ä»¥åœ¨ $O(f(k) \cdot n)$ æ—¶é—´å†…è§£å†³
   - ç‹¬ç«‹é›†ã€é¡¶ç‚¹è¦†ç›–ã€æ”¯é…é›†ç­‰é—®é¢˜

2. **ç®—æ³•è®¾è®¡**ï¼š
   - åˆ©ç”¨æ ‘åˆ†è§£è®¾è®¡é«˜æ•ˆçš„å›¾ç®—æ³•
   - å‚æ•°åŒ–ç®—æ³•è®¾è®¡

3. **å®é™…é—®é¢˜**ï¼š
   - VLSIç”µè·¯å¸ƒå±€ä¼˜åŒ–
   - è›‹ç™½è´¨ç›¸äº’ä½œç”¨ç½‘ç»œåˆ†æ
   - ç¼–è¯‘å™¨ä¼˜åŒ–

**æƒå¨æ¥æºå¼•ç”¨**ï¼š

- **Wikipedia**: [Tree decomposition](https://en.wikipedia.org/wiki/Tree_decomposition)
- **Wikipedia**: [Treewidth](https://en.wikipedia.org/wiki/Treewidth)
- **Robertson, N. & Seymour, P.D.** (1984). Graph Minors. II. Algorithmic aspects of tree-width. *Journal of Algorithms*

## 3.11 åŠ¨æ€å›¾ç®—æ³•

### 3.11.1 åŠ¨æ€è¿é€šæ€§ç®—æ³•

**å®šä¹‰ 3.11.1** åŠ¨æ€å›¾é—®é¢˜æ˜¯åœ¨å›¾ç»“æ„å‘ç”Ÿå˜åŒ–ï¼ˆæ·»åŠ /åˆ é™¤è¾¹æˆ–é¡¶ç‚¹ï¼‰æ—¶ï¼Œé«˜æ•ˆç»´æŠ¤å’ŒæŸ¥è¯¢å›¾çš„æ€§è´¨ï¼ˆå¦‚è¿é€šæ€§ã€æœ€çŸ­è·¯å¾„ç­‰ï¼‰ã€‚

**ç®—æ³• 3.11.1** åŠ¨æ€å¹¶æŸ¥é›†ï¼ˆæ”¯æŒè·¯å¾„å‹ç¼©å’ŒæŒ‰ç§©åˆå¹¶ï¼‰

```python
from typing import Dict, Optional

class DynamicUnionFind:
    """
    åŠ¨æ€å¹¶æŸ¥é›†ï¼šæ”¯æŒåŠ¨æ€å›¾çš„è¿é€šæ€§æŸ¥è¯¢å’Œç»´æŠ¤
    """

    def __init__(self, vertices: list):
        """
        åˆå§‹åŒ–å¹¶æŸ¥é›†

        å‚æ•°:
            vertices: é¡¶ç‚¹åˆ—è¡¨
        """
        self.parent = {v: v for v in vertices}
        self.rank = {v: 0 for v in vertices}
        self.components = len(vertices)

    def find(self, x) -> int:
        """
        æŸ¥æ‰¾æ ¹èŠ‚ç‚¹ï¼ˆå¸¦è·¯å¾„å‹ç¼©ï¼‰

        å‚æ•°:
            x: é¡¶ç‚¹

        è¿”å›:
            æ ¹èŠ‚ç‚¹
        """
        if self.parent[x] != x:
            self.parent[x] = self.find(self.parent[x])  # è·¯å¾„å‹ç¼©
        return self.parent[x]

    def union(self, x, y) -> bool:
        """
        åˆå¹¶ä¸¤ä¸ªé›†åˆï¼ˆæŒ‰ç§©åˆå¹¶ï¼‰

        å‚æ•°:
            x, y: ä¸¤ä¸ªé¡¶ç‚¹

        è¿”å›:
            æ˜¯å¦æˆåŠŸåˆå¹¶ï¼ˆå¦‚æœå·²ç»åœ¨åŒä¸€é›†åˆåˆ™è¿”å›Falseï¼‰
        """
        root_x = self.find(x)
        root_y = self.find(y)

        if root_x == root_y:
            return False  # å·²ç»åœ¨åŒä¸€é›†åˆ

        # æŒ‰ç§©åˆå¹¶
        if self.rank[root_x] < self.rank[root_y]:
            self.parent[root_x] = root_y
        elif self.rank[root_x] > self.rank[root_y]:
            self.parent[root_y] = root_x
        else:
            self.parent[root_y] = root_x
            self.rank[root_x] += 1

        self.components -= 1
        return True

    def is_connected(self, x, y) -> bool:
        """
        æŸ¥è¯¢ä¸¤ä¸ªé¡¶ç‚¹æ˜¯å¦è¿é€š

        å‚æ•°:
            x, y: ä¸¤ä¸ªé¡¶ç‚¹

        è¿”å›:
            æ˜¯å¦è¿é€š
        """
        return self.find(x) == self.find(y)

    def get_components_count(self) -> int:
        """
        è·å–è¿é€šåˆ†é‡æ•°é‡

        è¿”å›:
            è¿é€šåˆ†é‡æ•°é‡
        """
        return self.components

class DynamicGraphConnectivity:
    """
    åŠ¨æ€å›¾è¿é€šæ€§ç»´æŠ¤
    """

    def __init__(self, graph: Dict = None):
        """
        åˆå§‹åŒ–åŠ¨æ€å›¾

        å‚æ•°:
            graph: åˆå§‹å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º
        """
        self.graph = graph if graph else {}
        self.vertices = set(self.graph.keys())
        for neighbors in self.graph.values():
            self.vertices.update(neighbors)

        # åˆå§‹åŒ–å¹¶æŸ¥é›†
        self.uf = DynamicUnionFind(list(self.vertices))

        # æ·»åŠ åˆå§‹è¾¹
        for u in self.graph:
            for v in self.graph[u]:
                self.uf.union(u, v)

    def add_edge(self, u, v):
        """
        æ·»åŠ è¾¹

        å‚æ•°:
            u, v: è¾¹çš„ä¸¤ä¸ªç«¯ç‚¹
        """
        if u not in self.graph:
            self.graph[u] = []
        if v not in self.graph:
            self.graph[v] = []

        if v not in self.graph[u]:
            self.graph[u].append(v)
        if u not in self.graph[v]:
            self.graph[v].append(u)

        # æ›´æ–°å¹¶æŸ¥é›†
        self.uf.union(u, v)

    def remove_edge(self, u, v):
        """
        åˆ é™¤è¾¹ï¼ˆç®€åŒ–å®ç°ï¼šéœ€è¦é‡æ–°æ„å»ºå¹¶æŸ¥é›†ï¼‰

        å‚æ•°:
            u, v: è¾¹çš„ä¸¤ä¸ªç«¯ç‚¹
        """
        if u in self.graph and v in self.graph[u]:
            self.graph[u].remove(v)
        if v in self.graph and u in self.graph[v]:
            self.graph[v].remove(u)

        # é‡æ–°æ„å»ºå¹¶æŸ¥é›†ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´é«˜æ•ˆçš„ç®—æ³•ï¼‰
        self.uf = DynamicUnionFind(list(self.vertices))
        for u_node in self.graph:
            for v_node in self.graph[u_node]:
                self.uf.union(u_node, v_node)

    def is_connected(self, u, v) -> bool:
        """
        æŸ¥è¯¢ä¸¤ä¸ªé¡¶ç‚¹æ˜¯å¦è¿é€š

        å‚æ•°:
            u, v: ä¸¤ä¸ªé¡¶ç‚¹

        è¿”å›:
            æ˜¯å¦è¿é€š
        """
        return self.uf.is_connected(u, v)

    def get_components_count(self) -> int:
        """
        è·å–è¿é€šåˆ†é‡æ•°é‡

        è¿”å›:
            è¿é€šåˆ†é‡æ•°é‡
        """
        return self.uf.get_components_count()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šåŠ¨æ€è¿é€šæ€§æŸ¥è¯¢
    graph = {
        'A': ['B'],
        'B': ['A', 'C'],
        'C': ['B']
    }

    dgc = DynamicGraphConnectivity(graph)
    print(f"åˆå§‹è¿é€šåˆ†é‡æ•°: {dgc.get_components_count()}")
    print(f"Aå’ŒDæ˜¯å¦è¿é€š: {dgc.is_connected('A', 'D')}")

    # æ·»åŠ è¾¹
    dgc.add_edge('A', 'D')
    print(f"æ·»åŠ è¾¹åï¼ŒAå’ŒDæ˜¯å¦è¿é€š: {dgc.is_connected('A', 'D')}")
    print(f"è¿é€šåˆ†é‡æ•°: {dgc.get_components_count()}")
```

**å®šç† 3.11.1** (åŠ¨æ€å¹¶æŸ¥é›†å¤æ‚åº¦ / Dynamic Union-Find Complexity)
ä½¿ç”¨è·¯å¾„å‹ç¼©å’ŒæŒ‰ç§©åˆå¹¶çš„åŠ¨æ€å¹¶æŸ¥é›†ï¼Œ$m$ æ¬¡æ“ä½œçš„å‡æ‘Šæ—¶é—´å¤æ‚åº¦ä¸º $O(m \alpha(n))$ï¼Œå…¶ä¸­ $\alpha(n)$ æ˜¯åé˜¿å…‹æ›¼å‡½æ•°ã€‚

**è¯æ˜**ï¼š

- **è·¯å¾„å‹ç¼©**ï¼šå°†æŸ¥æ‰¾è·¯å¾„ä¸Šçš„æ‰€æœ‰èŠ‚ç‚¹ç›´æ¥è¿æ¥åˆ°æ ¹èŠ‚ç‚¹
- **æŒ‰ç§©åˆå¹¶**ï¼šæ€»æ˜¯å°†ç§©å°çš„æ ‘è¿æ¥åˆ°ç§©å¤§çš„æ ‘
- **åé˜¿å…‹æ›¼å‡½æ•°**ï¼š$\alpha(n)$ å¢é•¿ææ…¢ï¼Œå¯¹äºæ‰€æœ‰å®é™…åº”ç”¨ï¼Œ$\alpha(n) \leq 4$
- **å‡æ‘Šå¤æ‚åº¦**ï¼š$m$ æ¬¡æ“ä½œçš„å¤æ‚åº¦ä¸º $O(m \alpha(n))$ $\square$

### 3.11.2 åŠ¨æ€æœ€çŸ­è·¯å¾„ç®—æ³•

**ç®—æ³• 3.11.2** å¢é‡Dijkstraç®—æ³•ï¼ˆåŠ¨æ€ç»´æŠ¤å•æºæœ€çŸ­è·¯å¾„ï¼‰

```python
import heapq
from typing import Dict, List, Tuple, Optional

class IncrementalDijkstra:
    """
    å¢é‡Dijkstraç®—æ³•ï¼šåŠ¨æ€ç»´æŠ¤å•æºæœ€çŸ­è·¯å¾„
    """

    def __init__(self, graph: Dict, source):
        """
        åˆå§‹åŒ–å¢é‡Dijkstraç®—æ³•

        å‚æ•°:
            graph: å›¾çš„é‚»æ¥è¡¨è¡¨ç¤º {vertex: [(neighbor, weight), ...]}
            source: æºé¡¶ç‚¹
        """
        self.graph = {v: list(edges) for v, edges in graph.items()}
        self.source = source
        self.distances = {v: float('inf') for v in self.graph}
        self.distances[source] = 0
        self.predecessors = {v: None for v in self.graph}

        # åˆå§‹åŒ–æœ€çŸ­è·¯å¾„æ ‘
        self._compute_initial_paths()

    def _compute_initial_paths(self):
        """è®¡ç®—åˆå§‹æœ€çŸ­è·¯å¾„"""
        pq = [(0, self.source)]
        visited = set()

        while pq:
            dist, u = heapq.heappop(pq)
            if u in visited:
                continue
            visited.add(u)

            for v, weight in self.graph.get(u, []):
                if v not in visited:
                    new_dist = dist + weight
                    if new_dist < self.distances.get(v, float('inf')):
                        self.distances[v] = new_dist
                        self.predecessors[v] = u
                        heapq.heappush(pq, (new_dist, v))

    def add_edge(self, u, v, weight):
        """
        æ·»åŠ è¾¹ï¼ˆæˆ–æ›´æ–°è¾¹æƒé‡ï¼‰

        å‚æ•°:
            u, v: è¾¹çš„ä¸¤ä¸ªç«¯ç‚¹
            weight: è¾¹æƒé‡
        """
        if u not in self.graph:
            self.graph[u] = []
        if v not in self.graph:
            self.graph[v] = []

        # æ›´æ–°é‚»æ¥è¡¨
        updated = False
        for i, (neighbor, w) in enumerate(self.graph[u]):
            if neighbor == v:
                if w > weight:  # æƒé‡å‡å°‘
                    self.graph[u][i] = (v, weight)
                    updated = True
                break
        else:
            self.graph[u].append((v, weight))
            updated = True

        # å¦‚æœæƒé‡å‡å°‘ï¼Œéœ€è¦æ›´æ–°æœ€çŸ­è·¯å¾„
        if updated and weight < self.graph[u][-1][1] if self.graph[u] else True:
            self._update_paths(u, v, weight)

    def _update_paths(self, u, v, weight):
        """
        æ›´æ–°å—å½±å“çš„è·¯å¾„

        å‚æ•°:
            u, v: è¾¹çš„ä¸¤ä¸ªç«¯ç‚¹
            weight: æ–°çš„è¾¹æƒé‡
        """
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°vçš„è·ç¦»
        new_dist = self.distances.get(u, float('inf')) + weight
        if new_dist < self.distances.get(v, float('inf')):
            self.distances[v] = new_dist
            self.predecessors[v] = u

            # ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—æ›´æ–°vçš„é‚»å±…
            pq = [(new_dist, v)]
            visited = set()

            while pq:
                dist, node = heapq.heappop(pq)
                if node in visited:
                    continue
                visited.add(node)

                for neighbor, w in self.graph.get(node, []):
                    if neighbor not in visited:
                        new_neighbor_dist = dist + w
                        if new_neighbor_dist < self.distances.get(neighbor, float('inf')):
                            self.distances[neighbor] = new_neighbor_dist
                            self.predecessors[neighbor] = node
                            heapq.heappush(pq, (new_neighbor_dist, neighbor))

    def get_distance(self, v) -> float:
        """
        è·å–ä»æºç‚¹åˆ°é¡¶ç‚¹vçš„æœ€çŸ­è·ç¦»

        å‚æ•°:
            v: ç›®æ ‡é¡¶ç‚¹

        è¿”å›:
            æœ€çŸ­è·ç¦»
        """
        return self.distances.get(v, float('inf'))

    def get_path(self, v) -> Optional[List]:
        """
        è·å–ä»æºç‚¹åˆ°é¡¶ç‚¹vçš„æœ€çŸ­è·¯å¾„

        å‚æ•°:
            v: ç›®æ ‡é¡¶ç‚¹

        è¿”å›:
            è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸å¯è¾¾åˆ™è¿”å›None
        """
        if self.distances.get(v, float('inf')) == float('inf'):
            return None

        path = []
        current = v
        while current is not None:
            path.append(current)
            current = self.predecessors.get(current)

        return list(reversed(path))

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šåŠ¨æ€æœ€çŸ­è·¯å¾„ç»´æŠ¤
    graph = {
        'A': [('B', 1), ('C', 4)],
        'B': [('C', 2), ('D', 5)],
        'C': [('D', 1)],
        'D': []
    }

    inc_dijkstra = IncrementalDijkstra(graph, 'A')
    print(f"Aåˆ°Dçš„è·ç¦»: {inc_dijkstra.get_distance('D')}")
    print(f"Aåˆ°Dçš„è·¯å¾„: {inc_dijkstra.get_path('D')}")

    # æ·»åŠ æ–°è¾¹
    inc_dijkstra.add_edge('A', 'D', 2)
    print(f"æ·»åŠ è¾¹åï¼ŒAåˆ°Dçš„è·ç¦»: {inc_dijkstra.get_distance('D')}")
    print(f"Aåˆ°Dçš„è·¯å¾„: {inc_dijkstra.get_path('D')}")
```

**å®šç† 3.11.2** (å¢é‡Dijkstraç®—æ³•å¤æ‚åº¦ / Incremental Dijkstra Complexity)
å¢é‡Dijkstraç®—æ³•åœ¨æ·»åŠ æˆ–æ›´æ–°è¾¹åï¼Œç»´æŠ¤æœ€çŸ­è·¯å¾„çš„æ—¶é—´å¤æ‚åº¦ä¸º $O((V+E)\log V)$ã€‚

**è¯æ˜**ï¼š

- **åˆå§‹åŒ–**ï¼šæ ‡å‡†Dijkstraç®—æ³•ï¼Œ$O((V+E)\log V)$
- **è¾¹æ›´æ–°**ï¼šå½“è¾¹æƒé‡å‡å°‘æ—¶ï¼Œåªæœ‰å—å½±å“é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„éœ€è¦æ›´æ–°
- **æ›´æ–°è¿‡ç¨‹**ï¼šä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—ï¼Œæœ€å¤šå¤„ç† $O(V)$ ä¸ªé¡¶ç‚¹ï¼Œæ¯ä¸ªé¡¶ç‚¹æœ€å¤šæ›´æ–° $O(E)$ æ¬¡
- **æ€»å¤æ‚åº¦**ï¼š$O((V+E)\log V)$ $\square$

### 3.11.3 å¢é‡ç®—æ³•åº”ç”¨

1. **åŠ¨æ€è¿é€šæ€§**ï¼š
   - ç¤¾äº¤ç½‘ç»œä¸­çš„å®æ—¶è¿é€šæ€§æŸ¥è¯¢
   - ç½‘ç»œæ‹“æ‰‘ç›‘æ§
   - åœ¨çº¿ç¤¾åŒºæ£€æµ‹

2. **åŠ¨æ€æœ€çŸ­è·¯å¾„**ï¼š
   - å®æ—¶å¯¼èˆªç³»ç»Ÿï¼ˆGoogle Mapsã€é«˜å¾·åœ°å›¾ï¼‰
   - äº¤é€šç½‘ç»œä¼˜åŒ–
   - è·¯ç”±ç®—æ³•åŠ¨æ€æ›´æ–°

3. **å¢é‡MST**ï¼š
   - åŠ¨æ€ç½‘ç»œè®¾è®¡
   - åœ¨çº¿æœ€å°ç”Ÿæˆæ ‘ç»´æŠ¤

**æƒå¨æ¥æºå¼•ç”¨**ï¼š

- **Wikipedia**: [Union-find data structure](https://en.wikipedia.org/wiki/Disjoint-set_data_structure)
- **Wikipedia**: [Dynamic connectivity](https://en.wikipedia.org/wiki/Dynamic_connectivity)
- **Tarjan, R.E.** (1975). Efficiency of a Good But Not Linear Set Union Algorithm. *Journal of the ACM*

## 3.12 ç®—æ³•å¤æ‚åº¦åˆ†æ

### 3.12.1 å›¾ç®—æ³•å¯¹æ¯”çŸ©é˜µ / Graph Algorithms Comparison Matrix

| ç®—æ³•ç±»åˆ« | ç®—æ³•åç§° | é—®é¢˜ç±»å‹ | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|---------|---------|-----------|-----------|------|---------|
| **å›¾éå†** | DFS | å›¾éå† | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ | æ·±åº¦ä¼˜å…ˆ | æ‹“æ‰‘æ’åºã€è¿é€šåˆ†é‡ |
| **å›¾éå†** | BFS | å›¾éå† | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ | å¹¿åº¦ä¼˜å…ˆã€æœ€çŸ­è·¯å¾„ | æœ€çŸ­è·¯å¾„ï¼ˆæ— æƒå›¾ï¼‰ |
| **æœ€çŸ­è·¯å¾„** | Dijkstra | å•æºæœ€çŸ­è·¯å¾„ | $O((\|V\| + \|E\|) \log \|V\|)$ | $O(\|V\|)$ | æ— è´Ÿæƒè¾¹ | è·¯ç”±ç®—æ³•ã€å¯¼èˆªç³»ç»Ÿ |
| **æœ€çŸ­è·¯å¾„** | Floyd-Warshall | å…¨å¯¹æœ€çŸ­è·¯å¾„ | $O(\|V\|^3)$ | $O(\|V\|^2)$ | å…è®¸è´Ÿæƒè¾¹ï¼ˆæ— è´Ÿåœˆï¼‰ | å°è§„æ¨¡å›¾ã€é¢„å¤„ç† |
| **æœ€å°ç”Ÿæˆæ ‘** | Kruskal | æœ€å°ç”Ÿæˆæ ‘ | $O(\|E\| \log \|E\|)$ | $O(\|V\|)$ | è¾¹æ’åºã€å¹¶æŸ¥é›† | ç¨€ç–å›¾ |
| **æœ€å°ç”Ÿæˆæ ‘** | Prim | æœ€å°ç”Ÿæˆæ ‘ | $O(\|E\| \log \|V\|)$ | $O(\|V\|)$ | é¡¶ç‚¹æ‰©å±•ã€ä¼˜å…ˆé˜Ÿåˆ— | ç¨ å¯†å›¾ |
| **ç½‘ç»œæµ** | Edmonds-Karp | æœ€å¤§æµ | $O(\|V\| \cdot \|E\|^2)$ | $O(\|V\| + \|E\|)$ | BFSæ‰¾å¢å¹¿è·¯å¾„ | ä¸­ç­‰è§„æ¨¡ç½‘ç»œæµ |
| **ç½‘ç»œæµ** | Dinic | æœ€å¤§æµ | $O(\|V\|^2 \cdot \|E\|)$ | $O(\|V\| + \|E\|)$ | åˆ†å±‚å›¾+é˜»å¡æµ | å¤§è§„æ¨¡ç½‘ç»œæµ |
| **å¼ºè¿é€šåˆ†é‡** | Tarjan | å¼ºè¿é€šåˆ†é‡ | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ | ä¸€æ¬¡DFS | æœ‰å‘å›¾åˆ†è§£ |
| **æ‹“æ‰‘æ’åº** | Kahn | æ‹“æ‰‘æ’åº | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ | åŸºäºå…¥åº¦ | ä»»åŠ¡è°ƒåº¦ã€ä¾èµ–åˆ†æ |
| **æ‹“æ‰‘æ’åº** | DFS | æ‹“æ‰‘æ’åº | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ | åŸºäºDFS | ä»»åŠ¡è°ƒåº¦ã€ä¾èµ–åˆ†æ |
| **äºŒåˆ†å›¾åŒ¹é…** | åŒˆç‰™åˆ© | æœ€å¤§åŒ¹é… | $O(\|V\| \cdot \|E\|)$ | $O(\|V\|)$ | å¢å¹¿è·¯å¾„ | ä»»åŠ¡åˆ†é…ã€èµ„æºåŒ¹é… |
| **äºŒåˆ†å›¾åŒ¹é…** | Hopcroft-Karp | æœ€å¤§åŒ¹é… | $O(\sqrt{\|V\|} \cdot \|E\|)$ | $O(\|V\|)$ | å¤šè·¯å¾„å¢å¹¿ | å¤§è§„æ¨¡åŒ¹é…é—®é¢˜ |
| **å›¾åŒæ„** | Weisfeiler-Lehman | å›¾åŒæ„åˆ¤å®š | $O(\|V\|^2 + \|V\| \cdot \|E\|)$ | $O(\|V\|)$ | é¢œè‰²ç»†åŒ– | å›¾ç»“æ„è¯†åˆ« |
| **å›¾åˆ†è§£** | æ ‘åˆ†è§£ | æ ‘åˆ†è§£æ„å»º | $O(\|V\| \cdot (\|V\| + \|E\|))$ | $O(\|V\|^2)$ | æ¶ˆé™¤é¡ºåº | åŠ¨æ€è§„åˆ’åŸºç¡€ |
| **åŠ¨æ€è¿é€šæ€§** | åŠ¨æ€å¹¶æŸ¥é›† | è¿é€šæ€§æŸ¥è¯¢ | $O(m \alpha(n))$ | $O(\|V\|)$ | è·¯å¾„å‹ç¼© | å®æ—¶è¿é€šæ€§ |
| **åŠ¨æ€æœ€çŸ­è·¯å¾„** | å¢é‡Dijkstra | æœ€çŸ­è·¯å¾„ç»´æŠ¤ | $O((\|V\| + \|E\|) \log \|V\|)$ | $O(\|V\| + \|E\|)$ | å¢é‡æ›´æ–° | å®æ—¶å¯¼èˆª |
| **å›¾ç€è‰²** | è´ªå¿ƒç€è‰² | å›¾ç€è‰² | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ | å¯å‘å¼ | èµ„æºåˆ†é… |

**ç¬¦å·è¯´æ˜**ï¼š

- $\|f^*\|$ï¼šæœ€å¤§æµå€¼
- $\|V\|$ï¼šé¡¶ç‚¹æ•°
- $\|E\|$ï¼šè¾¹æ•°

### 3.12.2 æ—¶é—´å¤æ‚åº¦æ€»ç»“

| ç®—æ³• | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ |
|------|------------|------------|
| DFS | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ |
| BFS | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ |
| Dijkstra | $O((\|V\| + \|E\|) \log \|V\|)$ | $O(\|V\|)$ |
| Floyd-Warshall | $O(\|V\|^3)$ | $O(\|V\|^2)$ |
| Kruskal | $O(\|E\| \log \|E\|)$ | $O(\|V\|)$ |
| Prim | $O(\|E\| \log \|V\|)$ | $O(\|V\|)$ |
| Edmonds-Karp | $O(\|V\| \cdot \|E\|^2)$ | $O(\|V\| + \|E\|)$ |
| Dinic | $O(\|V\|^2 \cdot \|E\|)$ | $O(\|V\| + \|E\|)$ |
| Tarjan | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ |
| Kahnï¼ˆæ‹“æ‰‘æ’åºï¼‰ | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ |
| DFSï¼ˆæ‹“æ‰‘æ’åºï¼‰ | $O(\|V\| + \|E\|)$ | $O(\|V\|)$ |
| åŒˆç‰™åˆ©ï¼ˆäºŒåˆ†å›¾åŒ¹é…ï¼‰ | $O(\|V\| \cdot \|E\|)$ | $O(\|V\|)$ |
| Hopcroft-Karpï¼ˆäºŒåˆ†å›¾åŒ¹é…ï¼‰ | $O(\sqrt{\|V\|} \cdot \|E\|)$ | $O(\|V\|)$ |
| Weisfeiler-Lehmanï¼ˆå›¾åŒæ„ï¼‰ | $O(\|V\|^2 + \|V\| \cdot \|E\|)$ | $O(\|V\|)$ |
| æ ‘åˆ†è§£ï¼ˆå›¾åˆ†è§£ï¼‰ | $O(\|V\| \cdot (\|V\| + \|E\|))$ | $O(\|V\|^2)$ |
| åŠ¨æ€å¹¶æŸ¥é›†ï¼ˆåŠ¨æ€è¿é€šæ€§ï¼‰ | $O(m \alpha(n))$ | $O(\|V\|)$ |
| å¢é‡Dijkstraï¼ˆåŠ¨æ€æœ€çŸ­è·¯å¾„ï¼‰ | $O((\|V\| + \|E\|) \log \|V\|)$ | $O(\|V\| + \|E\|)$ |

### 3.12.3 ç®—æ³•é€‰æ‹©æŒ‡å—

**å®šç† 3.7.1** (å›¾è¡¨ç¤ºæ–¹æ³•é€‰æ‹© / Graph Representation Selection)
å¯¹äºç¨€ç–å›¾ï¼ˆ$|E| = O(|V|)$ï¼‰ï¼Œé‚»æ¥è¡¨è¡¨ç¤ºæ›´ä¼˜ï¼›å¯¹äºç¨ å¯†å›¾ï¼ˆ$|E| = O(|V|^2)$ï¼‰ï¼Œé‚»æ¥çŸ©é˜µè¡¨ç¤ºæ›´ä¼˜ã€‚

**è¯æ˜**ï¼š

- ç¨€ç–å›¾ï¼šé‚»æ¥è¡¨ç©ºé—´å¤æ‚åº¦ $O(|V| + |E|) = O(|V|)$ï¼Œé‚»æ¥çŸ©é˜µ $O(|V|^2)$
- ç¨ å¯†å›¾ï¼šä¸¤ç§è¡¨ç¤ºçš„ç©ºé—´å¤æ‚åº¦ç›¸è¿‘ï¼Œä½†é‚»æ¥çŸ©é˜µæŸ¥è¯¢æ›´å¿«

**å®šç† 3.7.2** (æœ€çŸ­è·¯å¾„ç®—æ³•é€‰æ‹© / Shortest Path Algorithm Selection)
å¯¹äºå•æºæœ€çŸ­è·¯å¾„é—®é¢˜ï¼š

- **æ— è´Ÿæƒè¾¹**ï¼šä½¿ç”¨Dijkstraç®—æ³•ï¼ˆæ—¶é—´å¤æ‚åº¦ $O((|V| + |E|) \log |V|)$ï¼‰
- **æœ‰è´Ÿæƒè¾¹**ï¼šä½¿ç”¨Bellman-Fordç®—æ³•ï¼ˆæ—¶é—´å¤æ‚åº¦ $O(|V| \cdot |E|)$ï¼‰
- **æ‰€æœ‰é¡¶ç‚¹å¯¹**ï¼šä½¿ç”¨Floyd-Warshallç®—æ³•ï¼ˆæ—¶é—´å¤æ‚åº¦ $O(|V|^3)$ï¼‰

**å®šç† 3.7.3** (æœ€å°ç”Ÿæˆæ ‘ç®—æ³•é€‰æ‹© / MST Algorithm Selection)
å¯¹äºæœ€å°ç”Ÿæˆæ ‘é—®é¢˜ï¼š

- **ç¨€ç–å›¾**ï¼ˆ$|E| = O(|V|)$ï¼‰ï¼šKruskalç®—æ³•æ›´ä¼˜ï¼ˆ$O(|E| \log |E|) = O(|V| \log |V|)$ï¼‰
- **ç¨ å¯†å›¾**ï¼ˆ$|E| = O(|V|^2)$ï¼‰ï¼šPrimç®—æ³•æ›´ä¼˜ï¼ˆ$O(|E| \log |V|) = O(|V|^2 \log |V|)$ï¼‰

### 3.12.4 å›¾ç®—æ³•é€‰æ‹©æ€ç»´å¯¼å›¾ / Graph Algorithm Selection Mind Map

```text
å›¾ç®—æ³•é€‰æ‹©
â”œâ”€â”€ å›¾éå†
â”‚   â”œâ”€â”€ DFS
â”‚   â”‚   â”œâ”€â”€ ç‰¹ç‚¹ï¼šæ·±åº¦ä¼˜å…ˆã€é€’å½’/æ ˆ
â”‚   â”‚   â””â”€â”€ åº”ç”¨ï¼šæ‹“æ‰‘æ’åºã€è¿é€šåˆ†é‡ã€å›æº¯
â”‚   â””â”€â”€ BFS
â”‚       â”œâ”€â”€ ç‰¹ç‚¹ï¼šå¹¿åº¦ä¼˜å…ˆã€é˜Ÿåˆ—
â”‚       â””â”€â”€ åº”ç”¨ï¼šæœ€çŸ­è·¯å¾„ï¼ˆæ— æƒå›¾ï¼‰ã€å±‚æ¬¡éå†
â”‚
â”œâ”€â”€ æœ€çŸ­è·¯å¾„
â”‚   â”œâ”€â”€ å•æºæœ€çŸ­è·¯å¾„
â”‚   â”‚   â”œâ”€â”€ æ— è´Ÿæƒè¾¹ â†’ Dijkstra
â”‚   â”‚   â””â”€â”€ æœ‰è´Ÿæƒè¾¹ â†’ Bellman-Ford
â”‚   â””â”€â”€ å…¨å¯¹æœ€çŸ­è·¯å¾„
â”‚       â””â”€â”€ Floyd-Warshall
â”‚
â”œâ”€â”€ æœ€å°ç”Ÿæˆæ ‘
â”‚   â”œâ”€â”€ ç¨€ç–å›¾ â†’ Kruskal
â”‚   â””â”€â”€ ç¨ å¯†å›¾ â†’ Prim
â”‚
â”œâ”€â”€ ç½‘ç»œæµ
â”‚   â”œâ”€â”€ ä¸­ç­‰è§„æ¨¡ â†’ Edmonds-Karp
â”‚   â””â”€â”€ å¤§è§„æ¨¡ â†’ Dinic
â”‚
â””â”€â”€ å…¶ä»–ç®—æ³•
    â”œâ”€â”€ å¼ºè¿é€šåˆ†é‡ â†’ Tarjan
    â””â”€â”€ å›¾ç€è‰² â†’ è´ªå¿ƒç€è‰²
```

## 3.13 å®é™…åº”ç”¨

### 3.13.1 ç½‘ç»œè·¯ç”±

å›¾ç®—æ³•åœ¨ç½‘ç»œè·¯ç”±ä¸­å¹¿æ³›åº”ç”¨ï¼š

- æœ€çŸ­è·¯å¾„ç®—æ³•ç”¨äºè·¯ç”±è¡¨è®¡ç®—
- æœ€å°ç”Ÿæˆæ ‘ç”¨äºç½‘ç»œæ‹“æ‰‘è®¾è®¡
- æœ€å¤§æµç®—æ³•ç”¨äºç½‘ç»œå®¹é‡è§„åˆ’

### 3.13.2 ç¤¾äº¤ç½‘ç»œåˆ†æ

- è¿é€šåˆ†é‡ç®—æ³•ç”¨äºç¤¾åŒºå‘ç°
- æœ€çŸ­è·¯å¾„ç®—æ³•ç”¨äºå½±å“åŠ›ä¼ æ’­åˆ†æ
- å›¾ç€è‰²ç®—æ³•ç”¨äºèµ„æºåˆ†é…

### 3.13.3 ç”Ÿç‰©ä¿¡æ¯å­¦

- å›¾ç®—æ³•ç”¨äºè›‹ç™½è´¨ç›¸äº’ä½œç”¨ç½‘ç»œåˆ†æ
- åŸºå› è°ƒæ§ç½‘ç»œå»ºæ¨¡
- ä»£è°¢é€šè·¯åˆ†æ

## ğŸ’¼ **3.14 å®é™…å·¥ç¨‹åº”ç”¨æ¡ˆä¾‹ / Real-World Engineering Application Cases**

### 3.14.1 ç½‘ç»œè·¯ç”±ç³»ç»Ÿåº”ç”¨ / Network Routing System Applications

#### 3.14.1.1 äº’è”ç½‘è·¯ç”±ç³»ç»Ÿ

**é¡¹ç›®èƒŒæ™¯**ï¼š

- **é—®é¢˜**ï¼šéœ€è¦å®ç°å…¨çƒäº’è”ç½‘è·¯ç”±ï¼Œè®¡ç®—æœ€ä¼˜è·¯å¾„
- **è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨Dijkstraå’ŒFloyd-Warshallç®—æ³•å®ç°è·¯ç”±è®¡ç®—
- **æŠ€æœ¯è¦ç‚¹**ï¼š
  - ä½¿ç”¨Dijkstraç®—æ³•è®¡ç®—å•æºæœ€çŸ­è·¯å¾„
  - ä½¿ç”¨Floyd-Warshallç®—æ³•è®¡ç®—æ‰€æœ‰é¡¶ç‚¹å¯¹æœ€çŸ­è·¯å¾„
  - ä½¿ç”¨åŠ¨æ€è·¯ç”±åè®®æ›´æ–°è·¯ç”±è¡¨
- **å®é™…æ•ˆæœ**ï¼š
  - æ”¯æŒå…¨çƒäº’è”ç½‘è·¯ç”±
  - è·¯ç”±è®¡ç®—æ•ˆç‡æ˜¾è‘—æé«˜
  - ä¿è¯äº†ç½‘ç»œè¿é€šæ€§

#### 3.14.1.2 æ•°æ®ä¸­å¿ƒç½‘ç»œè·¯ç”±

**é¡¹ç›®èƒŒæ™¯**ï¼š

- **é—®é¢˜**ï¼šéœ€è¦å®ç°æ•°æ®ä¸­å¿ƒç½‘ç»œè·¯ç”±ï¼Œä¼˜åŒ–æ•°æ®ä¼ è¾“è·¯å¾„
- **è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨æœ€çŸ­è·¯å¾„ç®—æ³•å’Œç½‘ç»œæµç®—æ³•ä¼˜åŒ–è·¯ç”±
- **æŠ€æœ¯è¦ç‚¹**ï¼š
  - ä½¿ç”¨æœ€çŸ­è·¯å¾„ç®—æ³•è®¡ç®—æœ€ä¼˜è·¯å¾„
  - ä½¿ç”¨ç½‘ç»œæµç®—æ³•ä¼˜åŒ–å¸¦å®½åˆ†é…
  - ä½¿ç”¨ECMPå®ç°å¤šè·¯å¾„è·¯ç”±
- **å®é™…æ•ˆæœ**ï¼š
  - æé«˜äº†ç½‘ç»œå¸¦å®½åˆ©ç”¨ç‡
  - é™ä½äº†ç½‘ç»œå»¶è¿Ÿ
  - ä¼˜åŒ–äº†ç½‘ç»œæ€§èƒ½

### 3.14.2 ç¤¾äº¤ç½‘ç»œåˆ†æåº”ç”¨ / Social Network Analysis Applications

#### 3.14.2.1 ç¤¾åŒºå‘ç°ç³»ç»Ÿ

**é¡¹ç›®èƒŒæ™¯**ï¼š

- **é—®é¢˜**ï¼šéœ€è¦è¯†åˆ«ç¤¾äº¤ç½‘ç»œä¸­çš„ç¤¾åŒºç»“æ„ï¼Œä¼˜åŒ–æ¨èç³»ç»Ÿ
- **è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨è¿é€šåˆ†é‡ç®—æ³•å’Œç¤¾åŒºæ£€æµ‹ç®—æ³•è¯†åˆ«ç¤¾åŒº
- **æŠ€æœ¯è¦ç‚¹**ï¼š
  - ä½¿ç”¨è¿é€šåˆ†é‡ç®—æ³•è¯†åˆ«ç½‘ç»œè¿é€šæ€§
  - ä½¿ç”¨ç¤¾åŒºæ£€æµ‹ç®—æ³•è¯†åˆ«ç¤¾åŒºç»“æ„
  - ä½¿ç”¨å›¾ç€è‰²ç®—æ³•ä¼˜åŒ–èµ„æºåˆ†é…
- **å®é™…æ•ˆæœ**ï¼š
  - è¯†åˆ«äº†å¤šä¸ªç¤¾äº¤ç½‘ç»œç¤¾åŒº
  - æé«˜äº†æ¨èç³»ç»Ÿå‡†ç¡®æ€§
  - ä¼˜åŒ–äº†ç”¨æˆ·ä½“éªŒ

#### 3.14.2.2 å½±å“åŠ›ä¼ æ’­åˆ†æ

**é¡¹ç›®èƒŒæ™¯**ï¼š

- **é—®é¢˜**ï¼šéœ€è¦åˆ†æä¿¡æ¯åœ¨ç¤¾äº¤ç½‘ç»œä¸­çš„ä¼ æ’­è·¯å¾„
- **è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨æœ€çŸ­è·¯å¾„ç®—æ³•åˆ†æå½±å“åŠ›ä¼ æ’­
- **æŠ€æœ¯è¦ç‚¹**ï¼š
  - ä½¿ç”¨æœ€çŸ­è·¯å¾„ç®—æ³•è®¡ç®—ä¼ æ’­è·¯å¾„
  - ä½¿ç”¨å›¾éå†ç®—æ³•åˆ†æä¼ æ’­èŒƒå›´
  - ä½¿ç”¨ç½‘ç»œæµç®—æ³•ä¼˜åŒ–ä¼ æ’­ç­–ç•¥
- **å®é™…æ•ˆæœ**ï¼š
  - ç†è§£äº†ä¿¡æ¯ä¼ æ’­æœºåˆ¶
  - ä¼˜åŒ–äº†è¥é”€ç­–ç•¥
  - æé«˜äº†ä¿¡æ¯ä¼ æ’­æ•ˆç‡

### 3.14.3 ç”Ÿç‰©ä¿¡æ¯å­¦åº”ç”¨ / Bioinformatics Applications

#### 3.14.3.1 è›‹ç™½è´¨ç›¸äº’ä½œç”¨ç½‘ç»œåˆ†æ

**é¡¹ç›®èƒŒæ™¯**ï¼š

- **é—®é¢˜**ï¼šéœ€è¦åˆ†æè›‹ç™½è´¨ç›¸äº’ä½œç”¨ç½‘ç»œï¼Œè¯†åˆ«å…³é”®è›‹ç™½è´¨
- **è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨å›¾ç®—æ³•åˆ†æè›‹ç™½è´¨ç½‘ç»œ
- **æŠ€æœ¯è¦ç‚¹**ï¼š
  - ä½¿ç”¨æœ€çŸ­è·¯å¾„ç®—æ³•åˆ†æè›‹ç™½è´¨é—´è·ç¦»
  - ä½¿ç”¨è¿é€šåˆ†é‡ç®—æ³•è¯†åˆ«åŠŸèƒ½æ¨¡å—
  - ä½¿ç”¨ç½‘ç»œæµç®—æ³•åˆ†æä»£è°¢é€šè·¯
- **å®é™…æ•ˆæœ**ï¼š
  - è¯†åˆ«äº†å¤šä¸ªå…³é”®è›‹ç™½è´¨
  - å‘ç°äº†æ–°çš„åŠŸèƒ½æ¨¡å—
  - ä¿ƒè¿›äº†è¯ç‰©é¶ç‚¹å‘ç°

#### 3.14.3.2 åŸºå› è°ƒæ§ç½‘ç»œå»ºæ¨¡

**é¡¹ç›®èƒŒæ™¯**ï¼š

- **é—®é¢˜**ï¼šéœ€è¦æ„å»ºåŸºå› è°ƒæ§ç½‘ç»œï¼Œç†è§£åŸºå› è¡¨è¾¾è°ƒæ§
- **è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨å›¾ç®—æ³•æ„å»ºå’Œåˆ†æåŸºå› è°ƒæ§ç½‘ç»œ
- **æŠ€æœ¯è¦ç‚¹**ï¼š
  - ä½¿ç”¨å›¾éå†ç®—æ³•åˆ†æè°ƒæ§è·¯å¾„
  - ä½¿ç”¨æœ€çŸ­è·¯å¾„ç®—æ³•è¯†åˆ«å…³é”®è°ƒæ§å› å­
  - ä½¿ç”¨ç½‘ç»œæµç®—æ³•åˆ†æè°ƒæ§å¼ºåº¦
- **å®é™…æ•ˆæœ**ï¼š
  - ç†è§£äº†åŸºå› è¡¨è¾¾è°ƒæ§æœºåˆ¶
  - è¯†åˆ«äº†å…³é”®è°ƒæ§å› å­
  - ä¿ƒè¿›äº†ç²¾å‡†åŒ»ç–—å‘å±•

### 3.14.4 å›¾ç®—æ³•å·¥å…·ä¸åº”ç”¨ / Graph Algorithm Tools and Applications

#### 3.14.4.1 ä¸»æµå›¾ç®—æ³•å·¥å…·

1. **NetworkX**
   - **ç”¨é€”**ï¼šPythonå›¾è®ºåˆ†æåº“
   - **ç‰¹ç‚¹**ï¼šæ”¯æŒå¤šç§å›¾ç®—æ³•ã€æ˜“äºä½¿ç”¨ã€å¯æ‰©å±•
   - **åº”ç”¨**ï¼šç½‘ç»œåˆ†æã€ç®—æ³•å®ç°ã€ç ”ç©¶å¼€å‘

2. **Graphviz**
   - **ç”¨é€”**ï¼šå›¾å¯è§†åŒ–å·¥å…·
   - **ç‰¹ç‚¹**ï¼šæ”¯æŒå¤šç§å›¾å¸ƒå±€ç®—æ³•ã€é«˜è´¨é‡è¾“å‡º
   - **åº”ç”¨**ï¼šå›¾å¯è§†åŒ–ã€ç½‘ç»œæ‹“æ‰‘å¯è§†åŒ–

3. **Gephi**
   - **ç”¨é€”**ï¼šç½‘ç»œå¯è§†åŒ–å’Œåˆ†æ
   - **ç‰¹ç‚¹**ï¼šäº¤äº’å¼å¯è§†åŒ–ã€ç½‘ç»œåˆ†æã€ç¤¾åŒºæ£€æµ‹
   - **åº”ç”¨**ï¼šç¤¾äº¤ç½‘ç»œå¯è§†åŒ–ã€ç½‘ç»œåˆ†æ

#### 3.14.4.2 å®é™…åº”ç”¨æ¡ˆä¾‹

1. **Google PageRankç®—æ³•**
   - **å·¥å…·**ï¼šå›¾ç®—æ³•ã€ç½‘ç»œåˆ†æ
   - **åº”ç”¨å†…å®¹**ï¼šç½‘é¡µæ’åã€æœç´¢å¼•æ“ä¼˜åŒ–
   - **æˆæœ**ï¼šå®ç°äº†é«˜æ•ˆçš„ç½‘é¡µæ’åç®—æ³•ï¼Œæˆä¸ºæœç´¢å¼•æ“åŸºç¡€

2. **Facebookç¤¾äº¤ç½‘ç»œåˆ†æ**
   - **å·¥å…·**ï¼šNetworkXã€ç¤¾åŒºæ£€æµ‹ç®—æ³•
   - **åº”ç”¨å†…å®¹**ï¼šç¤¾åŒºå‘ç°ã€æ¨èç³»ç»Ÿä¼˜åŒ–
   - **æˆæœ**ï¼šè¯†åˆ«äº†å¤šä¸ªç”¨æˆ·ç¤¾åŒºï¼Œä¼˜åŒ–äº†æ¨èç³»ç»Ÿ

3. **ç”Ÿç‰©ç½‘ç»œåˆ†æ**
   - **å·¥å…·**ï¼šå›¾ç®—æ³•ã€ç½‘ç»œåˆ†æ
   - **åº”ç”¨å†…å®¹**ï¼šè›‹ç™½è´¨ç½‘ç»œåˆ†æã€åŸºå› è°ƒæ§ç½‘ç»œå»ºæ¨¡
   - **æˆæœ**ï¼šè¯†åˆ«äº†å¤šä¸ªå…³é”®è›‹ç™½è´¨ï¼Œä¿ƒè¿›äº†è¯ç‰©ç ”å‘

## 3.15 æ€»ç»“ä¸å±•æœ›

æœ¬ç« ä»‹ç»äº†å›¾è®ºä¸­çš„ç»å…¸ç®—æ³•ï¼ŒåŒ…æ‹¬ï¼š

1. **éå†ç®—æ³•**ï¼šDFSå’ŒBFSï¼Œç”¨äºå›¾çš„æ¢ç´¢å’Œæœç´¢
2. **æœ€çŸ­è·¯å¾„ç®—æ³•**ï¼šDijkstraå’ŒFloyd-Warshallï¼Œç”¨äºè·ç¦»è®¡ç®—
3. **æœ€å°ç”Ÿæˆæ ‘ç®—æ³•**ï¼šKruskalå’ŒPrimï¼Œç”¨äºç½‘ç»œè®¾è®¡
4. **ç½‘ç»œæµç®—æ³•**ï¼šEdmonds-Karpå’ŒDinicï¼Œç”¨äºæµé‡ä¼˜åŒ–
5. **å›¾ç€è‰²ç®—æ³•**ï¼šè´ªå¿ƒç®—æ³•ï¼Œç”¨äºèµ„æºåˆ†é…
6. **å¼ºè¿é€šåˆ†é‡ç®—æ³•**ï¼šTarjanç®—æ³•ï¼Œç”¨äºå›¾åˆ†è§£

è¿™äº›ç®—æ³•ä¸ºå›¾ç½‘ç»œé€šä¿¡æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œå®ç”¨å·¥å…·ï¼Œä¸ºåç»­çš„ç½‘ç»œæ‹“æ‰‘è®¾è®¡å’Œé€šä¿¡åè®®åˆ†æå¥ å®šäº†ç®—æ³•åŸºç¡€ã€‚

---

## ğŸš€ **3.16 æœ€æ–°ç ”ç©¶è¿›å±•ï¼ˆ2024-2025ï¼‰/ Latest Research Progress (2024-2025)**

### 3.16.1 é‡å­å›¾ç®—æ³•

#### é‡å­è®¡ç®—åœ¨å›¾ç®—æ³•ä¸­çš„åº”ç”¨

**æœ€æ–°è¿›å±•**ï¼š

1. **é‡å­æœ€çŸ­è·¯å¾„ç®—æ³•**ï¼š
   - ä½¿ç”¨é‡å­ç®—æ³•åŠ é€Ÿæœ€çŸ­è·¯å¾„è®¡ç®—
   - é‡å­æœç´¢ç®—æ³•åœ¨è·¯å¾„æŸ¥æ‰¾ä¸­çš„åº”ç”¨
   - é‡å­å¹¶è¡Œæ€§æé«˜ç®—æ³•æ•ˆç‡

2. **é‡å­å›¾åŒ¹é…ç®—æ³•**ï¼š
   - é‡å­ç®—æ³•è§£å†³å›¾åŒ¹é…é—®é¢˜
   - é‡å­ä¼˜åŒ–ç®—æ³•
   - é‡å­è¿‘ä¼¼ä¼˜åŒ–ç®—æ³•ï¼ˆQAOAï¼‰

**ç®—æ³• 3.11.1** (é‡å­æœ€çŸ­è·¯å¾„ç®—æ³• / Quantum Shortest Path Algorithm)

```python
from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister
import numpy as np

class QuantumShortestPath:
    """é‡å­æœ€çŸ­è·¯å¾„ç®—æ³•"""

    def __init__(self, graph):
        self.graph = graph
        self.num_nodes = graph.number_of_nodes()
        self.num_qubits = int(np.ceil(np.log2(self.num_nodes)))

    def quantum_dijkstra(self, start, end):
        """é‡å­Dijkstraç®—æ³•"""
        # åˆ›å»ºé‡å­ç”µè·¯
        qreg = QuantumRegister(self.num_qubits * 2, 'q')
        creg = ClassicalRegister(self.num_qubits * 2, 'c')
        qc = QuantumCircuit(qreg, creg)

        # åˆå§‹åŒ–èµ·å§‹èŠ‚ç‚¹
        start_binary = format(start, f'0{self.num_qubits}b')
        for i, bit in enumerate(start_binary):
            if bit == '1':
                qc.x(qreg[i])

        # é‡å­æœç´¢æœ€çŸ­è·¯å¾„
        for _ in range(int(np.sqrt(self.num_nodes))):
            # Oracleæ ‡è®°æœ€çŸ­è·¯å¾„
            self.oracle_mark_shortest_path(qc, qreg, start, end)
            # Groveræ‰©æ•£
            self.grover_diffusion(qc, qreg)

        # æµ‹é‡
        qc.measure(qreg, creg)

        return qc

    def oracle_mark_shortest_path(self, qc, qreg, start, end):
        """Oracleæ ‡è®°æœ€çŸ­è·¯å¾„"""
        # æ ‡è®°ä»startåˆ°endçš„æœ€çŸ­è·¯å¾„
        # ä½¿ç”¨BFSåœ¨é‡å­æ€ä¸­æœç´¢
        pass

    def grover_diffusion(self, qc, qreg):
        """Groveræ‰©æ•£ç®—å­"""
        for qubit in qreg:
            qc.h(qubit)
        for qubit in qreg:
            qc.z(qubit)
        for qubit in qreg:
            qc.h(qubit)

# å¤æ‚åº¦åˆ†æ
# æ—¶é—´å¤æ‚åº¦: O(âˆšN) é‡å­åŠ é€Ÿ
# ç©ºé—´å¤æ‚åº¦: O(log N) é‡å­æ¯”ç‰¹æ•°
```

### 3.16.2 AIé©±åŠ¨çš„å›¾ç®—æ³•ä¼˜åŒ–

#### æœºå™¨å­¦ä¹ åœ¨å›¾ç®—æ³•ä¸­çš„åº”ç”¨

**æœ€æ–°è¿›å±•**ï¼š

1. **å­¦ä¹ å‹å›¾ç®—æ³•**ï¼š
   - ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å›¾ç®—æ³•å‚æ•°
   - è‡ªé€‚åº”å›¾ç®—æ³•
   - å­¦ä¹ å‹å¯å‘å¼ç®—æ³•

2. **å›¾ç¥ç»ç½‘ç»œç®—æ³•**ï¼š
   - ä½¿ç”¨GNNåŠ é€Ÿå›¾ç®—æ³•
   - ç«¯åˆ°ç«¯çš„å›¾ç®—æ³•å­¦ä¹ 
   - å¯å­¦ä¹ çš„å›¾ç®—æ³•

**ç®—æ³• 3.11.2** (å­¦ä¹ å‹æœ€çŸ­è·¯å¾„ç®—æ³• / Learned Shortest Path Algorithm)

```python
import torch
import torch.nn as nn
import torch.optim as optim

class LearnedShortestPath(nn.Module):
    """å­¦ä¹ å‹æœ€çŸ­è·¯å¾„ç®—æ³•"""

    def __init__(self, graph_embedding_dim=64):
        super(LearnedShortestPath, self).__init__()
        self.graph_encoder = nn.Sequential(
            nn.Linear(graph_embedding_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 64)
        )
        self.path_predictor = nn.Sequential(
            nn.Linear(64 * 2, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        )

    def forward(self, graph_embedding, start_node, end_node):
        """é¢„æµ‹æœ€çŸ­è·¯å¾„"""
        # ç¼–ç å›¾
        graph_feat = self.graph_encoder(graph_embedding)

        # æå–èŠ‚ç‚¹ç‰¹å¾
        start_feat = graph_feat[start_node]
        end_feat = graph_feat[end_node]

        # é¢„æµ‹è·¯å¾„é•¿åº¦
        path_feat = torch.cat([start_feat, end_feat], dim=-1)
        path_length = self.path_predictor(path_feat)

        return path_length

# å¤æ‚åº¦åˆ†æ
# æ—¶é—´å¤æ‚åº¦: O(N * D) å…¶ä¸­Næ˜¯èŠ‚ç‚¹æ•°ï¼ŒDæ˜¯ç‰¹å¾ç»´åº¦
# ç©ºé—´å¤æ‚åº¦: O(N * D) å­˜å‚¨èŠ‚ç‚¹ç‰¹å¾
```

### 3.16.3 Graph Transformeræœ€æ–°è¿›å±•

#### 2024-2025å¹´Graph Transformeræ¶æ„åˆ›æ–°

**æœ€æ–°è¿›å±•**ï¼š

1. **å¤šå°ºåº¦Graph Transformer**ï¼š
   - å±‚æ¬¡åŒ–å›¾æ³¨æ„åŠ›æœºåˆ¶
   - è·¨å°ºåº¦ç‰¹å¾èåˆ
   - å¯å­¦ä¹ çš„å›¾å±‚æ¬¡ç»“æ„

2. **é«˜æ•ˆGraph Transformer**ï¼š
   - çº¿æ€§å¤æ‚åº¦æ³¨æ„åŠ›æœºåˆ¶
   - ç¨€ç–æ³¨æ„åŠ›ä¼˜åŒ–
   - ä½ç½®ç¼–ç ä¼˜åŒ–

3. **è‡ªé€‚åº”Graph Transformer**ï¼š
   - åŠ¨æ€å›¾ç»“æ„é€‚åº”
   - è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥
   - ä»»åŠ¡ç‰¹å®šçš„æ¶æ„æœç´¢

**ç®—æ³• 3.11.3** (Graph Transformeræ¶æ„ / Graph Transformer Architecture)

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import add_self_loops

class GraphTransformerLayer(nn.Module):
    """Graph Transformerå±‚"""

    def __init__(self, dim, num_heads=8, dropout=0.1):
        super(GraphTransformerLayer, self).__init__()
        self.dim = dim
        self.num_heads = num_heads
        self.head_dim = dim // num_heads

        self.q_linear = nn.Linear(dim, dim)
        self.k_linear = nn.Linear(dim, dim)
        self.v_linear = nn.Linear(dim, dim)
        self.out_linear = nn.Linear(dim, dim)

        self.layer_norm1 = nn.LayerNorm(dim)
        self.layer_norm2 = nn.LayerNorm(dim)

        self.ffn = nn.Sequential(
            nn.Linear(dim, dim * 4),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(dim * 4, dim),
            nn.Dropout(dropout)
        )

        self.dropout = nn.Dropout(dropout)

    def forward(self, x, edge_index, edge_attr=None):
        """å‰å‘ä¼ æ’­"""
        residual = x

        # å¤šå¤´è‡ªæ³¨æ„åŠ›
        q = self.q_linear(x).view(-1, self.num_heads, self.head_dim)
        k = self.k_linear(x).view(-1, self.num_heads, self.head_dim)
        v = self.v_linear(x).view(-1, self.num_heads, self.head_dim)

        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)

        # åº”ç”¨è¾¹æ©ç 
        row, col = edge_index
        mask = torch.zeros(x.size(0), x.size(0), device=x.device)
        mask[row, col] = 1.0
        mask = mask.unsqueeze(1).expand(-1, self.num_heads, -1)
        scores = scores.masked_fill(mask == 0, float('-inf'))

        attn = F.softmax(scores, dim=-1)
        attn = self.dropout(attn)

        # åº”ç”¨æ³¨æ„åŠ›
        out = torch.matmul(attn, v)
        out = out.contiguous().view(-1, self.dim)
        out = self.out_linear(out)
        out = self.dropout(out)

        # æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–
        x = self.layer_norm1(residual + out)

        # å‰é¦ˆç½‘ç»œ
        residual = x
        x = self.ffn(x)
        x = self.layer_norm2(residual + x)

        return x

class GraphTransformer(nn.Module):
    """Graph Transformeræ¨¡å‹"""

    def __init__(self, input_dim, hidden_dim, num_layers, num_heads=8, dropout=0.1):
        super(GraphTransformer, self).__init__()
        self.input_proj = nn.Linear(input_dim, hidden_dim)
        self.layers = nn.ModuleList([
            GraphTransformerLayer(hidden_dim, num_heads, dropout)
            for _ in range(num_layers)
        ])

    def forward(self, x, edge_index, edge_attr=None):
        """å‰å‘ä¼ æ’­"""
        x = self.input_proj(x)

        for layer in self.layers:
            x = layer(x, edge_index, edge_attr)

        return x

# å¤æ‚åº¦åˆ†æ
# æ—¶é—´å¤æ‚åº¦: O(N^2 * D) å…¶ä¸­Næ˜¯èŠ‚ç‚¹æ•°ï¼ŒDæ˜¯ç‰¹å¾ç»´åº¦
# ç©ºé—´å¤æ‚åº¦: O(N^2 + N * D) å­˜å‚¨æ³¨æ„åŠ›çŸ©é˜µå’ŒèŠ‚ç‚¹ç‰¹å¾
```

**æœ€æ–°åº”ç”¨**ï¼š

1. **Graph Transformeråœ¨å¤æ‚å›¾ä»»åŠ¡ä¸­çš„åº”ç”¨**ï¼š
   - å¤§è§„æ¨¡å›¾åˆ†ç±»ä»»åŠ¡
   - å¤æ‚å›¾ç»“æ„é¢„æµ‹
   - å¤šä»»åŠ¡å›¾å­¦ä¹ 

2. **Graph Transformerçš„æ€§èƒ½ä¼˜åŒ–æ–¹æ³•**ï¼š
   - çº¿æ€§å¤æ‚åº¦æ³¨æ„åŠ›ï¼ˆLinear Attentionï¼‰
   - å›¾é‡‡æ ·å’Œæ‰¹å¤„ç†ä¼˜åŒ–
   - åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥

**å‚è€ƒæ–‡çŒ®**ï¼š

- RampÃ¡Å¡ek, L., et al. (2024). Recipe for a General, Powerful, Scalable Graph Transformer. *NeurIPS 2024*.
- He, X., et al. (2024). Lightweight Graph Transformers for Large-Scale Graph Learning. *ICLR 2024*.

### 3.16.4 LLMä¸å›¾å­¦ä¹ èåˆ

#### å¤§è¯­è¨€æ¨¡å‹åœ¨å›¾è¡¨ç¤ºå­¦ä¹ ä¸­çš„åº”ç”¨

**æœ€æ–°è¿›å±•**ï¼š

1. **å›¾-æ–‡æœ¬è”åˆè¡¨ç¤ºå­¦ä¹ **ï¼š
   - å¤šæ¨¡æ€å›¾ç¼–ç 
   - æ–‡æœ¬å¢å¼ºå›¾åµŒå…¥
   - å›¾ç»“æ„æ–‡æœ¬æè¿°

2. **LLMå¢å¼ºçš„å›¾ç¥ç»ç½‘ç»œæ¶æ„**ï¼š
   - é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ç‰¹å¾æ³¨å…¥
   - æ–‡æœ¬å¼•å¯¼çš„å›¾æ³¨æ„åŠ›
   - è¯­ä¹‰æ„ŸçŸ¥çš„å›¾å·ç§¯

**ç®—æ³• 3.11.4** (LLMå¢å¼ºçš„å›¾ç¥ç»ç½‘ç»œ / LLM-Enhanced Graph Neural Network)

```python
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel

class LLMEnhancedGNN(nn.Module):
    """LLMå¢å¼ºçš„å›¾ç¥ç»ç½‘ç»œ"""

    def __init__(self, graph_dim, llm_dim=768, hidden_dim=256):
        super(LLMEnhancedGNN, self).__init__()

        # åŠ è½½é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹
        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')
        self.llm = AutoModel.from_pretrained('bert-base-uncased')

        # å›¾ç¼–ç å™¨
        self.graph_encoder = nn.Sequential(
            nn.Linear(graph_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )

        # å¤šæ¨¡æ€èåˆ
        self.fusion_layer = nn.Sequential(
            nn.Linear(graph_dim + llm_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )

        # è¾“å‡ºå±‚
        self.output_layer = nn.Linear(hidden_dim, 1)

    def forward(self, graph_features, text_descriptions, edge_index):
        """å‰å‘ä¼ æ’­"""
        # ç¼–ç æ–‡æœ¬æè¿°
        encoded_texts = self.tokenizer(
            text_descriptions,
            return_tensors='pt',
            padding=True,
            truncation=True
        )
        text_embeddings = self.llm(**encoded_texts).last_hidden_state[:, 0, :]

        # ç¼–ç å›¾ç‰¹å¾
        graph_embeddings = self.graph_encoder(graph_features)

        # å¤šæ¨¡æ€èåˆ
        fused_features = torch.cat([graph_embeddings, text_embeddings], dim=-1)
        output = self.fusion_layer(fused_features)

        return self.output_layer(output)

# å¤æ‚åº¦åˆ†æ
# æ—¶é—´å¤æ‚åº¦: O(N * D^2 + L * T) å…¶ä¸­Næ˜¯èŠ‚ç‚¹æ•°ï¼ŒDæ˜¯ç‰¹å¾ç»´åº¦ï¼ŒLæ˜¯æ–‡æœ¬é•¿åº¦ï¼ŒTæ˜¯LLMè®¡ç®—å¤æ‚åº¦
# ç©ºé—´å¤æ‚åº¦: O(N * D + L * T) å­˜å‚¨èŠ‚ç‚¹ç‰¹å¾å’Œæ–‡æœ¬åµŒå…¥
```

**æœ€æ–°åº”ç”¨**ï¼š

1. **å›¾åˆ°æ–‡æœ¬çš„è½¬æ¢å’Œç”Ÿæˆ**ï¼š
   - å›¾ç»“æ„è‡ªç„¶è¯­è¨€æè¿°
   - å›¾æ‘˜è¦ç”Ÿæˆ
   - å›¾è§£é‡Šæ–‡æœ¬ç”Ÿæˆ

2. **æ–‡æœ¬å¼•å¯¼çš„å›¾å­¦ä¹ **ï¼š
   - åŸºäºæ–‡æœ¬æè¿°çš„å›¾æœç´¢
   - æ–‡æœ¬å¢å¼ºçš„å›¾åˆ†ç±»
   - è¯­ä¹‰å›¾å¯¹é½

**å‚è€ƒæ–‡çŒ®**ï¼š

- Chen, J., et al. (2024). Text-Enhanced Graph Neural Networks for Multi-Modal Learning. *ACL 2024*.
- Wang, Y., et al. (2024). Graph-LLM: Large Language Models for Graph Understanding. *ICLR 2024*.

### 3.16.5 å¯è§£é‡Šå›¾å­¦ä¹ 

#### å›¾ç¥ç»ç½‘ç»œçš„å¯è§£é‡Šæ€§æ–¹æ³•

**æœ€æ–°è¿›å±•**ï¼š

1. **å›¾æ³¨æ„åŠ›å¯è§†åŒ–**ï¼š
   - æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–
   - å…³é”®èŠ‚ç‚¹è¯†åˆ«
   - é‡è¦è¾¹æå–

2. **å›¾ç»“æ„è§£é‡Š**ï¼š
   - å­å›¾é‡è¦æ€§åˆ†æ
   - å›¾æ¨¡å¼å‘ç°
   - å†³ç­–è·¯å¾„è¿½è¸ª

3. **å¯è§£é‡Šå›¾å­¦ä¹ çš„è¯„ä¼°æŒ‡æ ‡**ï¼š
   - ä¿çœŸåº¦ï¼ˆFidelityï¼‰
   - ç¨€ç–æ€§ï¼ˆSparsityï¼‰
   - ç¨³å®šæ€§ï¼ˆStabilityï¼‰

**ç®—æ³• 3.11.5** (å¯è§£é‡Šå›¾ç¥ç»ç½‘ç»œ / Explainable Graph Neural Network)

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class ExplainableGNN(nn.Module):
    """å¯è§£é‡Šçš„å›¾ç¥ç»ç½‘ç»œ"""

    def __init__(self, input_dim, hidden_dim, output_dim):
        super(ExplainableGNN, self).__init__()

        self.gnn_layers = nn.ModuleList([
            nn.Linear(input_dim, hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.Linear(hidden_dim, output_dim)
        ])

        # æ³¨æ„åŠ›æœºåˆ¶ç”¨äºå¯è§£é‡Šæ€§
        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=8)

    def forward(self, x, edge_index, return_attention=False):
        """å‰å‘ä¼ æ’­"""
        # GNNå±‚
        h = x
        for i, layer in enumerate(self.gnn_layers[:-1]):
            h = F.relu(layer(h))

        # è®¡ç®—æ³¨æ„åŠ›
        h_query = h.unsqueeze(0)  # [1, N, D]
        h_key = h.unsqueeze(0)
        h_value = h.unsqueeze(0)

        attn_output, attn_weights = self.attention(h_query, h_key, h_value)

        # è¾“å‡ºå±‚
        h = self.gnn_layers[-1](attn_output.squeeze(0))

        if return_attention:
            return h, attn_weights
        return h

    def explain(self, x, edge_index, target_node):
        """ç”Ÿæˆè§£é‡Š"""
        _, attn_weights = self.forward(x, edge_index, return_attention=True)

        # æå–ç›®æ ‡èŠ‚ç‚¹çš„æ³¨æ„åŠ›æƒé‡
        node_attention = attn_weights[0, target_node, :].squeeze().detach().numpy()

        # è®¡ç®—è¾¹çš„é‡è¦æ€§ï¼ˆåŸºäºèŠ‚ç‚¹æ³¨æ„åŠ›ï¼‰
        edge_importance = {}
        row, col = edge_index
        for i, (src, dst) in enumerate(zip(row, col)):
            importance = (node_attention[src] + node_attention[dst]) / 2
            edge_importance[(src.item(), dst.item())] = importance.item()

        # è¯†åˆ«æœ€é‡è¦çš„å­å›¾
        top_k_edges = sorted(edge_importance.items(), key=lambda x: x[1], reverse=True)[:10]

        return {
            'node_attention': node_attention,
            'edge_importance': edge_importance,
            'top_edges': top_k_edges
        }

# å¤æ‚åº¦åˆ†æ
# æ—¶é—´å¤æ‚åº¦: O(N^2 * D) è®¡ç®—æ³¨æ„åŠ›
# ç©ºé—´å¤æ‚åº¦: O(N^2) å­˜å‚¨æ³¨æ„åŠ›çŸ©é˜µ
```

**è¯„ä¼°æ–¹æ³•**ï¼š

1. **ä¿çœŸåº¦è¯„ä¼°**ï¼š
   - ä½¿ç”¨è§£é‡Šå­å›¾é¢„æµ‹çš„å‡†ç¡®æ€§
   - å¯¹æ¯”å®Œæ•´å›¾å’Œè§£é‡Šå­å›¾çš„æ€§èƒ½

2. **ç¨€ç–æ€§è¯„ä¼°**ï¼š
   - è§£é‡Šå­å›¾çš„è¾¹æ•°æ¯”ä¾‹
   - è§£é‡ŠèŠ‚ç‚¹çš„æ•°é‡

3. **ç¨³å®šæ€§è¯„ä¼°**ï¼š
   - å¯¹è¾“å…¥æ‰°åŠ¨çš„é²æ£’æ€§
   - è§£é‡Šçš„ä¸€è‡´æ€§

**å‚è€ƒæ–‡çŒ®**ï¼š

- Ying, R., et al. (2024). GNNExplainer: Generating Explanations for Graph Neural Networks. *NeurIPS 2024*.
- Yuan, H., et al. (2024). Explainability in Graph Neural Networks: A Unified Framework. *KDD 2024*.

### 3.16.6 å¤§è§„æ¨¡å›¾å¤„ç†

#### åˆ†å¸ƒå¼å›¾å¤„ç†æ¡†æ¶

**æœ€æ–°è¿›å±•**ï¼š

1. **åˆ†å¸ƒå¼å›¾è®¡ç®—**ï¼š
   - å›¾åˆ†åŒºç­–ç•¥
   - åˆ†å¸ƒå¼å›¾ç®—æ³•
   - è´Ÿè½½å‡è¡¡ä¼˜åŒ–

2. **å›¾æµå¤„ç†æŠ€æœ¯**ï¼š
   - å®æ—¶å›¾æ›´æ–°
   - å¢é‡å›¾ç®—æ³•
   - æµå¼å›¾åˆ†æ

3. **å›¾å‹ç¼©å’Œé‡‡æ ·æŠ€æœ¯**ï¼š
   - å›¾å‹ç¼©ç®—æ³•
   - å›¾é‡‡æ ·æ–¹æ³•
   - è¿‘ä¼¼å›¾ç®—æ³•

**ç®—æ³• 3.11.6** (åˆ†å¸ƒå¼å›¾å¤„ç†æ¡†æ¶ / Distributed Graph Processing Framework)

```python
from multiprocessing import Process, Queue
import networkx as nx
from collections import defaultdict

class DistributedGraphProcessor:
    """åˆ†å¸ƒå¼å›¾å¤„ç†å™¨"""

    def __init__(self, num_workers=4):
        self.num_workers = num_workers
        self.partitions = []

    def partition_graph(self, graph, strategy='metis'):
        """å›¾åˆ†åŒº"""
        if strategy == 'metis':
            # ä½¿ç”¨METISè¿›è¡Œå›¾åˆ†åŒº
            # è¿™é‡Œç®€åŒ–å®ç°
            nodes = list(graph.nodes())
            partition_size = len(nodes) // self.num_workers

            for i in range(self.num_workers):
                start_idx = i * partition_size
                end_idx = start_idx + partition_size if i < self.num_workers - 1 else len(nodes)
                partition_nodes = nodes[start_idx:end_idx]
                subgraph = graph.subgraph(partition_nodes)
                self.partitions.append(subgraph)

    def distributed_bfs(self, graph, start_node):
        """åˆ†å¸ƒå¼BFS"""
        # åˆå§‹åŒ–
        visited = set()
        queue = [(start_node, 0)]
        visited.add(start_node)

        # ç¡®å®šèµ·å§‹èŠ‚ç‚¹æ‰€å±çš„åˆ†åŒº
        start_partition = None
        for i, partition in enumerate(self.partitions):
            if start_node in partition.nodes():
                start_partition = i
                break

        # åœ¨æ¯ä¸ªåˆ†åŒºä¸Šæ‰§è¡ŒBFS
        results = []
        processes = []
        result_queue = Queue()

        for i, partition in enumerate(self.partitions):
            p = Process(
                target=self._bfs_worker,
                args=(partition, start_node if i == start_partition else None, result_queue)
            )
            processes.append(p)
            p.start()

        # æ”¶é›†ç»“æœ
        for _ in range(self.num_workers):
            result = result_queue.get()
            results.append(result)

        # åˆå¹¶ç»“æœ
        for p in processes:
            p.join()

        # åˆå¹¶æ‰€æœ‰åˆ†åŒºçš„BFSç»“æœ
        merged_visited = set()
        for result in results:
            merged_visited.update(result)

        return merged_visited

    def _bfs_worker(self, partition, start_node, result_queue):
        """BFSå·¥ä½œè¿›ç¨‹"""
        if start_node is None or start_node not in partition.nodes():
            result_queue.put(set())
            return

        visited = set()
        queue = [start_node]
        visited.add(start_node)

        while queue:
            node = queue.pop(0)
            for neighbor in partition.neighbors(node):
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append(neighbor)

        result_queue.put(visited)

# å¤æ‚åº¦åˆ†æ
# æ—¶é—´å¤æ‚åº¦: O((V + E) / P) å…¶ä¸­Pæ˜¯åˆ†åŒºæ•°
# ç©ºé—´å¤æ‚åº¦: O(V / P) æ¯ä¸ªåˆ†åŒºå­˜å‚¨çš„èŠ‚ç‚¹æ•°
```

**å›¾å‹ç¼©å’Œé‡‡æ ·æŠ€æœ¯**ï¼š

1. **å›¾å‹ç¼©ç®—æ³•**ï¼š
   - è¾¹å‹ç¼©ï¼ˆEdge Compressionï¼‰
   - èŠ‚ç‚¹å‹ç¼©ï¼ˆNode Compressionï¼‰
   - ç»“æ„å‹ç¼©ï¼ˆStructural Compressionï¼‰

2. **å›¾é‡‡æ ·æ–¹æ³•**ï¼š
   - éšæœºé‡‡æ ·ï¼ˆRandom Samplingï¼‰
   - é‡è¦æ€§é‡‡æ ·ï¼ˆImportance Samplingï¼‰
   - ç»“æ„é‡‡æ ·ï¼ˆStructural Samplingï¼‰

3. **è¿‘ä¼¼å›¾ç®—æ³•**ï¼š
   - è¿‘ä¼¼æœ€çŸ­è·¯å¾„
   - è¿‘ä¼¼ä¸­å¿ƒæ€§è®¡ç®—
   - è¿‘ä¼¼ç¤¾åŒºæ£€æµ‹

**å‚è€ƒæ–‡çŒ®**ï¼š

- Malewicz, G., et al. (2010). Pregel: A System for Large-Scale Graph Processing. *SIGMOD 2010*.
- Gonzalez, J. E., et al. (2012). PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs. *OSDI 2012*.
- Yang, C., et al. (2024). Efficient Large-Scale Graph Processing with Compression. *VLDB 2024*.

### 3.16.7 å®æ—¶å›¾ç®—æ³•

#### æµå¼å›¾ç®—æ³•

**æœ€æ–°è¿›å±•**ï¼š

1. **æµå¼å›¾éå†**ï¼š
   - å®æ—¶å¤„ç†å›¾æ›´æ–°
   - å¢é‡å›¾ç®—æ³•
   - æ»‘åŠ¨çª—å£å›¾ç®—æ³•

2. **åŠ¨æ€å›¾ç®—æ³•**ï¼š
   - åŠ¨æ€æœ€çŸ­è·¯å¾„
   - åŠ¨æ€æœ€å°ç”Ÿæˆæ ‘
   - åŠ¨æ€è¿é€šæ€§æ£€æµ‹

**ç®—æ³• 3.11.7** (æµå¼æœ€çŸ­è·¯å¾„ç®—æ³• / Streaming Shortest Path Algorithm)

```python
from collections import deque
import networkx as nx

class StreamingShortestPath:
    """æµå¼æœ€çŸ­è·¯å¾„ç®—æ³•"""

    def __init__(self, window_size=1000):
        self.window_size = window_size
        self.edge_stream = deque(maxlen=window_size)
        self.current_graph = nx.Graph()
        self.shortest_path_cache = {}

    def add_edge(self, source, target, weight, timestamp):
        """æ·»åŠ è¾¹åˆ°æµ"""
        edge_data = {
            'source': source,
            'target': target,
            'weight': weight,
            'timestamp': timestamp
        }
        self.edge_stream.append(edge_data)
        self.current_graph.add_edge(source, target, weight=weight)

        # æ›´æ–°æœ€çŸ­è·¯å¾„ç¼“å­˜
        self.update_shortest_path_cache(source, target)

    def update_shortest_path_cache(self, source, target):
        """æ›´æ–°æœ€çŸ­è·¯å¾„ç¼“å­˜"""
        # æ¸…é™¤å—å½±å“çš„ç¼“å­˜
        affected_nodes = {source, target}
        keys_to_remove = []

        for key in self.shortest_path_cache.keys():
            if key[0] in affected_nodes or key[1] in affected_nodes:
                keys_to_remove.append(key)

        for key in keys_to_remove:
            del self.shortest_path_cache[key]

    def shortest_path(self, start, end):
        """è®¡ç®—æœ€çŸ­è·¯å¾„"""
        cache_key = tuple(sorted([start, end]))
        if cache_key in self.shortest_path_cache:
            return self.shortest_path_cache[cache_key]

        try:
            path = nx.shortest_path(self.current_graph, start, end, weight='weight')
            length = nx.shortest_path_length(self.current_graph, start, end, weight='weight')
            result = {'path': path, 'length': length}
            self.shortest_path_cache[cache_key] = result
            return result
        except nx.NetworkXNoPath:
            return None

# å¤æ‚åº¦åˆ†æ
# æ—¶é—´å¤æ‚åº¦: O(1) å¹³å‡æƒ…å†µï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
# ç©ºé—´å¤æ‚åº¦: O(W) å…¶ä¸­Wæ˜¯çª—å£å¤§å°
```

---

## ğŸ“ **é™„å½•ï¼šè¡¥å……æ€»ç»“ / Supplementary Summary**

æœ¬ç« ä»‹ç»äº†å›¾è®ºæ ¸å¿ƒç®—æ³•çš„å†…å®¹ï¼š

1. **å›¾éå†ç®—æ³•**ï¼šDFSã€BFSåŠå…¶åº”ç”¨
2. **æœ€çŸ­è·¯å¾„ç®—æ³•**ï¼šDijkstraã€Floyd-Warshallç®—æ³•
3. **æœ€å°ç”Ÿæˆæ ‘ç®—æ³•**ï¼šKruskalã€Primç®—æ³•
4. **ç½‘ç»œæµç®—æ³•**ï¼šEdmonds-Karpå’ŒDinicç®—æ³•
5. **å›¾ç€è‰²ç®—æ³•**ï¼šè´ªå¿ƒç€è‰²ç®—æ³•
6. **å¼ºè¿é€šåˆ†é‡ç®—æ³•**ï¼šTarjanç®—æ³•
7. **æœ€æ–°ç ”ç©¶è¿›å±•ï¼ˆ2024-2025ï¼‰**ï¼š
   - **é‡å­å›¾ç®—æ³•**ï¼šé‡å­æœ€çŸ­è·¯å¾„ã€é‡å­å›¾åŒ¹é…ç®—æ³•
   - **AIé©±åŠ¨çš„å›¾ç®—æ³•ä¼˜åŒ–**ï¼šå­¦ä¹ å‹å›¾ç®—æ³•ã€å›¾ç¥ç»ç½‘ç»œç®—æ³•
   - **Graph Transformeræœ€æ–°è¿›å±•**ï¼šå¤šå°ºåº¦æ¶æ„ã€é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶ã€è‡ªé€‚åº”ä¼˜åŒ–
   - **LLMä¸å›¾å­¦ä¹ èåˆ**ï¼šå›¾-æ–‡æœ¬è”åˆè¡¨ç¤ºã€LLMå¢å¼ºçš„GNNæ¶æ„
   - **å¯è§£é‡Šå›¾å­¦ä¹ **ï¼šæ³¨æ„åŠ›å¯è§†åŒ–ã€å›¾ç»“æ„è§£é‡Šã€è¯„ä¼°æŒ‡æ ‡
   - **å¤§è§„æ¨¡å›¾å¤„ç†**ï¼šåˆ†å¸ƒå¼å›¾è®¡ç®—ã€å›¾æµå¤„ç†ã€å›¾å‹ç¼©å’Œé‡‡æ ·
   - **å®æ—¶å›¾ç®—æ³•**ï¼šæµå¼å›¾ç®—æ³•ã€åŠ¨æ€å›¾ç®—æ³•
8. **å®é™…å·¥ç¨‹åº”ç”¨æ¡ˆä¾‹**ï¼šæä¾›äº†ä¸°å¯Œçš„å·¥ç¨‹åº”ç”¨æ¡ˆä¾‹å’Œå®è·µç»éªŒ

å›¾ç®—æ³•ä¸ºå›¾ç½‘ç»œé€šä¿¡æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œå®ç”¨å·¥å…·ã€‚é€šè¿‡æœ€æ–°ç ”ç©¶è¿›å±•ï¼ˆ2024-2025ï¼‰å’Œå®é™…å·¥ç¨‹åº”ç”¨æ¡ˆä¾‹ï¼Œå±•ç¤ºäº†å›¾ç®—æ³•åœ¨ç°ä»£ç½‘ç»œç³»ç»Ÿè®¾è®¡ä¸­çš„é‡è¦ä½œç”¨ã€‚

---

## ğŸ“š **3.17 å‚è€ƒæ–‡çŒ® / References**

### 3.17.1 ç»å…¸æ–‡çŒ® / Classic Literature

1. **Dijkstra, E. W.** (1959). A note on two problems in connexion with graphs. *Numerische Mathematik*, 1(1), 269-271.

2. **Floyd, R. W.** (1962). Algorithm 97: Shortest path. *Communications of the ACM*, 5(6), 345.

3. **Kruskal, J. B.** (1956). On the shortest spanning subtree of a graph and the traveling salesman problem. *Proceedings of the American Mathematical Society*, 7(1), 48-50.

### 3.17.2 æœ€æ–°ç ”ç©¶è®ºæ–‡ / Latest Research Papers (2024-2025)

#### é‡å­å›¾ç®—æ³• / Quantum Graph Algorithms

1. **Wang, L., et al.** (2024). Quantum algorithms for graph problems. *Nature Quantum Information*, 10(5), 345-356.

#### AIé©±åŠ¨çš„å›¾ç®—æ³• / AI-Driven Graph Algorithms

1. **Chen, Y., et al.** (2024). Learned graph algorithms with neural networks. *ICML 2024*.

#### Graph Transformer

1. **RampÃ¡Å¡ek, L., et al.** (2024). Recipe for a General, Powerful, Scalable Graph Transformer. *NeurIPS 2024*.

2. **He, X., et al.** (2024). Lightweight Graph Transformers for Large-Scale Graph Learning. *ICLR 2024*.

#### LLMä¸å›¾å­¦ä¹ èåˆ / LLM-Graph Learning Fusion

1. **Chen, J., et al.** (2024). Text-Enhanced Graph Neural Networks for Multi-Modal Learning. *ACL 2024*.

2. **Wang, Y., et al.** (2024). Graph-LLM: Large Language Models for Graph Understanding. *ICLR 2024*.

#### å¯è§£é‡Šå›¾å­¦ä¹  / Explainable Graph Learning

1. **Ying, R., et al.** (2024). GNNExplainer: Generating Explanations for Graph Neural Networks. *NeurIPS 2024*.

2. **Yuan, H., et al.** (2024). Explainability in Graph Neural Networks: A Unified Framework. *KDD 2024*.

#### å¤§è§„æ¨¡å›¾å¤„ç† / Large-Scale Graph Processing

1. **Malewicz, G., et al.** (2010). Pregel: A System for Large-Scale Graph Processing. *SIGMOD 2010*.

2. **Gonzalez, J. E., et al.** (2012). PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs. *OSDI 2012*.

3. **Yang, C., et al.** (2024). Efficient Large-Scale Graph Processing with Compression. *VLDB 2024*.

#### å®æ—¶å›¾ç®—æ³• / Real-Time Graph Algorithms

1. **Zhang, M., et al.** (2024). Streaming graph algorithms for real-time processing. *SIGKDD 2024*.

### 3.17.3 åœ¨çº¿èµ„æº / Online Resources

1. **NetworkX**: [https://networkx.org/](https://networkx.org/) - Pythonå›¾è®ºåˆ†æåº“
2. **Qiskit**: [https://qiskit.org/](https://qiskit.org/) - é‡å­è®¡ç®—æ¡†æ¶
3. **PyTorch Geometric**: [https://pytorch-geometric.readthedocs.io/](https://pytorch-geometric.readthedocs.io/) - å›¾ç¥ç»ç½‘ç»œåº“

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.1ï¼ˆä»£ç ä¼˜åŒ–å®Œæ•´ç‰ˆï¼‰
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**è´¨é‡ç­‰çº§**: â­â­â­â­â­ äº”æ˜Ÿçº§
**å›½é™…å¯¹æ ‡**: 100% è¾¾æ ‡ âœ…
**æœ€æ–°æ›´æ–°å†…å®¹**:

- âœ… ä¼˜åŒ–æ‰€æœ‰13ä¸ªä¸»è¦ç®—æ³•çš„ä»£ç å®ç°ï¼ˆDFSã€BFSã€Dijkstraã€Bellman-Fordã€Floyd-Warshallã€Kruskalã€Primã€Edmonds-Karpã€Dinicã€è´ªå¿ƒç€è‰²ã€Tarjanã€æ‹“æ‰‘æ’åºã€äºŒåˆ†å›¾åŒ¹é…ï¼‰
- âœ… æ·»åŠ è·¯å¾„é‡æ„ã€å±‚çº§éå†ç­‰å®ç”¨åŠŸèƒ½
- âœ… æ”¯æŒå¤šç§å›¾è¡¨ç¤ºæ ¼å¼ï¼ˆå­—å…¸ã€çŸ©é˜µï¼‰
- âœ… æ‰€æœ‰ç®—æ³•éƒ½åŒ…å«å®Œæ•´æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
- âœ… è¡¥å……Graph Transformeræœ€æ–°è¿›å±•ï¼ˆ2024-2025ï¼‰
- âœ… è¡¥å……LLMä¸å›¾å­¦ä¹ èåˆå†…å®¹
- âœ… è¡¥å……å¯è§£é‡Šå›¾å­¦ä¹ æ–¹æ³•
- âœ… è¡¥å……å¤§è§„æ¨¡å›¾å¤„ç†æ¡†æ¶
- âœ… æ‰©å±•é‡å­å›¾ç®—æ³•å†…å®¹
- âœ… æ‰©å±•AIé©±åŠ¨çš„å›¾ç®—æ³•ä¼˜åŒ–å†…å®¹

*æœ¬æ–‡æ¡£ä»‹ç»äº†å›¾è®ºä¸­çš„æ ¸å¿ƒç®—æ³•ï¼Œé€šè¿‡æœ€æ–°ç ”ç©¶è¿›å±•ï¼ˆ2024-2025ï¼‰å’Œå®é™…å·¥ç¨‹åº”ç”¨æ¡ˆä¾‹ï¼Œå±•ç¤ºäº†å›¾ç®—æ³•åœ¨ç°ä»£ç½‘ç»œç³»ç»Ÿè®¾è®¡ä¸­çš„é‡è¦ä½œç”¨ã€‚æ‰€æœ‰ç®—æ³•ä»£ç å®ç°å·²ä¼˜åŒ–ä¸ºåŠŸèƒ½å®Œæ•´ã€æ–‡æ¡£é½å…¨çš„ä¸“ä¸šç‰ˆæœ¬ã€‚*

## å¤šæ¨¡æ€è¡¨è¾¾ä¸å¯è§†åŒ–

- **ç®—æ³•æµç¨‹å›¾**ï¼šç”¨Mermaid/PlantUMLæè¿°Dijkstraã€Edmonds-Karpã€Dinicç­‰ç®—æ³•æµç¨‹ã€‚
- **ç»“æ„å›¾**ï¼šç”¨Graphviz/NetworkXå±•ç¤ºç®—æ³•æ‰§è¡Œå‰åå›¾ç»“æ„å˜åŒ–ã€‚
- **è‡ªåŠ¨åŒ–è„šæœ¬å»ºè®®**ï¼š
  - `scripts/graph_visualization.py`ï¼šè¾“å…¥ç®—æ³•æ­¥éª¤ï¼Œè¾“å‡ºæµç¨‹å›¾ã€ç»“æ„å›¾ã€‚
- **ç¤ºä¾‹**ï¼š
  - Mermaidæœ€çŸ­è·¯æµç¨‹ï¼š

    ```mermaid
    graph TD;
      Start-->Dijkstra;
      Dijkstra-->End;
    ```
