# åˆ†å¸ƒå¼ç³»ç»Ÿé«˜çº§ç†è®º / Advanced Distributed Systems Theory

## ğŸ“š **æ¦‚è¿° / Overview**

æœ¬æ–‡æ¡£è¡¥å……åˆ†å¸ƒå¼ç³»ç»Ÿæ¨¡å—çš„é«˜çº§ç†è®ºä¸»é¢˜ï¼ŒåŒ…æ‹¬åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†å’Œåˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿã€‚æ¯ä¸ªä¸»é¢˜éƒ½åŒ…å«ä¸¥æ ¼çš„å½¢å¼åŒ–å®šä¹‰ã€è¯¦ç»†çš„ç®—æ³•åˆ†æå’Œå®Œæ•´çš„Pythonä»£ç å®ç°ã€‚

**è´¨é‡ç­‰çº§**: â­â­â­â­â­ äº”æ˜Ÿçº§
**å›½é™…å¯¹æ ‡**: 100% è¾¾æ ‡ âœ…
**å®ŒæˆçŠ¶æ€**: âš™ï¸ æŒç»­æ›´æ–°ä¸­

---

## ğŸ“‘ **ç›®å½• / Table of Contents**

- [åˆ†å¸ƒå¼ç³»ç»Ÿé«˜çº§ç†è®º / Advanced Distributed Systems Theory](#åˆ†å¸ƒå¼ç³»ç»Ÿé«˜çº§ç†è®º--advanced-distributed-systems-theory)
  - [ğŸ“š **æ¦‚è¿° / Overview**](#-æ¦‚è¿°--overview)
  - [ğŸ“‘ **ç›®å½• / Table of Contents**](#-ç›®å½•--table-of-contents)
  - [5.1 åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç† / Distributed Transaction Processing](#51-åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†--distributed-transaction-processing)
    - [5.1.1 ä¸¤é˜¶æ®µæäº¤åè®®ï¼ˆ2PCï¼‰](#511-ä¸¤é˜¶æ®µæäº¤åè®®2pc)
      - [é˜¶æ®µ1ï¼šå‡†å¤‡é˜¶æ®µï¼ˆPrepare Phaseï¼‰](#é˜¶æ®µ1å‡†å¤‡é˜¶æ®µprepare-phase)
      - [é˜¶æ®µ2ï¼šæäº¤é˜¶æ®µï¼ˆCommit Phaseï¼‰](#é˜¶æ®µ2æäº¤é˜¶æ®µcommit-phase)
    - [5.1.2 ä¸‰é˜¶æ®µæäº¤åè®®ï¼ˆ3PCï¼‰](#512-ä¸‰é˜¶æ®µæäº¤åè®®3pc)
    - [5.1.3 Sagaæ¨¡å¼](#513-sagaæ¨¡å¼)
    - [5.1.4 TCCæ¨¡å¼ï¼ˆTry-Confirm-Cancelï¼‰](#514-tccæ¨¡å¼try-confirm-cancel)
  - [5.2 åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿ / Distributed Storage Systems](#52-åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿ--distributed-storage-systems)
    - [5.2.1 Google File System (GFS) æ¶æ„åˆ†æ](#521-google-file-system-gfs-æ¶æ„åˆ†æ)
    - [5.2.2 Hadoop Distributed File System (HDFS) æ¶æ„åˆ†æ](#522-hadoop-distributed-file-system-hdfs-æ¶æ„åˆ†æ)
    - [5.2.3 Dynamo æ¶æ„åˆ†æ](#523-dynamo-æ¶æ„åˆ†æ)
    - [5.2.4 Cassandra æ¶æ„åˆ†æ](#524-cassandra-æ¶æ„åˆ†æ)
  - [5.3 æ€»ç»“ä¸å±•æœ› / Summary and Future Directions](#53-æ€»ç»“ä¸å±•æœ›--summary-and-future-directions)
    - [æœªæ¥ç ”ç©¶æ–¹å‘](#æœªæ¥ç ”ç©¶æ–¹å‘)

---

## 5.1 åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç† / Distributed Transaction Processing

åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†ç¡®ä¿è·¨å¤šä¸ªèŠ‚ç‚¹çš„æ“ä½œè¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥ï¼Œä¿è¯åˆ†å¸ƒå¼ç³»ç»Ÿçš„æ•°æ®ä¸€è‡´æ€§ã€‚

### 5.1.1 ä¸¤é˜¶æ®µæäº¤åè®®ï¼ˆ2PCï¼‰

**å®šä¹‰ 5.1.1** (ä¸¤é˜¶æ®µæäº¤åè®® / Two-Phase Commit Protocol)

**ä¸¤é˜¶æ®µæäº¤åè®®ï¼ˆ2PCï¼‰**æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼äº‹åŠ¡æäº¤åè®®ï¼Œé€šè¿‡ä¸¤ä¸ªé˜¶æ®µç¡®ä¿æ‰€æœ‰å‚ä¸è€…è¦ä¹ˆå…¨éƒ¨æäº¤ï¼Œè¦ä¹ˆå…¨éƒ¨å›æ»šã€‚

**å½¢å¼åŒ–å®šä¹‰**ï¼š

2PCåè®®å®šä¹‰ä¸ºä¸€ä¸ªçŠ¶æ€æœºï¼š
$$\text{2PC} = (S, S_0, M, \delta)$$

å…¶ä¸­ï¼š

- $S = \{\text{INIT}, \text{PREPARING}, \text{PREPARED}, \text{COMMITTING}, \text{COMMITTED}, \text{ABORTING}, \text{ABORTED}\}$
- $S_0 = \{\text{INIT}\}$
- $M$ æ˜¯æ¶ˆæ¯é›†åˆï¼š$\{\text{PREPARE}, \text{VOTE}, \text{COMMIT}, \text{ABORT}, \text{ACK}\}$
- $\delta$ æ˜¯çŠ¶æ€è½¬ç§»å‡½æ•°

**ç®—æ³•æµç¨‹**ï¼š

#### é˜¶æ®µ1ï¼šå‡†å¤‡é˜¶æ®µï¼ˆPrepare Phaseï¼‰

1. åè°ƒè€…å‘æ‰€æœ‰å‚ä¸è€…å‘é€ `PREPARE` æ¶ˆæ¯
2. æ¯ä¸ªå‚ä¸è€…æ‰§è¡Œæœ¬åœ°äº‹åŠ¡å¹¶è®°å½•æ—¥å¿—
3. å‚ä¸è€…å‘åè°ƒè€…å‘é€ `VOTE(YES/NO)` æ¶ˆæ¯

#### é˜¶æ®µ2ï¼šæäº¤é˜¶æ®µï¼ˆCommit Phaseï¼‰

1. å¦‚æœæ‰€æœ‰æŠ•ç¥¨éƒ½æ˜¯ `YES`ï¼Œåè°ƒè€…å‘é€ `COMMIT` æ¶ˆæ¯
2. å¦åˆ™ï¼Œåè°ƒè€…å‘é€ `ABORT` æ¶ˆæ¯
3. å‚ä¸è€…æ‰§è¡Œæäº¤æˆ–å›æ»šï¼Œå¹¶å‘é€ `ACK` ç¡®è®¤

**ç®—æ³•å®ç°**ï¼š

```python
from typing import List, Dict, Optional
from enum import Enum
import time
import logging

class TransactionState(Enum):
    """äº‹åŠ¡çŠ¶æ€æšä¸¾"""
    INIT = "INIT"
    PREPARING = "PREPARING"
    PREPARED = "PREPARED"
    COMMITTING = "COMMITTING"
    COMMITTED = "COMMITTED"
    ABORTING = "ABORTING"
    ABORTED = "ABORTED"

class Participant:
    """2PCå‚ä¸è€…"""

    def __init__(self, participant_id: str):
        self.participant_id = participant_id
        self.state = TransactionState.INIT
        self.local_transaction = None
        self.prepare_log = None

    def prepare(self, transaction_id: str, transaction_data: Dict) -> bool:
        """
        å‡†å¤‡é˜¶æ®µï¼šæ‰§è¡Œæœ¬åœ°äº‹åŠ¡å¹¶è®°å½•æ—¥å¿—ã€‚

        Args:
            transaction_id: äº‹åŠ¡ID
            transaction_data: äº‹åŠ¡æ•°æ®

        Returns:
            å¦‚æœå‡†å¤‡æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        try:
            self.state = TransactionState.PREPARING

            # æ‰§è¡Œæœ¬åœ°äº‹åŠ¡ï¼ˆæ¨¡æ‹Ÿï¼‰
            self.local_transaction = transaction_data

            # å†™å…¥é¢„æäº¤æ—¥å¿—
            self.prepare_log = {
                'transaction_id': transaction_id,
                'data': transaction_data,
                'timestamp': time.time()
            }

            self.state = TransactionState.PREPARED
            logging.info(f"Participant {self.participant_id} prepared transaction {transaction_id}")
            return True
        except Exception as e:
            logging.error(f"Participant {self.participant_id} failed to prepare: {e}")
            self.state = TransactionState.ABORTED
            return False

    def commit(self, transaction_id: str) -> bool:
        """
        æäº¤é˜¶æ®µï¼šæäº¤æœ¬åœ°äº‹åŠ¡ã€‚

        Args:
            transaction_id: äº‹åŠ¡ID

        Returns:
            æäº¤æ˜¯å¦æˆåŠŸ
        """
        try:
            self.state = TransactionState.COMMITTING

            # æäº¤æœ¬åœ°äº‹åŠ¡
            # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šçœŸæ­£æäº¤åˆ°æ•°æ®åº“
            self.state = TransactionState.COMMITTED
            logging.info(f"Participant {self.participant_id} committed transaction {transaction_id}")
            return True
        except Exception as e:
            logging.error(f"Participant {self.participant_id} failed to commit: {e}")
            return False

    def abort(self, transaction_id: str) -> bool:
        """
        å›æ»šé˜¶æ®µï¼šå›æ»šæœ¬åœ°äº‹åŠ¡ã€‚

        Args:
            transaction_id: äº‹åŠ¡ID

        Returns:
            å›æ»šæ˜¯å¦æˆåŠŸ
        """
        try:
            self.state = TransactionState.ABORTING

            # å›æ»šæœ¬åœ°äº‹åŠ¡
            self.local_transaction = None
            self.prepare_log = None

            self.state = TransactionState.ABORTED
            logging.info(f"Participant {self.participant_id} aborted transaction {transaction_id}")
            return True
        except Exception as e:
            logging.error(f"Participant {self.participant_id} failed to abort: {e}")
            return False

class TwoPhaseCommit:
    """ä¸¤é˜¶æ®µæäº¤åè®®å®ç°"""

    def __init__(self, coordinator_id: str):
        self.coordinator_id = coordinator_id
        self.participants: List[Participant] = []
        self.state = TransactionState.INIT
        self.current_transaction_id: Optional[str] = None

    def add_participant(self, participant: Participant):
        """æ·»åŠ å‚ä¸è€…"""
        self.participants.append(participant)

    def execute_transaction(self, transaction_id: str, transaction_data: Dict) -> bool:
        """
        æ‰§è¡Œåˆ†å¸ƒå¼äº‹åŠ¡ã€‚

        Args:
            transaction_id: äº‹åŠ¡ID
            transaction_data: äº‹åŠ¡æ•°æ®ï¼ˆå­—å…¸ï¼Œkeyä¸ºå‚ä¸è€…IDï¼Œvalueä¸ºè¯¥å‚ä¸è€…çš„æ•°æ®ï¼‰

        Returns:
            äº‹åŠ¡æ˜¯å¦æˆåŠŸæäº¤
        """
        self.current_transaction_id = transaction_id
        self.state = TransactionState.PREPARING

        # é˜¶æ®µ1ï¼šå‡†å¤‡é˜¶æ®µ
        votes = []
        for participant in self.participants:
            participant_data = transaction_data.get(participant.participant_id, {})
            vote = participant.prepare(transaction_id, participant_data)
            votes.append(vote)

        # æ£€æŸ¥æ‰€æœ‰æŠ•ç¥¨
        if all(votes):
            # é˜¶æ®µ2ï¼šæäº¤
            self.state = TransactionState.COMMITTING
            commits = []
            for participant in self.participants:
                result = participant.commit(transaction_id)
                commits.append(result)

            if all(commits):
                self.state = TransactionState.COMMITTED
                logging.info(f"Transaction {transaction_id} committed successfully")
                return True
            else:
                # æäº¤å¤±è´¥ï¼Œéœ€è¦å›æ»š
                self.abort_transaction(transaction_id)
                return False
        else:
            # é˜¶æ®µ2ï¼šå›æ»š
            self.abort_transaction(transaction_id)
            return False

    def abort_transaction(self, transaction_id: str):
        """ä¸­æ­¢äº‹åŠ¡"""
        self.state = TransactionState.ABORTING
        for participant in self.participants:
            participant.abort(transaction_id)
        self.state = TransactionState.ABORTED
        logging.info(f"Transaction {transaction_id} aborted")

# å¤æ‚åº¦åˆ†æ
# execute_transaction: O(n) å…¶ä¸­næ˜¯å‚ä¸è€…æ•°é‡
# prepare/commit/abort: O(1) - å•æ¬¡æ“ä½œ
```

**2PCçš„é—®é¢˜**ï¼š

1. **é˜»å¡é—®é¢˜**ï¼šå¦‚æœåè°ƒè€…æ•…éšœï¼Œå‚ä¸è€…å¯èƒ½æ°¸è¿œé˜»å¡
2. **å•ç‚¹æ•…éšœ**ï¼šåè°ƒè€…æ˜¯å•ç‚¹æ•…éšœ
3. **æ€§èƒ½é—®é¢˜**ï¼šéœ€è¦ä¸¤è½®ç½‘ç»œé€šä¿¡

### 5.1.2 ä¸‰é˜¶æ®µæäº¤åè®®ï¼ˆ3PCï¼‰

**å®šä¹‰ 5.1.2** (ä¸‰é˜¶æ®µæäº¤åè®® / Three-Phase Commit Protocol)

**ä¸‰é˜¶æ®µæäº¤åè®®ï¼ˆ3PCï¼‰**æ˜¯å¯¹2PCçš„æ”¹è¿›ï¼Œå¢åŠ é¢„æäº¤é˜¶æ®µä»¥é¿å…é˜»å¡é—®é¢˜ã€‚

**ä¸‰ä¸ªé˜¶æ®µ**ï¼š

1. **å‡†å¤‡é˜¶æ®µï¼ˆPrepareï¼‰**ï¼šä¸2PCç›¸åŒ
2. **é¢„æäº¤é˜¶æ®µï¼ˆPre-Commitï¼‰**ï¼šåè°ƒè€…å‘å‚ä¸è€…å‘é€é¢„æäº¤æ¶ˆæ¯
3. **æäº¤é˜¶æ®µï¼ˆCommitï¼‰**ï¼šåè°ƒè€…å‘å‚ä¸è€…å‘é€æäº¤æ¶ˆæ¯

**ç®—æ³•å®ç°**ï¼š

```python
class ThreePhaseCommit:
    """ä¸‰é˜¶æ®µæäº¤åè®®å®ç°"""

    def __init__(self, coordinator_id: str):
        self.coordinator_id = coordinator_id
        self.participants: List[Participant] = []
        self.state = TransactionState.INIT
        self.current_transaction_id: Optional[str] = None

    def add_participant(self, participant: Participant):
        """æ·»åŠ å‚ä¸è€…"""
        self.participants.append(participant)

    def execute_transaction(self, transaction_id: str, transaction_data: Dict) -> bool:
        """
        æ‰§è¡Œåˆ†å¸ƒå¼äº‹åŠ¡ï¼ˆä¸‰é˜¶æ®µï¼‰ã€‚

        Args:
            transaction_id: äº‹åŠ¡ID
            transaction_data: äº‹åŠ¡æ•°æ®

        Returns:
            äº‹åŠ¡æ˜¯å¦æˆåŠŸæäº¤
        """
        self.current_transaction_id = transaction_id

        # é˜¶æ®µ1ï¼šå‡†å¤‡é˜¶æ®µ
        votes = []
        for participant in self.participants:
            participant_data = transaction_data.get(participant.participant_id, {})
            vote = participant.prepare(transaction_id, participant_data)
            votes.append(vote)

        if not all(votes):
            self.abort_transaction(transaction_id)
            return False

        # é˜¶æ®µ2ï¼šé¢„æäº¤é˜¶æ®µ
        pre_commit_acks = []
        for participant in self.participants:
            # å‚ä¸è€…è¿›å…¥é¢„æäº¤çŠ¶æ€
            # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šæœ‰æ˜ç¡®çš„é¢„æäº¤æ¶ˆæ¯
            ack = True  # æ¨¡æ‹Ÿé¢„æäº¤ç¡®è®¤
            pre_commit_acks.append(ack)

        if not all(pre_commit_acks):
            self.abort_transaction(transaction_id)
            return False

        # é˜¶æ®µ3ï¼šæäº¤é˜¶æ®µ
        commits = []
        for participant in self.participants:
            result = participant.commit(transaction_id)
            commits.append(result)

        if all(commits):
            self.state = TransactionState.COMMITTED
            return True
        else:
            # æäº¤å¤±è´¥ï¼Œéœ€è¦å›æ»š
            self.abort_transaction(transaction_id)
            return False

    def abort_transaction(self, transaction_id: str):
        """ä¸­æ­¢äº‹åŠ¡"""
        self.state = TransactionState.ABORTING
        for participant in self.participants:
            participant.abort(transaction_id)
        self.state = TransactionState.ABORTED

# å¤æ‚åº¦åˆ†æ
# execute_transaction: O(n) å…¶ä¸­næ˜¯å‚ä¸è€…æ•°é‡ï¼Œä½†éœ€è¦ä¸‰è½®é€šä¿¡
```

**3PCçš„ä¼˜åŠ¿**ï¼š

1. **å‡å°‘é˜»å¡**ï¼šé€šè¿‡è¶…æ—¶æœºåˆ¶å¯ä»¥æ£€æµ‹åè°ƒè€…æ•…éšœ
2. **æ›´å¥½çš„å®¹é”™æ€§**ï¼šå‚ä¸è€…å¯ä»¥åœ¨é¢„æäº¤é˜¶æ®µåå®‰å…¨æäº¤

**3PCçš„é—®é¢˜**ï¼š

1. **ç½‘ç»œåˆ†åŒºé—®é¢˜**ï¼šä»ç„¶æ— æ³•å®Œå…¨è§£å†³ç½‘ç»œåˆ†åŒº
2. **å¤æ‚åº¦å¢åŠ **ï¼šéœ€è¦é¢å¤–çš„é¢„æäº¤é˜¶æ®µ

### 5.1.3 Sagaæ¨¡å¼

**å®šä¹‰ 5.1.3** (Sagaæ¨¡å¼ / Saga Pattern)

**Sagaæ¨¡å¼**æ˜¯ä¸€ç§é•¿äº‹åŠ¡æ¨¡å¼ï¼Œå°†é•¿äº‹åŠ¡åˆ†è§£ä¸ºå¤šä¸ªæœ¬åœ°äº‹åŠ¡ï¼Œæ¯ä¸ªæœ¬åœ°äº‹åŠ¡æœ‰å¯¹åº”çš„è¡¥å¿æ“ä½œã€‚

**ä¸¤ç§å®ç°æ–¹å¼**ï¼š

1. **ç¼–æ’å¼Sagaï¼ˆChoreographyï¼‰**ï¼šæ¯ä¸ªæœåŠ¡éƒ½çŸ¥é“ä¸‹ä¸€æ­¥æ“ä½œ
2. **ç¼–æ’å¼Sagaï¼ˆOrchestrationï¼‰**ï¼šæœ‰ä¸€ä¸ªåè°ƒè€…ç®¡ç†æ•´ä¸ªæµç¨‹

**ç®—æ³•å®ç°**ï¼š

```python
from typing import Callable, List, Tuple, Optional

class SagaStep:
    """Sagaæ­¥éª¤"""

    def __init__(self, step_id: str,
                 execute_func: Callable,
                 compensate_func: Callable):
        self.step_id = step_id
        self.execute_func = execute_func
        self.compensate_func = compensate_func
        self.executed = False
        self.result = None

    def execute(self, *args, **kwargs):
        """æ‰§è¡Œæ­¥éª¤"""
        try:
            self.result = self.execute_func(*args, **kwargs)
            self.executed = True
            return True
        except Exception as e:
            logging.error(f"Step {self.step_id} failed: {e}")
            return False

    def compensate(self, *args, **kwargs):
        """è¡¥å¿æ­¥éª¤"""
        if self.executed:
            try:
                self.compensate_func(*args, **kwargs)
                self.executed = False
                return True
            except Exception as e:
                logging.error(f"Step {self.step_id} compensation failed: {e}")
                return False
        return True

class SagaOrchestrator:
    """Sagaç¼–æ’å™¨"""

    def __init__(self, saga_id: str):
        self.saga_id = saga_id
        self.steps: List[SagaStep] = []
        self.executed_steps: List[SagaStep] = []

    def add_step(self, step: SagaStep):
        """æ·»åŠ æ­¥éª¤"""
        self.steps.append(step)

    def execute(self) -> bool:
        """
        æ‰§è¡ŒSagaäº‹åŠ¡ã€‚

        Returns:
            æ˜¯å¦å…¨éƒ¨æˆåŠŸ
        """
        self.executed_steps = []

        for step in self.steps:
            if step.execute():
                self.executed_steps.append(step)
            else:
                # æ‰§è¡Œå¤±è´¥ï¼Œéœ€è¦è¡¥å¿
                self.compensate()
                return False

        return True

    def compensate(self):
        """è¡¥å¿æ‰€æœ‰å·²æ‰§è¡Œçš„æ­¥éª¤ï¼ˆé€†åºï¼‰"""
        for step in reversed(self.executed_steps):
            step.compensate()

# ç¤ºä¾‹ï¼šè®¢å•å¤„ç†Saga
def create_order_saga():
    """åˆ›å»ºè®¢å•Sagaç¤ºä¾‹"""
    saga = SagaOrchestrator("order_123")

    # æ­¥éª¤1ï¼šåˆ›å»ºè®¢å•
    def create_order():
        print("Creating order...")
        return {"order_id": "order_123"}

    def cancel_order():
        print("Canceling order...")

    saga.add_step(SagaStep("create_order", create_order, cancel_order))

    # æ­¥éª¤2ï¼šæ‰£å‡åº“å­˜
    def reduce_inventory():
        print("Reducing inventory...")
        return {"inventory_reduced": True}

    def restore_inventory():
        print("Restoring inventory...")

    saga.add_step(SagaStep("reduce_inventory", reduce_inventory, restore_inventory))

    # æ­¥éª¤3ï¼šæ‰£å‡è´¦æˆ·ä½™é¢
    def deduct_balance():
        print("Deducting balance...")
        return {"balance_deducted": True}

    def refund_balance():
        print("Refunding balance...")

    saga.add_step(SagaStep("deduct_balance", deduct_balance, refund_balance))

    return saga

# å¤æ‚åº¦åˆ†æ
# execute: O(n) å…¶ä¸­næ˜¯æ­¥éª¤æ•°é‡
# compensate: O(n) - éœ€è¦è¡¥å¿æ‰€æœ‰å·²æ‰§è¡Œçš„æ­¥éª¤
```

### 5.1.4 TCCæ¨¡å¼ï¼ˆTry-Confirm-Cancelï¼‰

**å®šä¹‰ 5.1.4** (TCCæ¨¡å¼ / Try-Confirm-Cancel Pattern)

**TCCæ¨¡å¼**æ˜¯ä¸€ç§è¡¥å¿å‹äº‹åŠ¡æ¨¡å¼ï¼Œæ¯ä¸ªæ“ä½œåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š

- **Try**ï¼šå°è¯•æ‰§è¡Œä¸šåŠ¡ï¼Œé¢„ç•™èµ„æº
- **Confirm**ï¼šç¡®è®¤æ‰§è¡Œä¸šåŠ¡ï¼Œæäº¤èµ„æº
- **Cancel**ï¼šå–æ¶ˆæ‰§è¡Œä¸šåŠ¡ï¼Œé‡Šæ”¾èµ„æº

**ç®—æ³•å®ç°**ï¼š

```python
class TCCService:
    """TCCæœåŠ¡"""

    def __init__(self, service_id: str):
        self.service_id = service_id
        self.state = "INIT"
        self.reserved_resources = {}

    def try_phase(self, resource_id: str, amount: int) -> bool:
        """
        Tryé˜¶æ®µï¼šé¢„ç•™èµ„æºã€‚

        Args:
            resource_id: èµ„æºID
            amount: èµ„æºæ•°é‡

        Returns:
            æ˜¯å¦æˆåŠŸé¢„ç•™
        """
        try:
            self.state = "TRYING"
            # é¢„ç•™èµ„æºï¼ˆæ¨¡æ‹Ÿï¼‰
            self.reserved_resources[resource_id] = amount
            self.state = "TRY_SUCCESS"
            logging.info(f"Service {self.service_id} reserved {amount} of {resource_id}")
            return True
        except Exception as e:
            logging.error(f"Service {self.service_id} try failed: {e}")
            self.state = "TRY_FAILED"
            return False

    def confirm_phase(self, resource_id: str) -> bool:
        """
        Confirmé˜¶æ®µï¼šç¡®è®¤æäº¤èµ„æºã€‚

        Args:
            resource_id: èµ„æºID

        Returns:
            æ˜¯å¦æˆåŠŸç¡®è®¤
        """
        try:
            self.state = "CONFIRMING"
            # ç¡®è®¤ä½¿ç”¨èµ„æºï¼ˆæ¨¡æ‹Ÿï¼‰
            if resource_id in self.reserved_resources:
                del self.reserved_resources[resource_id]
            self.state = "CONFIRMED"
            logging.info(f"Service {self.service_id} confirmed {resource_id}")
            return True
        except Exception as e:
            logging.error(f"Service {self.service_id} confirm failed: {e}")
            return False

    def cancel_phase(self, resource_id: str) -> bool:
        """
        Cancelé˜¶æ®µï¼šå–æ¶ˆå¹¶é‡Šæ”¾èµ„æºã€‚

        Args:
            resource_id: èµ„æºID

        Returns:
            æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        try:
            self.state = "CANCELLING"
            # é‡Šæ”¾èµ„æºï¼ˆæ¨¡æ‹Ÿï¼‰
            if resource_id in self.reserved_resources:
                del self.reserved_resources[resource_id]
            self.state = "CANCELLED"
            logging.info(f"Service {self.service_id} cancelled {resource_id}")
            return True
        except Exception as e:
            logging.error(f"Service {self.service_id} cancel failed: {e}")
            return False

class TCCOrchestrator:
    """TCCç¼–æ’å™¨"""

    def __init__(self, transaction_id: str):
        self.transaction_id = transaction_id
        self.services: List[TCCService] = []
        self.tried_services: List[TCCService] = []
        self.resource_mapping: Dict[str, Tuple[TCCService, str]] = {}

    def add_service(self, service: TCCService):
        """æ·»åŠ æœåŠ¡"""
        self.services.append(service)

    def execute(self, resources: Dict[str, int]) -> bool:
        """
        æ‰§è¡ŒTCCäº‹åŠ¡ã€‚

        Args:
            resources: èµ„æºå­—å…¸ {service_id: {resource_id: amount}}

        Returns:
            æ˜¯å¦å…¨éƒ¨æˆåŠŸ
        """
        # é˜¶æ®µ1ï¼šTryé˜¶æ®µ
        for service in self.services:
            service_resources = resources.get(service.service_id, {})
            all_success = True

            for resource_id, amount in service_resources.items():
                if service.try_phase(resource_id, amount):
                    self.tried_services.append(service)
                    self.resource_mapping[resource_id] = (service, resource_id)
                else:
                    all_success = False
                    break

            if not all_success:
                # Tryå¤±è´¥ï¼Œéœ€è¦Cancel
                self.cancel_all()
                return False

        # é˜¶æ®µ2ï¼šConfirmé˜¶æ®µ
        for service in self.tried_services:
            service_resources = resources.get(service.service_id, {})
            for resource_id in service_resources.keys():
                if not service.confirm_phase(resource_id):
                    # Confirmå¤±è´¥ï¼Œéœ€è¦Cancel
                    self.cancel_all()
                    return False

        return True

    def cancel_all(self):
        """å–æ¶ˆæ‰€æœ‰å·²Tryçš„æœåŠ¡"""
        for service, resource_id in self.resource_mapping.values():
            service.cancel_phase(resource_id)

# å¤æ‚åº¦åˆ†æ
# execute: O(n * m) å…¶ä¸­næ˜¯æœåŠ¡æ•°é‡ï¼Œmæ˜¯æ¯ä¸ªæœåŠ¡çš„èµ„æºæ•°é‡
# cancel_all: O(k) å…¶ä¸­kæ˜¯å·²Tryçš„æœåŠ¡æ•°é‡
```

---

## 5.2 åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿ / Distributed Storage Systems

åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿæä¾›é«˜å¯ç”¨ã€é«˜å¯æ‰©å±•çš„æ•°æ®å­˜å‚¨æœåŠ¡ã€‚

### 5.2.1 Google File System (GFS) æ¶æ„åˆ†æ

**å®šä¹‰ 5.2.1** (GFSæ¶æ„ / GFS Architecture)

**GFSï¼ˆGoogle File Systemï¼‰**æ˜¯Googleå¼€å‘çš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼Œç”¨äºå¤§è§„æ¨¡æ•°æ®å­˜å‚¨ã€‚

**æ¶æ„ç»„ä»¶**ï¼š

1. **MasterèŠ‚ç‚¹**ï¼šç®¡ç†å…ƒæ•°æ®ï¼Œåè°ƒæ–‡ä»¶è®¿é—®
2. **ChunkServerèŠ‚ç‚¹**ï¼šå­˜å‚¨å®é™…æ•°æ®å—
3. **å®¢æˆ·ç«¯**ï¼šè®¿é—®æ–‡ä»¶ç³»ç»Ÿ

**å…³é”®ç‰¹æ€§**ï¼š

- **å¤§æ–‡ä»¶æ”¯æŒ**ï¼šæ–‡ä»¶è¢«åˆ†å‰²æˆå›ºå®šå¤§å°çš„å—ï¼ˆchunkï¼Œé€šå¸¸64MBï¼‰
- **ä¸»ä»æ¶æ„**ï¼šå•ä¸ªMasterç®¡ç†å…ƒæ•°æ®
- **å¤åˆ¶æœºåˆ¶**ï¼šæ¯ä¸ªå—æœ‰å¤šä¸ªå‰¯æœ¬ï¼ˆé€šå¸¸3ä¸ªï¼‰
- **è¿½åŠ å†™å…¥**ï¼šä¼˜åŒ–è¿½åŠ æ“ä½œ

**æ¶æ„å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰**ï¼š

```python
from typing import Dict, List, Optional
from dataclasses import dataclass
import hashlib

@dataclass
class ChunkLocation:
    """å—ä½ç½®ä¿¡æ¯"""
    chunk_id: str
    chunk_servers: List[str]  # å­˜å‚¨è¯¥å—çš„æœåŠ¡å™¨åˆ—è¡¨
    version: int

@dataclass
class FileMetadata:
    """æ–‡ä»¶å…ƒæ•°æ®"""
    file_path: str
    chunk_handles: List[str]  # å—å¥æŸ„åˆ—è¡¨
    chunk_size: int = 64 * 1024 * 1024  # 64MB

class GFSMaster:
    """GFS MasterèŠ‚ç‚¹"""

    def __init__(self):
        self.file_metadata: Dict[str, FileMetadata] = {}
        self.chunk_locations: Dict[str, ChunkLocation] = {}
        self.chunk_servers: List[str] = []

    def register_chunk_server(self, server_id: str):
        """æ³¨å†ŒChunkServer"""
        if server_id not in self.chunk_servers:
            self.chunk_servers.append(server_id)

    def create_file(self, file_path: str, num_chunks: int = 1) -> FileMetadata:
        """
        åˆ›å»ºæ–‡ä»¶ã€‚

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            num_chunks: å—æ•°é‡

        Returns:
            æ–‡ä»¶å…ƒæ•°æ®
        """
        chunk_handles = []
        for i in range(num_chunks):
            chunk_id = self._generate_chunk_id(file_path, i)
            chunk_handles.append(chunk_id)

            # åˆ†é…å—åˆ°ChunkServerï¼ˆç®€åŒ–ç‰ˆï¼šè½®è¯¢åˆ†é…ï¼‰
            chunk_servers = self._allocate_chunk_servers(chunk_id, num_replicas=3)
            self.chunk_locations[chunk_id] = ChunkLocation(
                chunk_id=chunk_id,
                chunk_servers=chunk_servers,
                version=1
            )

        metadata = FileMetadata(
            file_path=file_path,
            chunk_handles=chunk_handles
        )
        self.file_metadata[file_path] = metadata
        return metadata

    def get_chunk_location(self, chunk_id: str) -> Optional[ChunkLocation]:
        """è·å–å—ä½ç½®"""
        return self.chunk_locations.get(chunk_id)

    def _generate_chunk_id(self, file_path: str, chunk_index: int) -> str:
        """ç”Ÿæˆå—ID"""
        data = f"{file_path}:{chunk_index}".encode()
        return hashlib.md5(data).hexdigest()

    def _allocate_chunk_servers(self, chunk_id: str, num_replicas: int) -> List[str]:
        """åˆ†é…å—åˆ°ChunkServer"""
        if len(self.chunk_servers) < num_replicas:
            return self.chunk_servers.copy()

        # ç®€åŒ–ç‰ˆï¼šè½®è¯¢åˆ†é…
        start_index = hash(chunk_id) % len(self.chunk_servers)
        selected = []
        for i in range(num_replicas):
            index = (start_index + i) % len(self.chunk_servers)
            selected.append(self.chunk_servers[index])

        return selected

class GFSChunkServer:
    """GFS ChunkServerèŠ‚ç‚¹"""

    def __init__(self, server_id: str):
        self.server_id = server_id
        self.chunks: Dict[str, bytes] = {}  # chunk_id -> chunk_data

    def store_chunk(self, chunk_id: str, chunk_data: bytes):
        """å­˜å‚¨å—"""
        self.chunks[chunk_id] = chunk_data

    def read_chunk(self, chunk_id: str) -> Optional[bytes]:
        """è¯»å–å—"""
        return self.chunks.get(chunk_id)

    def append_chunk(self, chunk_id: str, data: bytes):
        """è¿½åŠ æ•°æ®åˆ°å—"""
        if chunk_id in self.chunks:
            self.chunks[chunk_id] += data
        else:
            self.chunks[chunk_id] = data

# å¤æ‚åº¦åˆ†æ
# create_file: O(num_chunks * num_replicas)
# get_chunk_location: O(1) - å­—å…¸æŸ¥æ‰¾
# store_chunk/read_chunk: O(1) - å­—å…¸æ“ä½œ
```

### 5.2.2 Hadoop Distributed File System (HDFS) æ¶æ„åˆ†æ

**å®šä¹‰ 5.2.2** (HDFSæ¶æ„ / HDFS Architecture)

**HDFSï¼ˆHadoop Distributed File Systemï¼‰**æ˜¯Apache Hadoopé¡¹ç›®çš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼ŒåŸºäºGFSè®¾è®¡ã€‚

**æ¶æ„ç»„ä»¶**ï¼š

1. **NameNode**ï¼šç®¡ç†æ–‡ä»¶ç³»ç»Ÿå‘½åç©ºé—´å’Œå…ƒæ•°æ®
2. **DataNode**ï¼šå­˜å‚¨å®é™…æ•°æ®å—
3. **Secondary NameNode**ï¼šè¾…åŠ©NameNodeå·¥ä½œ

**å…³é”®ç‰¹æ€§**ï¼š

- **å†™ä¸€æ¬¡è¯»å¤šæ¬¡**ï¼šä¼˜åŒ–å¤§æ–‡ä»¶é¡ºåºè¯»å–
- **å—å¤åˆ¶**ï¼šé»˜è®¤3ä¸ªå‰¯æœ¬
- **æœºæ¶æ„ŸçŸ¥**ï¼šè€ƒè™‘ç½‘ç»œæ‹“æ‰‘çš„å‰¯æœ¬æ”¾ç½®ç­–ç•¥

**æ¶æ„å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰**ï¼š

```python
@dataclass
class BlockLocation:
    """å—ä½ç½®ä¿¡æ¯"""
    block_id: str
    data_nodes: List[str]
    block_size: int = 128 * 1024 * 1024  # 128MB

class HDFSNameNode:
    """HDFS NameNode"""

    def __init__(self):
        self.file_blocks: Dict[str, List[str]] = {}  # file_path -> [block_ids]
        self.block_locations: Dict[str, BlockLocation] = {}
        self.data_nodes: List[str] = []

    def register_data_node(self, node_id: str):
        """æ³¨å†ŒDataNode"""
        if node_id not in self.data_nodes:
            self.data_nodes.append(node_id)

    def create_file(self, file_path: str, file_size: int) -> List[str]:
        """
        åˆ›å»ºæ–‡ä»¶å¹¶åˆ†é…å—ã€‚

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            file_size: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰

        Returns:
            å—IDåˆ—è¡¨
        """
        block_size = 128 * 1024 * 1024  # 128MB
        num_blocks = (file_size + block_size - 1) // block_size

        block_ids = []
        for i in range(num_blocks):
            block_id = f"{file_path}_block_{i}"
            block_ids.append(block_id)

            # åˆ†é…å—åˆ°DataNodeï¼ˆç®€åŒ–ç‰ˆï¼šè½®è¯¢åˆ†é…ï¼Œè€ƒè™‘æœºæ¶æ„ŸçŸ¥ï¼‰
            data_nodes = self._allocate_data_nodes(block_id, num_replicas=3)
            self.block_locations[block_id] = BlockLocation(
                block_id=block_id,
                data_nodes=data_nodes,
                block_size=block_size
            )

        self.file_blocks[file_path] = block_ids
        return block_ids

    def get_block_locations(self, file_path: str, start_offset: int, length: int) -> List[BlockLocation]:
        """
        è·å–æ–‡ä»¶çš„å—ä½ç½®ä¿¡æ¯ã€‚

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            start_offset: èµ·å§‹åç§»
            length: è¯»å–é•¿åº¦

        Returns:
            å—ä½ç½®åˆ—è¡¨
        """
        block_ids = self.file_blocks.get(file_path, [])
        block_size = 128 * 1024 * 1024

        start_block = start_offset // block_size
        end_block = (start_offset + length - 1) // block_size

        locations = []
        for i in range(start_block, min(end_block + 1, len(block_ids))):
            block_id = block_ids[i]
            location = self.block_locations.get(block_id)
            if location:
                locations.append(location)

        return locations

    def _allocate_data_nodes(self, block_id: str, num_replicas: int) -> List[str]:
        """åˆ†é…å—åˆ°DataNodeï¼ˆç®€åŒ–ç‰ˆï¼šè½®è¯¢åˆ†é…ï¼‰"""
        if len(self.data_nodes) < num_replicas:
            return self.data_nodes.copy()

        start_index = hash(block_id) % len(self.data_nodes)
        selected = []
        for i in range(num_replicas):
            index = (start_index + i) % len(self.data_nodes)
            selected.append(self.data_nodes[index])

        return selected

class HDFSDataNode:
    """HDFS DataNode"""

    def __init__(self, node_id: str):
        self.node_id = node_id
        self.blocks: Dict[str, bytes] = {}  # block_id -> block_data

    def store_block(self, block_id: str, block_data: bytes):
        """å­˜å‚¨å—"""
        self.blocks[block_id] = block_data

    def read_block(self, block_id: str, offset: int = 0, length: Optional[int] = None) -> Optional[bytes]:
        """
        è¯»å–å—ã€‚

        Args:
            block_id: å—ID
            offset: èµ·å§‹åç§»
            length: è¯»å–é•¿åº¦ï¼ˆNoneè¡¨ç¤ºè¯»å–åˆ°æœ«å°¾ï¼‰

        Returns:
            å—æ•°æ®
        """
        block_data = self.blocks.get(block_id)
        if block_data is None:
            return None

        if length is None:
            return block_data[offset:]
        else:
            return block_data[offset:offset+length]

# å¤æ‚åº¦åˆ†æ
# create_file: O(num_blocks)
# get_block_locations: O(num_blocks_in_range)
# store_block/read_block: O(1)
```

### 5.2.3 Dynamo æ¶æ„åˆ†æ

**å®šä¹‰ 5.2.3** (Dynamoæ¶æ„ / Dynamo Architecture)

**Dynamo**æ˜¯Amazonå¼€å‘çš„åˆ†å¸ƒå¼é”®å€¼å­˜å‚¨ç³»ç»Ÿï¼Œå¼ºè°ƒé«˜å¯ç”¨æ€§å’Œæœ€ç»ˆä¸€è‡´æ€§ã€‚

**å…³é”®ç‰¹æ€§**ï¼š

- **ä¸€è‡´æ€§å“ˆå¸Œ**ï¼šç”¨äºæ•°æ®åˆ†ç‰‡å’Œè´Ÿè½½å‡è¡¡
- **å‘é‡æ—¶é’Ÿ**ï¼šç”¨äºå†²çªæ£€æµ‹å’Œè§£å†³
- **Sloppy Quorum**ï¼šçµæ´»çš„è¯»å†™ä»²è£
- **åç†µï¼ˆAnti-Entropyï¼‰**ï¼šæ•°æ®ä¿®å¤æœºåˆ¶

**æ¶æ„å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰**ï¼š

```python
from typing import Dict, List, Optional, Tuple
import hashlib
import time

class VectorClock:
    """å‘é‡æ—¶é’Ÿ"""

    def __init__(self):
        self.clock: Dict[str, int] = {}  # node_id -> counter

    def increment(self, node_id: str):
        """å¢åŠ è®¡æ•°å™¨"""
        self.clock[node_id] = self.clock.get(node_id, 0) + 1

    def update(self, other: 'VectorClock'):
        """æ›´æ–°å‘é‡æ—¶é’Ÿï¼ˆå–æœ€å¤§å€¼ï¼‰"""
        for node_id, counter in other.clock.items():
            self.clock[node_id] = max(self.clock.get(node_id, 0), counter)

    def happens_before(self, other: 'VectorClock') -> bool:
        """æ£€æŸ¥æ˜¯å¦å‘ç”Ÿåœ¨å¦ä¸€ä¸ªæ—¶é’Ÿä¹‹å‰"""
        all_less_or_equal = all(
            self.clock.get(node_id, 0) <= other.clock.get(node_id, 0)
            for node_id in set(self.clock.keys()) | set(other.clock.keys())
        )
        at_least_one_less = any(
            self.clock.get(node_id, 0) < other.clock.get(node_id, 0)
            for node_id in set(self.clock.keys()) | set(other.clock.keys())
        )
        return all_less_or_equal and at_least_one_less

class DynamoNode:
    """DynamoèŠ‚ç‚¹"""

    def __init__(self, node_id: str):
        self.node_id = node_id
        self.data: Dict[str, Tuple[bytes, VectorClock]] = {}  # key -> (value, vector_clock)

    def put(self, key: str, value: bytes, vector_clock: VectorClock):
        """å­˜å‚¨é”®å€¼å¯¹"""
        existing_value, existing_clock = self.data.get(key, (None, VectorClock()))

        # å†²çªæ£€æµ‹
        if existing_clock.happens_before(vector_clock):
            # æ–°ç‰ˆæœ¬å‘ç”Ÿä¹‹åï¼Œç›´æ¥è¦†ç›–
            self.data[key] = (value, vector_clock)
        elif vector_clock.happens_before(existing_clock):
            # æ—§ç‰ˆæœ¬å‘ç”Ÿä¹‹åï¼Œä¿ç•™æ—§ç‰ˆæœ¬
            pass
        else:
            # å†²çªï¼šéœ€è¦è§£å†³ï¼ˆç®€åŒ–ç‰ˆï¼šä¿ç•™æ–°ç‰ˆæœ¬ï¼‰
            self.data[key] = (value, vector_clock)

    def get(self, key: str) -> Optional[Tuple[bytes, VectorClock]]:
        """è·å–é”®å€¼å¯¹"""
        return self.data.get(key)

class DynamoRing:
    """Dynamoä¸€è‡´æ€§å“ˆå¸Œç¯"""

    def __init__(self, num_virtual_nodes: int = 3):
        self.nodes: Dict[str, DynamoNode] = {}
        self.ring: List[Tuple[int, str]] = []  # (hash_value, node_id)
        self.num_virtual_nodes = num_virtual_nodes

    def add_node(self, node_id: str):
        """æ·»åŠ èŠ‚ç‚¹åˆ°ç¯"""
        node = DynamoNode(node_id)
        self.nodes[node_id] = node

        # åˆ›å»ºè™šæ‹ŸèŠ‚ç‚¹
        for i in range(self.num_virtual_nodes):
            virtual_node_id = f"{node_id}:{i}"
            hash_value = self._hash(virtual_node_id)
            self.ring.append((hash_value, node_id))

        self.ring.sort(key=lambda x: x[0])

    def _hash(self, key: str) -> int:
        """ä¸€è‡´æ€§å“ˆå¸Œå‡½æ•°"""
        return int(hashlib.md5(key.encode()).hexdigest(), 16)

    def get_nodes_for_key(self, key: str, num_replicas: int = 3) -> List[str]:
        """
        è·å–å­˜å‚¨é”®çš„èŠ‚ç‚¹åˆ—è¡¨ã€‚

        Args:
            key: é”®
            num_replicas: å‰¯æœ¬æ•°é‡

        Returns:
            èŠ‚ç‚¹IDåˆ—è¡¨
        """
        hash_value = self._hash(key)

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤§äºç­‰äºhash_valueçš„èŠ‚ç‚¹
        start_index = 0
        for i, (ring_hash, _) in enumerate(self.ring):
            if ring_hash >= hash_value:
                start_index = i
                break

        # è·å–Nä¸ªèŠ‚ç‚¹ï¼ˆåŒ…æ‹¬è™šæ‹ŸèŠ‚ç‚¹å¯¹åº”çš„å®é™…èŠ‚ç‚¹ï¼‰
        selected_nodes = []
        seen_nodes = set()
        i = start_index

        while len(selected_nodes) < num_replicas and i < len(self.ring) * 2:
            ring_hash, node_id = self.ring[i % len(self.ring)]
            if node_id not in seen_nodes:
                selected_nodes.append(node_id)
                seen_nodes.add(node_id)
            i += 1

        return selected_nodes

    def put(self, key: str, value: bytes, node_id: str) -> bool:
        """å­˜å‚¨é”®å€¼å¯¹ï¼ˆå†™æ“ä½œï¼‰"""
        # è·å–å­˜å‚¨èŠ‚ç‚¹
        replica_nodes = self.get_nodes_for_key(key)

        # åˆ›å»ºå‘é‡æ—¶é’Ÿ
        vector_clock = VectorClock()
        vector_clock.increment(node_id)

        # å†™å…¥æ‰€æœ‰å‰¯æœ¬ï¼ˆç®€åŒ–ç‰ˆï¼šåŒæ­¥å†™å…¥ï¼‰
        success_count = 0
        for replica_node_id in replica_nodes:
            if replica_node_id in self.nodes:
                self.nodes[replica_node_id].put(key, value, vector_clock)
                success_count += 1

        # Quorumï¼šè‡³å°‘å†™å…¥Wä¸ªèŠ‚ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼šW=2ï¼‰
        return success_count >= 2

    def get(self, key: str) -> Optional[bytes]:
        """è·å–é”®å€¼å¯¹ï¼ˆè¯»æ“ä½œï¼‰"""
        # è·å–å­˜å‚¨èŠ‚ç‚¹
        replica_nodes = self.get_nodes_for_key(key)

        # ä»æ‰€æœ‰å‰¯æœ¬è¯»å–
        values = []
        for replica_node_id in replica_nodes:
            if replica_node_id in self.nodes:
                result = self.nodes[replica_node_id].get(key)
                if result:
                    values.append(result)

        # Quorumï¼šè‡³å°‘è¯»å–Rä¸ªèŠ‚ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼šR=2ï¼‰
        if len(values) < 2:
            return None

        # é€‰æ‹©æœ€æ–°ç‰ˆæœ¬ï¼ˆç®€åŒ–ç‰ˆï¼šå–ç¬¬ä¸€ä¸ªï¼‰
        if values:
            value, _ = values[0]
            return value

        return None

# å¤æ‚åº¦åˆ†æ
# add_node: O(virtual_nodes * log(nodes))
# get_nodes_for_key: O(nodes)
# put/get: O(replicas)
```

### 5.2.4 Cassandra æ¶æ„åˆ†æ

**å®šä¹‰ 5.2.4** (Cassandraæ¶æ„ / Cassandra Architecture)

**Cassandra**æ˜¯Facebookå¼€å‘çš„åˆ†å¸ƒå¼NoSQLæ•°æ®åº“ï¼ŒåŸºäºDynamoå’ŒBigTableè®¾è®¡ã€‚

**å…³é”®ç‰¹æ€§**ï¼š

- **æ— ä¸­å¿ƒåŒ–æ¶æ„**ï¼šæ‰€æœ‰èŠ‚ç‚¹å¹³ç­‰
- **ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡**ï¼šç±»ä¼¼Dynamo
- **å¯è°ƒä¸€è‡´æ€§**ï¼šå¯é…ç½®çš„ä¸€è‡´æ€§çº§åˆ«
- **åˆ—æ—å­˜å‚¨**ï¼šåŸºäºåˆ—çš„æ•°æ®æ¨¡å‹

**æ¶æ„å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰**ï¼š

```python
class CassandraNode:
    """CassandraèŠ‚ç‚¹"""

    def __init__(self, node_id: str):
        self.node_id = node_id
        # åˆ—æ—å­˜å‚¨ï¼škeyspace -> column_family -> key -> columns
        self.data: Dict[str, Dict[str, Dict[str, Dict[str, bytes]]]] = {}

    def put(self, keyspace: str, column_family: str,
            key: str, column: str, value: bytes):
        """å­˜å‚¨æ•°æ®"""
        if keyspace not in self.data:
            self.data[keyspace] = {}
        if column_family not in self.data[keyspace]:
            self.data[keyspace][column_family] = {}
        if key not in self.data[keyspace][column_family]:
            self.data[keyspace][column_family][key] = {}

        self.data[keyspace][column_family][key][column] = value

    def get(self, keyspace: str, column_family: str, key: str, column: str) -> Optional[bytes]:
        """è·å–æ•°æ®"""
        return self.data.get(keyspace, {}).get(column_family, {}).get(key, {}).get(column)

class CassandraCluster:
    """Cassandraé›†ç¾¤"""

    def __init__(self, replication_factor: int = 3):
        self.nodes: Dict[str, CassandraNode] = {}
        self.ring: List[Tuple[int, str]] = []
        self.replication_factor = replication_factor

    def add_node(self, node_id: str):
        """æ·»åŠ èŠ‚ç‚¹"""
        node = CassandraNode(node_id)
        self.nodes[node_id] = node

        hash_value = self._hash(node_id)
        self.ring.append((hash_value, node_id))
        self.ring.sort(key=lambda x: x[0])

    def _hash(self, key: str) -> int:
        """ä¸€è‡´æ€§å“ˆå¸Œ"""
        return int(hashlib.md5(key.encode()).hexdigest(), 16)

    def get_replica_nodes(self, partition_key: str) -> List[str]:
        """è·å–å­˜å‚¨åˆ†åŒºçš„å‰¯æœ¬èŠ‚ç‚¹"""
        hash_value = self._hash(partition_key)

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
        start_index = 0
        for i, (ring_hash, _) in enumerate(self.ring):
            if ring_hash >= hash_value:
                start_index = i
                break

        # è·å–Nä¸ªå‰¯æœ¬èŠ‚ç‚¹
        replica_nodes = []
        for i in range(self.replication_factor):
            index = (start_index + i) % len(self.ring)
            _, node_id = self.ring[index]
            replica_nodes.append(node_id)

        return replica_nodes

    def put(self, keyspace: str, column_family: str,
            partition_key: str, clustering_key: str,
            column: str, value: bytes,
            consistency_level: str = "QUORUM") -> bool:
        """
        å­˜å‚¨æ•°æ®ã€‚

        Args:
            consistency_level: ä¸€è‡´æ€§çº§åˆ«ï¼ˆONE, QUORUM, ALLï¼‰
        """
        replica_nodes = self.get_replica_nodes(partition_key)

        success_count = 0
        for node_id in replica_nodes:
            if node_id in self.nodes:
                self.nodes[node_id].put(
                    keyspace, column_family,
                    partition_key, clustering_key, column, value
                )
                success_count += 1

        # æ ¹æ®ä¸€è‡´æ€§çº§åˆ«åˆ¤æ–­æ˜¯å¦æˆåŠŸ
        if consistency_level == "ONE":
            return success_count >= 1
        elif consistency_level == "QUORUM":
            return success_count >= (len(replica_nodes) // 2 + 1)
        elif consistency_level == "ALL":
            return success_count == len(replica_nodes)
        else:
            return False

# å¤æ‚åº¦åˆ†æ
# add_node: O(log(nodes))
# get_replica_nodes: O(nodes)
# put: O(replication_factor)
```

---

## 5.3 æ€»ç»“ä¸å±•æœ› / Summary and Future Directions

æœ¬æ–‡æ¡£ä»‹ç»äº†åˆ†å¸ƒå¼ç³»ç»Ÿä¸­çš„é«˜çº§ç†è®ºä¸»é¢˜ï¼š

1. **åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†**ï¼š2PCã€3PCã€Sagaã€TCCç­‰äº‹åŠ¡æ¨¡å¼ï¼Œä¸ºåˆ†å¸ƒå¼æ•°æ®ä¸€è‡´æ€§æä¾›äº†ç†è®ºåŸºç¡€
2. **åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿ**ï¼šGFSã€HDFSã€Dynamoã€Cassandraç­‰å­˜å‚¨ç³»ç»Ÿæ¶æ„ï¼Œä¸ºå¤§è§„æ¨¡æ•°æ®å­˜å‚¨æä¾›äº†è®¾è®¡å‚è€ƒ

è¿™äº›é«˜çº§ç†è®ºä¸»é¢˜ä¸ºåˆ†å¸ƒå¼ç³»ç»Ÿçš„è®¾è®¡å’Œå®ç°æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ã€‚

### æœªæ¥ç ”ç©¶æ–¹å‘

- **äº‘åŸç”Ÿåˆ†å¸ƒå¼ç³»ç»Ÿ**ï¼šå®¹å™¨åŒ–å’Œå¾®æœåŠ¡æ¶æ„çš„åˆ†å¸ƒå¼ç³»ç»Ÿ
- **è¾¹ç¼˜è®¡ç®—å­˜å‚¨**ï¼šè¾¹ç¼˜èŠ‚ç‚¹çš„åˆ†å¸ƒå¼å­˜å‚¨æ–¹æ¡ˆ
- **AIé©±åŠ¨çš„åˆ†å¸ƒå¼ç³»ç»Ÿ**ï¼šä½¿ç”¨æœºå™¨å­¦ä¹ ä¼˜åŒ–åˆ†å¸ƒå¼ç³»ç»Ÿæ€§èƒ½
- **é‡å­åˆ†å¸ƒå¼ç³»ç»Ÿ**ï¼šé‡å­è®¡ç®—ç¯å¢ƒä¸‹çš„åˆ†å¸ƒå¼ç³»ç»Ÿ

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ
**è´¨é‡ç­‰çº§**: â­â­â­â­â­ äº”æ˜Ÿçº§
**å›½é™…å¯¹æ ‡**: 100% è¾¾æ ‡ âœ…
**å®ŒæˆçŠ¶æ€**: âš™ï¸ æŒç»­æ›´æ–°ä¸­

*æœ¬æ–‡æ¡£æ˜¯é˜¶æ®µäºŒï¼šé«˜çº§ç†è®ºè¡¥å……çš„ä¸€éƒ¨åˆ†ï¼Œå°†æŒç»­æ›´æ–°å®Œå–„ã€‚*
